{"INCIDENT ID": "Incident 1", "TITLE": "Google\u2019s YouTube Kids App Presents Inappropriate Content", "DESCRIPTION": "YouTube\u2019s content filtering and recommendation algorithms exposed children to disturbing and inappropriate videos.", "DATE": "2015-05-19", "ALLEGED DEPLOYER OF AI SYSTEM": "YouTube", "ALLEGED DEVELOPER OF AI SYSTEM": "YouTube", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Children"}
{"INCIDENT ID": "Incident 23", "TITLE": "Las Vegas Self-Driving Bus Involved in Accident", "DESCRIPTION": "A self-driving public shuttle by Keolis North America and Navya was involved in a collision with a human-driven delivery truck in Las Vegas, Nevada on its first day of service.", "DATE": "2017-11-08", "ALLEGED DEPLOYER OF AI SYSTEM": "Navya, Keolis North America", "ALLEGED DEVELOPER OF AI SYSTEM": "Navya, Keolis North America", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Navya, Keolis North America, bus passengers"}
{"INCIDENT ID": "Incident 4", "TITLE": "Uber AV Killed Pedestrian in Arizona", "DESCRIPTION": "An Uber autonomous vehicle (AV) in autonomous mode struck and killed a pedestrian in Tempe, Arizona.", "DATE": "2018-03-18", "ALLEGED DEPLOYER OF AI SYSTEM": "Uber", "ALLEGED DEVELOPER OF AI SYSTEM": "Uber", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Elaine Herzberg, pedestrians"}
{"INCIDENT ID": "Incident 12", "TITLE": "Common Biases of Vector Embeddings", "DESCRIPTION": "Researchers from Boston University and Microsoft Research, New England demonstrated gender bias in the most common techniques used to embed words for natural language processing (NLP).", "DATE": "2016-07-21", "ALLEGED DEPLOYER OF AI SYSTEM": "Microsoft Research, Boston University", "ALLEGED DEVELOPER OF AI SYSTEM": "Microsoft Research, Google, Boston University", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Women, Minority Groups"}
{"INCIDENT ID": "Incident 5", "TITLE": "Collection of Robotic Surgery Malfunctions", "DESCRIPTION": "Study on database reports of robotic surgery malfunctions (8,061), including those ending in injury (1,391) and death (144), between 2000 and 2013.", "DATE": "2015-07-13", "ALLEGED DEPLOYER OF AI SYSTEM": "Hospitals, Doctors", "ALLEGED DEVELOPER OF AI SYSTEM": "Intuitive Surgical", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "patients"}
{"INCIDENT ID": "Incident 6", "TITLE": "TayBot", "DESCRIPTION": "Microsoft's Tay, an artificially intelligent chatbot, was released on March 23, 2016 and removed within 24 hours due to multiple racist, sexist, and anit-semitic tweets generated by the bot.", "DATE": "2016-03-24", "ALLEGED DEPLOYER OF AI SYSTEM": "Microsoft", "ALLEGED DEVELOPER OF AI SYSTEM": "Microsoft", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Twitter Users"}
{"INCIDENT ID": "Incident 10", "TITLE": "Kronos Scheduling Algorithm Allegedly Caused Financial Issues for Starbucks Employees", "DESCRIPTION": "Kronos\u2019s scheduling algorithm and its use by Starbucks managers allegedly negatively impacted financial and scheduling stability for Starbucks employees, which disadvantaged wage workers.", "DATE": "2014-08-14", "ALLEGED DEPLOYER OF AI SYSTEM": "Starbucks", "ALLEGED DEVELOPER OF AI SYSTEM": "Kronos", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Starbucks employees"}
{"INCIDENT ID": "Incident 11", "TITLE": "Northpointe Risk Models", "DESCRIPTION": "An algorithm developed by Northpointe and used in the penal system is two times more likely to incorrectly label a black person as a high-risk re-offender and is two times more likely to incorrectly label a white person as low-risk for reoffense according to a ProPublica review.", "DATE": "2016-05-23", "ALLEGED DEPLOYER OF AI SYSTEM": "Northpointe", "ALLEGED DEVELOPER OF AI SYSTEM": "Northpointe", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Accused People"}
{"INCIDENT ID": "Incident 20", "TITLE": "A Collection of Tesla Autopilot-Involved Crashes", "DESCRIPTION": "Multiple unrelated car accidents result in varying levels of harm have been occurred while a Tesla's autopilot was in use.", "DATE": "2016-06-30", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Motorists"}
{"INCIDENT ID": "Incident 24", "TITLE": "Robot kills worker at German Volkswagen plant", "DESCRIPTION": "A Volkswagen plant robot \"crushed to death\" a worker by pinning him to a metal plate.", "DATE": "2014-07-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Volkswagen", "ALLEGED DEVELOPER OF AI SYSTEM": "Volkswagen", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Robotics Consultant"}
{"INCIDENT ID": "Incident 14", "TITLE": "Biased Sentiment Analysis", "DESCRIPTION": "Google Cloud's Natural Language API provided racist, homophobic, amd antisemitic sentiment analyses.", "DATE": "2017-10-26", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Women, Minority Groups"}
{"INCIDENT ID": "Incident 16", "TITLE": "Images of Black People Labeled as Gorillas", "DESCRIPTION": "Google Photos image processing software mistakenly labelled a black couple as \"gorillas.\"", "DATE": "2015-06-03", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Black people"}
{"INCIDENT ID": "Incident 3", "TITLE": "Crashes with Maneuvering Characteristics Augmentation System (MCAS)", "DESCRIPTION": "A Boeing 737 crashed into the sea, killing 189 people, after faulty sensor data caused an automated manuevering system to repeatedly push the plane's nose downward.", "DATE": "2018-10-27", "ALLEGED DEPLOYER OF AI SYSTEM": "Boeing", "ALLEGED DEVELOPER OF AI SYSTEM": "Boeing", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Airplane Passengers, Airplane Crew"}
{"INCIDENT ID": "Incident 19", "TITLE": "Sexist and Racist Google Adsense Advertisements", "DESCRIPTION": "Advertisements chosen by Google Adsense are reported as producing sexist and racist results.", "DATE": "2013-01-23", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Women, Minority Groups"}
{"INCIDENT ID": "Incident 8", "TITLE": "Uber Autonomous Cars Running Red Lights", "DESCRIPTION": "Uber vehicles equipped with technology allowing for autonomous driving running red lights in San Francisco street testing.", "DATE": "2014-08-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Uber", "ALLEGED DEVELOPER OF AI SYSTEM": "Uber", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "pedestrians, Motorists"}
{"INCIDENT ID": "Incident 13", "TITLE": "High-Toxicity Assessed on Text Involving Women and Minority Groups", "DESCRIPTION": "Google's Perspective API, which assigns a toxicity score to online text, seems to award higher toxicity scores to content involving non-white, male, Christian, heterosexual phrases.", "DATE": "2017-02-27", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Women, Minority Groups"}
{"INCIDENT ID": "Incident 17", "TITLE": "Inappropriate Gmail Smart Reply Suggestions", "DESCRIPTION": "Google's Gmail Smart Reply tool was over-recommending the response \"I love you\" in situations where it was deemed innappropriate.", "DATE": "2015-11-03", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Gmail Users"}
{"INCIDENT ID": "Incident 18", "TITLE": "Gender Biases of Google Image Search", "DESCRIPTION": "Google Image returns results that under-represent women in leadership roles, notably with the first photo of a female \"CEO\" being a Barbie doll after 11 rows of male CEOs.", "DATE": "2015-04-04", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Women"}
{"INCIDENT ID": "Incident 15", "TITLE": "Amazon Censors Gay Books", "DESCRIPTION": "Amazon's book store \"cataloging error\" led to books containing gay and lesbian themes to lose their sales ranking, therefore losing visibility on the sales platform.", "DATE": "2008-05-23", "ALLEGED DEPLOYER OF AI SYSTEM": "Amazon", "ALLEGED DEVELOPER OF AI SYSTEM": "Amazon", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Amazon Customers"}
{"INCIDENT ID": "Incident 7", "TITLE": "Wikipedia Vandalism Prevention Bot Loop", "DESCRIPTION": "Wikipedia bots meant to remove vandalism clash with each other and form feedback loops of repetitve undoing of the other bot's edits.", "DATE": "2017-02-24", "ALLEGED DEPLOYER OF AI SYSTEM": "Wikipedia", "ALLEGED DEVELOPER OF AI SYSTEM": "Wikipedia", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Wikimedia Foundation, Wikipedia Editors, Wikipedia Users"}
{"INCIDENT ID": "Incident 32", "TITLE": "Identical Twins Can Open Apple FaceID Protected Devices", "DESCRIPTION": "Apple's iPhone FaceID can be opened by an identical twin of the person who has registered their face to unlock the phone.", "DATE": "2017-09-13", "ALLEGED DEPLOYER OF AI SYSTEM": "Apple", "ALLEGED DEVELOPER OF AI SYSTEM": "Apple", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "People with Twins"}
{"INCIDENT ID": "Incident 48", "TITLE": "Passport checker Detects Asian man's Eyes as Closed", "DESCRIPTION": "New Zealand passport robot reader rejects the application of an applicant with Asian descent and says his eyes are closed.", "DATE": "2016-12-07", "ALLEGED DEPLOYER OF AI SYSTEM": "New Zealand", "ALLEGED DEVELOPER OF AI SYSTEM": "New Zealand", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Asian People"}
{"INCIDENT ID": "Incident 43", "TITLE": "Racist AI behaviour is not a new problem", "DESCRIPTION": "From 1982 to 1986, St George's Hospital Medical School used a program to automate a portion of their admissions process that resulted in discrimination against women and members of ethnic minorities.", "DATE": "1998-03-05", "ALLEGED DEPLOYER OF AI SYSTEM": "St George's Hospital Medical School", "ALLEGED DEVELOPER OF AI SYSTEM": "Dr. Geoffrey Franglen", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Women, Minority Groups"}
{"INCIDENT ID": "Incident 26", "TITLE": "Hackers Break Apple Face ID", "DESCRIPTION": "Vietnamese security firm Bkav created an improved mask to bypass Apple's Face ID", "DATE": "2017-09-13", "ALLEGED DEPLOYER OF AI SYSTEM": "Apple", "ALLEGED DEVELOPER OF AI SYSTEM": "Apple", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Apple, Device Owners"}
{"INCIDENT ID": "Incident 33", "TITLE": "Amazon Alexa Plays Loud Music when Owner is Away", "DESCRIPTION": "An Amazon Alexa, without instruction to do so, began playing loud music in the early morning while the homeowner was away leading to police breaking into their house to turn off the device.", "DATE": "2017-11-09", "ALLEGED DEPLOYER OF AI SYSTEM": "Amazon", "ALLEGED DEVELOPER OF AI SYSTEM": "Amazon", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Oliver Haberstroh, Neighbors"}
{"INCIDENT ID": "Incident 46", "TITLE": "Nest Smoke Alarm Erroneously Stops Alarming", "DESCRIPTION": "In testing, Google Nest engineers demonstrated that the Nest Wave feature of their Nest Protect: Smoke + CO Alarm could inadvertently silence genuine alarms.", "DATE": "2014-01-21", "ALLEGED DEPLOYER OF AI SYSTEM": "Nest Labs", "ALLEGED DEVELOPER OF AI SYSTEM": "Nest Labs", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Fire Victims"}
{"INCIDENT ID": "Incident 36", "TITLE": "Picture of Woman on Side of Bus Shamed for Jaywalking", "DESCRIPTION": "Facial recognition system in China mistakes celebrity's face on moving billboard for jaywalker", "DATE": "2018-11-06", "ALLEGED DEPLOYER OF AI SYSTEM": "Ningbo traffic police", "ALLEGED DEVELOPER OF AI SYSTEM": "Ningbo traffic police", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Dong Mingzhu"}
{"INCIDENT ID": "Incident 42", "TITLE": "Inefficiencies in the United States Resident Matching Program", "DESCRIPTION": "Alvin Roth, a Ph.D at the University of Pittsburgh, describes the National Resident Matching Program (NRMP) and suggests future changes that are needed in the algorithm used to match recently graduated medical students to their residency programs.", "DATE": "1996-04-03", "ALLEGED DEPLOYER OF AI SYSTEM": "National Resident Matching Program", "ALLEGED DEVELOPER OF AI SYSTEM": "National Resident Matching Program", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Medical Residents"}
{"INCIDENT ID": "Incident 58", "TITLE": "Russian Chatbot Supports Stalin and Violence", "DESCRIPTION": "Yandex, a Russian technology company, released an artificially intelligent chat bot named Alice which began to reply to questions with racist, pro-stalin, and pro-violence responses", "DATE": "2017-10-12", "ALLEGED DEPLOYER OF AI SYSTEM": "Yandex", "ALLEGED DEVELOPER OF AI SYSTEM": "Yandex", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Yandex Users"}
{"INCIDENT ID": "Incident 61", "TITLE": "Overfit Kaggle Models Discouraged Data Science Competitors", "DESCRIPTION": "In the \u201cThe Nature Conservancy Fisheries Monitoring\u201d competition on the data science competition website Kaggle, a number of competitors overfit their image classifier models to a poorly representative validation data set.", "DATE": "2017-05-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Individual Kaggle Competitors", "ALLEGED DEVELOPER OF AI SYSTEM": "Individual Kaggle Competitors", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Individual Kaggle Competitors"}
{"INCIDENT ID": "Incident 70", "TITLE": "Self-driving cars in winter", "DESCRIPTION": "Volvo autonomous driving XC90 SUV's experienced issues in Jokkmokk, Sweden when sensors used for automated driving iced over during the winter, rendering them useless.", "DATE": "2016-02-10", "ALLEGED DEPLOYER OF AI SYSTEM": "Volvo", "ALLEGED DEVELOPER OF AI SYSTEM": "Volvo", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "drivers in Jokkmokk, drivers in Sweden, Volvo"}
{"INCIDENT ID": "Incident 59", "TITLE": "Gender Biases in Google Translate", "DESCRIPTION": "A Cornell University study in 2016 highlighted Google Translate's pattern of assigning gender to occupations in a way showing an implicit gender bias against women.", "DATE": "2017-04-13", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Women"}
{"INCIDENT ID": "Incident 62", "TITLE": "Bad AI-Written Christmas Carols", "DESCRIPTION": "Janelle Shane, an AI research scientist, used 240 popular Christmas carols to train a neural network to write its own carols. This incident has been downgraded to an issue as it does not meet current ingestion criteria.", "DATE": "2017-12-23", "ALLEGED DEPLOYER OF AI SYSTEM": "Janelle Shane", "ALLEGED DEVELOPER OF AI SYSTEM": "Janelle Shane", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Carollers"}
{"INCIDENT ID": "Incident 51", "TITLE": "Security Robot Rolls Over Child in Mall", "DESCRIPTION": "On July 7, 2016, a Knightscope K5 autonomous security robot collided with a 16-month old boy while patrolling the Stanford Shopping Center in Palo Alto, CA.", "DATE": "2016-07-12", "ALLEGED DEPLOYER OF AI SYSTEM": "Stanford Shopping Center", "ALLEGED DEVELOPER OF AI SYSTEM": "Knightscope", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Child"}
{"INCIDENT ID": "Incident 53", "TITLE": "Biased Google Image Results", "DESCRIPTION": "On June 6, 2016, Google image searches of \"three black teenagers\" resulted in mostly mugshot images whereas Google image searchers of \"three white teenagers\" consisted of mostly stock images, suggesting a racial bias in Google's algorithm.", "DATE": "2016-03-31", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Minority Groups"}
{"INCIDENT ID": "Incident 69", "TITLE": "Worker killed by robot in welding accident at car parts factory in India", "DESCRIPTION": "A factory robot at the SKH Metals Factory in Manesar, India pierced and killed 24-year-old worker Ramji Lal when Lal reached behind the machine to dislodge a piece of metal stuck in the machine.", "DATE": "2015-07-02", "ALLEGED DEPLOYER OF AI SYSTEM": "SKH Metals", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Ramji Lal"}
{"INCIDENT ID": "Incident 49", "TITLE": "AI Beauty Judge Did Not Like Dark Skin", "DESCRIPTION": "In 2016, after artificial inntelligence software Beauty.AI judged an international beauty contest and declared a majority of winners to be white, researchers found that Beauty.AI was racially biased in determining beauty.", "DATE": "2016-09-05", "ALLEGED DEPLOYER OF AI SYSTEM": "Youth Laboratories", "ALLEGED DEVELOPER OF AI SYSTEM": "Youth Laboratories", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "People with Dark Skin"}
{"INCIDENT ID": "Incident 64", "TITLE": "Customer Service Robot Scares Away Customers", "DESCRIPTION": "Heriot-Watt Univeristy in Scotland developed an artificially intelligent grocery store robot, Fabio, who provided unhelpful answers to customer's questions and \"scared away\" multiple customers, according to the grocery store Margiotta.", "DATE": "2018-01-22", "ALLEGED DEPLOYER OF AI SYSTEM": "Heriot-Watt University, Margiotta", "ALLEGED DEVELOPER OF AI SYSTEM": "Heriot-Watt University", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Store Patrons"}
{"INCIDENT ID": "Incident 67", "TITLE": "Sleeping Driver on Tesla AutoPilot", "DESCRIPTION": "A Tesla Model S remained on autopilot while being operated by a drunk, sleeping operator whose hands were not on the wheel. The police had to slow the car down by slowing in front of the vehicle to activate its 'driver assist' feature .", "DATE": "2018-12-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla, Motorist", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Motorists"}
{"INCIDENT ID": "Incident 60", "TITLE": "FaceApp Racial Filters", "DESCRIPTION": "FaceApp is criticized for offering racist filters.", "DATE": "2017-04-25", "ALLEGED DEPLOYER OF AI SYSTEM": "FaceApp", "ALLEGED DEVELOPER OF AI SYSTEM": "FaceApp", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Minority Groups"}
{"INCIDENT ID": "Incident 54", "TITLE": "Predictive Policing Biases of PredPol", "DESCRIPTION": "Predictive policing algorithms meant to aid law enforcement by predicting future crime show signs of biased output.", "DATE": "2015-11-18", "ALLEGED DEPLOYER OF AI SYSTEM": "PredPol, Oakland Police Department", "ALLEGED DEVELOPER OF AI SYSTEM": "PredPol", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Oakland Residents"}
{"INCIDENT ID": "Incident 68", "TITLE": "Security Robot Drowns Itself in a Fountain", "DESCRIPTION": "A Knightscope K5 security robot ran itself into a water fountain in Washington, DC.", "DATE": "2017-07-17", "ALLEGED DEPLOYER OF AI SYSTEM": "Knightscope", "ALLEGED DEVELOPER OF AI SYSTEM": "Knightscope", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Knightscope"}
{"INCIDENT ID": "Incident 52", "TITLE": "Tesla on AutoPilot Killed Driver in Crash in Florida while Watching Movie", "DESCRIPTION": "A Tesla Model S on autopilot crashed into a white articulated tractor-trailer on Highway US 27A in Williston, Florida, killing the driver.", "DATE": "2016-07-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Joshua Brown"}
{"INCIDENT ID": "Incident 63", "TITLE": "Google Photo Merge Decapitates Subject", "DESCRIPTION": "Google Photos' AI Assistant created a strange hybrid photograph when merging three different pictures from a ski trip.", "DATE": "2018-01-25", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Alex Harker"}
{"INCIDENT ID": "Incident 56", "TITLE": "AI-Designed Phone Cases Are Unexpected", "DESCRIPTION": "A third-party Amazon merchant named \u201cmy_handy_design\u201d was suspected of using a bot to generate cell phone case designs based on the bizarre and unattractive designs being offered.", "DATE": "2017-07-10", "ALLEGED DEPLOYER OF AI SYSTEM": "my_handy_design", "ALLEGED DEVELOPER OF AI SYSTEM": "my_handy_design", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "my_handy_design"}
{"INCIDENT ID": "Incident 57", "TITLE": "Australian Automated Debt Assessment System Issued False Notices to Thousands", "DESCRIPTION": "Australian Department of Human Services (DHS)\u2019s automated debt assessment system issued false or incorrect debt notices to hundreds of thousands of people, resulting in years-long lawsuits and damages to welfare recipients.", "DATE": "2015-07-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Australian Department of Human Services", "ALLEGED DEVELOPER OF AI SYSTEM": "Centrelink", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Australian welfare recipients"}
{"INCIDENT ID": "Incident 65", "TITLE": "Reinforcement Learning Reward Functions in Video Games", "DESCRIPTION": "OpenAI published a post about its findings when using Universe, a software for measuring and training AI agents to conduct reinforcement learning experiments, showing that the AI agent did not act in the way intended to complete a videogame.", "DATE": "2016-12-22", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "OpenAI"}
{"INCIDENT ID": "Incident 50", "TITLE": "The DAO Hack", "DESCRIPTION": "On June 18, 2016, an attacker successfully exploited a vulnerability in The Decentralized Autonomous Organization (The DAO) on the Ethereum blockchain to steal 3.7M Ether valued at $70M.", "DATE": "2016-06-17", "ALLEGED DEPLOYER OF AI SYSTEM": "The DAO", "ALLEGED DEVELOPER OF AI SYSTEM": "The DAO", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "DAO Token Holders"}
{"INCIDENT ID": "Incident 71", "TITLE": "Google admits its self driving car got it wrong: Bus crash was caused by software", "DESCRIPTION": "On February 14, 2016, a Google autonomous test vehicle partially responsible for a low-speed collision with a bus on El Camino Real in Google\u2019s hometown of Mountain View, CA.", "DATE": "2016-09-26", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Mountain View municipal bus passengers, Mountain View municipal bus"}
{"INCIDENT ID": "Incident 55", "TITLE": "Alexa Plays Pornography Instead of Kids Song", "DESCRIPTION": "An Amazon Echo Dot using the Amazon Alex software started to play pornographic results when a child asked it to play a song.", "DATE": "2016-12-30", "ALLEGED DEPLOYER OF AI SYSTEM": "Amazon", "ALLEGED DEVELOPER OF AI SYSTEM": "Amazon", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Children"}
{"INCIDENT ID": "Incident 66", "TITLE": "Chinese Chatbots Question Communist Party", "DESCRIPTION": "Chatbots on Chinese messaging service expressed anti-China sentiments, causing the messaging service to remove and reprogram the chatbots.", "DATE": "2017-08-02", "ALLEGED DEPLOYER OF AI SYSTEM": "Tencent Holdings", "ALLEGED DEVELOPER OF AI SYSTEM": "Microsoft, Turing Robot", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Chinese Communist Party, Tencent Holdings, Microsoft, Turing Robot"}
{"INCIDENT ID": "Incident 72", "TITLE": "Facebook translates 'good morning' into 'attack them', leading to arrest", "DESCRIPTION": "Facebook's automatic language translation software incorrectly translated an Arabic post saying \"Good morning\" into Hebrew saying \"hurt them,\" leading to the arrest of a Palestinian man in Beitar Illit, Israel.", "DATE": "2017-10-17", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "unnamed Palestinian Facebook user, Palestinian Facebook users, Arabic-speaking Facebook users, Facebook users"}
{"INCIDENT ID": "Incident 84", "TITLE": "Tiny Changes Let False Claims About COVID-19, Voting Evade Facebook Fact Checks", "DESCRIPTION": "Avaaz, an international advocacy group, released a review of Facebook's misinformation identifying software showing that the labeling process failed to label 42% of false information posts, most surrounding COVID-19 and the 2020 USA Presidential Election.", "DATE": "2020-10-09", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Facebook users, Facebook users interested in COVID information, Facebook users interested in the US Presidential Election"}
{"INCIDENT ID": "Incident 78", "TITLE": "Meet the Secret Algorithm That's Keeping Students Out of College", "DESCRIPTION": "In response to the Covid-19 pandemic, the International Baccalaureate final exams were replaced by a calculated score, prompting complaints of unfairness from teachers and students.", "DATE": "2020-07-06", "ALLEGED DEPLOYER OF AI SYSTEM": "International Baccalaurette", "ALLEGED DEVELOPER OF AI SYSTEM": "International Baccalaurette", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "International Baccalaureate students"}
{"INCIDENT ID": "Incident 88", "TITLE": "\"Jewish Baby Strollers\" Provided Anti-Semitic Google Images, Allegedly Resulting from Hate Speech Campaign", "DESCRIPTION": "Google's Image search for \"Jewish baby strollers\" showed offensive, anti-Semitic results, allegedly a result of a coordinated hate-speech campaign involving malicious actors on 4chan.", "DATE": "2017-08-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Jewish people, Google Images users"}
{"INCIDENT ID": "Incident 73", "TITLE": "Is Pok\u00e9mon Go racist? How the app may be redlining communities of color", "DESCRIPTION": "Through a crowdsourcing social media campaign in 2016, several journalists and researchers demonstrated that augmented reality locations in the popular smartphone game Pokemon Go were more likely to be in white neighborhoods.", "DATE": "2016-03-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Niantic Labs", "ALLEGED DEVELOPER OF AI SYSTEM": "Niantic Labs", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "non-white neighborhoods, communities of color"}
{"INCIDENT ID": "Incident 75", "TITLE": "Google Instant's Allegedly 'Anti-Semitic' Results Lead To Lawsuit In France", "DESCRIPTION": "The organizations SOS Racisme, Union of Jewish Students of France, Movement Against Racism and for Friendship Among Peoples are suing Google due to its autocomplete software suggesting \"jewish\" when the names of certain public figures were searched on the platform.", "DATE": "2012-01-05", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Jewish people, Jewish public figures"}
{"INCIDENT ID": "Incident 81", "TITLE": "Researchers find evidence of racial, gender, and socioeconomic bias in chest X-ray classifiers", "DESCRIPTION": "A study by the University of Toronto, the Vector Institute, and MIT showed the input databases that trained AI systems used to classify chest X-rays led the systems to show gender, socioeconomic, and racial biases.", "DATE": "2020-10-21", "ALLEGED DEPLOYER OF AI SYSTEM": "Mount Sinai Hospitals", "ALLEGED DEVELOPER OF AI SYSTEM": "Google, Qure.ai, Aidoc, DarwinAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "patients of minority groups, low-income patients, female patients, Hispanic patients, patients with Medicaid insurance"}
{"INCIDENT ID": "Incident 86", "TITLE": "Coding Errors in Leaving Certificate Grading Algorithm Caused Inaccurate Scores in Ireland", "DESCRIPTION": "Errors in Irish Department of Education's algorithm to calculate students\u2019 Leaving Certificate exam grades resulted in thousands of inaccurate scores.", "DATE": "2020-10-08", "ALLEGED DEPLOYER OF AI SYSTEM": "Irish Department of Education and Skills", "ALLEGED DEVELOPER OF AI SYSTEM": "Irish Department of Education and Skills", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Leaving Certificate exam takers, Irish Department of Education and Skills"}
{"INCIDENT ID": "Incident 74", "TITLE": "Detroit Police Wrongfully Arrested Black Man Due To Faulty FRT", "DESCRIPTION": "A Black man was wrongfully detained by the Detroit Police Department as a result of a false facial recognition (FRT) result..", "DATE": "2020-01-30", "ALLEGED DEPLOYER OF AI SYSTEM": "Detroit Police Department", "ALLEGED DEVELOPER OF AI SYSTEM": "DataWorks Plus", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Robert Julian-Borchak Williams, Black people in Detroit"}
{"INCIDENT ID": "Incident 95", "TITLE": "Job Screening Service Halts Facial Analysis of Applicants", "DESCRIPTION": "In January 2021, HireVue removed the controversial AI expression tracking tool from its virtual job interview software.", "DATE": "2019-11-06", "ALLEGED DEPLOYER OF AI SYSTEM": "HireVue", "ALLEGED DEVELOPER OF AI SYSTEM": "HireVue", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "job applicants using HireVue, HireVue customers"}
{"INCIDENT ID": "Incident 97", "TITLE": "Tesla Autopilot Mistakes Red Letters on Flag for Red Traffic Lights", "DESCRIPTION": "A Tesla Model 3 misidentified flags with \"COOP\" written vertically on them as traffic lights.", "DATE": "2020-10-22", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Tesla drivers"}
{"INCIDENT ID": "Incident 98", "TITLE": "N.Y.P.D. Robot Dog\u2019s Run Is Cut Short After Fierce Backlash", "DESCRIPTION": "The New York Police Department canceled a contract to use Boston Dynamics' robotic dog Spot following public backlash.", "DATE": "2021-04-28", "ALLEGED DEPLOYER OF AI SYSTEM": "New York City Police Department", "ALLEGED DEVELOPER OF AI SYSTEM": "Boston Dynamics", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "New York City low-income communities"}
{"INCIDENT ID": "Incident 91", "TITLE": "Frontline workers protest at Stanford after hospital distributed vaccine to administrators", "DESCRIPTION": "In 2020, Stanford Medical Center's distribution algorithm only designated 7 of 5,000 vaccines to Medical Residents, who are frontline workers regularly exposed to COVID-19.", "DATE": "2020-12-18", "ALLEGED DEPLOYER OF AI SYSTEM": "Stanford Medical Center", "ALLEGED DEVELOPER OF AI SYSTEM": "Stanford Medical Center", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Stanford Medical frontline workers, Stanford Medical residents"}
{"INCIDENT ID": "Incident 76", "TITLE": "Live facial recognition is tracking kids suspected of being criminals", "DESCRIPTION": "Buenos Aires city government uses a facial recognition system that has led to numerous false arrests.", "DATE": "2020-10-09", "ALLEGED DEPLOYER OF AI SYSTEM": "Buenos Aires city government", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Buenos Aires children"}
{"INCIDENT ID": "Incident 89", "TITLE": "The Christchurch shooter and YouTube\u2019s radicalization trap", "DESCRIPTION": "A New Zealand government report released following a right-wing terrorist killing 51 worshippers at two New Sealand mosques which indicated that Youtube's recommendation algorithm played an important role in the terrorist's radicalization.", "DATE": "2019-03-15", "ALLEGED DEPLOYER OF AI SYSTEM": "YouTube", "ALLEGED DEVELOPER OF AI SYSTEM": "YouTube", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "YouTube users"}
{"INCIDENT ID": "Incident 82", "TITLE": "#LekkiMassacre: Why Facebook labelled content from October 20 incident \u2018false\u2019", "DESCRIPTION": "Facebook incorrectly labels content relating to an incident between #EndSARS protestors and the Nigerian army as misinformation.", "DATE": "2020-10-21", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Facebook users, Facebook users interested in the Lekki Massacre incident"}
{"INCIDENT ID": "Incident 93", "TITLE": "HUD charges Facebook with enabling housing discrimination", "DESCRIPTION": "In March 2019 the U.S. Department of Housing and Urban Development charged Facebook with violating the Fair Housing Act by allowing real estate sellers to target advertisements in a discriminatory manner.", "DATE": "2018-08-13", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Facebook users of minority groups, non-American-born Facebook users, non-Christian Facebook users, Facebook users interested in accessibility, Facebook users interested in Hispanic culture"}
{"INCIDENT ID": "Incident 85", "TITLE": "AI attempts to ease fear of robots, blurts out it can\u2019t \u2018avoid destroying humankind\u2019", "DESCRIPTION": "On September 8, 2020, the Guardian published an op-ed generated by OpenAI\u2019s GPT-3 text generating AI that included threats to destroy humankind. This incident has been downgraded to an issue as it does not meet current ingestion criteria.", "DATE": "2020-10-09", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "unknown"}
{"INCIDENT ID": "Incident 77", "TITLE": "Knightscope's Park Patrol Robot Ignored Bystander Pressing Emergency Button to Alert Police about Fight", "DESCRIPTION": "A Knightscope K5 autonomous \"police\" robot patrolling Huntington Park, California failed to respond to an onlooker who attempted to activate its emergency alert button when a nearby fight broke out.", "DATE": "2019-10-04", "ALLEGED DEPLOYER OF AI SYSTEM": "Knightscope", "ALLEGED DEVELOPER OF AI SYSTEM": "Knightscope", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Cogo Guebara, unnamed woman injured in the fight"}
{"INCIDENT ID": "Incident 96", "TITLE": "Houston Schools Must Face Teacher Evaluation Lawsuit", "DESCRIPTION": "On May 4, 2017, a U.S. federal judge advanced teachers\u2019 claims that the Houston Independent School District\u2019s algorithmic teacher evaluations violated their due process rights to their jobs by not allowing them to review the grounds of their termination.", "DATE": "2017-05-08", "ALLEGED DEPLOYER OF AI SYSTEM": "Houston Independent School District", "ALLEGED DEVELOPER OF AI SYSTEM": "SAS Institute", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Houston Independent School District teachers"}
{"INCIDENT ID": "Incident 80", "TITLE": "AI mistakes referee\u2019s bald head for football \u2014 hilarity ensued", "DESCRIPTION": "In a Scottish soccer match the AI-enabled ball-tracking camera used to livestream the game repeatedly tracked an official\u2019s bald head as though it were the soccer ball.", "DATE": "2020-10-24", "ALLEGED DEPLOYER OF AI SYSTEM": "Inverness Caledonian Thistle Football Club", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "livestream viewers"}
{"INCIDENT ID": "Incident 83", "TITLE": "Spam filters are efficient and uncontroversial. Until you look at them.", "DESCRIPTION": "Gmail, Yahoo, Outlook, GMX, and LaPoste email inbox sites showed racial and content-based biases when AlgorithmWatch tested their spam box filtering algorithms.", "DATE": "2020-10-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Gmail, Outlook, Yahoo, GMX, LaPoste", "ALLEGED DEVELOPER OF AI SYSTEM": "Gmail, Outlook, Yahoo, GMX, LaPoste", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "email users"}
{"INCIDENT ID": "Incident 79", "TITLE": "Kidney Testing Method Allegedly Underestimated Risk of Black Patients", "DESCRIPTION": "Decades-long use of the estimated glomerular filtration rate (eGFR) method to test kidney function which considers race has been criticized by physicians and medical students for its racist history and inaccuracy against Black patients.", "DATE": "1999-03-16", "ALLEGED DEPLOYER OF AI SYSTEM": "Chronic Kidney Disease Epidemiology Collaboration", "ALLEGED DEVELOPER OF AI SYSTEM": "Chronic Kidney Disease Epidemiology Collaboration", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Black patients, African-American patients"}
{"INCIDENT ID": "Incident 87", "TITLE": "UK passport photo checker shows bias against dark-skinned women", "DESCRIPTION": "UK passport photo checker shows bias against dark-skinned women.", "DATE": "2020-10-07", "ALLEGED DEPLOYER OF AI SYSTEM": "UK Home Office", "ALLEGED DEVELOPER OF AI SYSTEM": "UK Home Office", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "dark-skinned people, dark-skinned women"}
{"INCIDENT ID": "Incident 92", "TITLE": "Apple Card's Credit Assessment Algorithm Allegedly Discriminated against Women", "DESCRIPTION": "Apple Card's credit assessment algorithm was reported by Goldman-Sachs customers to have shown gender bias, in which men received significantly higher credit limits than women with equal credit qualifications.", "DATE": "2019-11-11", "ALLEGED DEPLOYER OF AI SYSTEM": "Goldman-Sachs", "ALLEGED DEVELOPER OF AI SYSTEM": "Apple", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Apple Card female users, Apple Card female credit applicants"}
{"INCIDENT ID": "Incident 94", "TITLE": "Court Rules Deliveroo Used 'Discriminatory' Algorithm", "DESCRIPTION": "In December 2020, an Italian court ruled that Deliveroo\u2019s employee \u2018reliability\u2019 algorithm illegally discriminated against workers with legitimate reasons for cancelling shifts.", "DATE": "2020-11-27", "ALLEGED DEPLOYER OF AI SYSTEM": "Deliveroo", "ALLEGED DEVELOPER OF AI SYSTEM": "Deliveroo", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Deliveroo workers with legitimate reasons for cancelling shifts, Deliveroo workers"}
{"INCIDENT ID": "Incident 111", "TITLE": "Amazon Flex Drivers Allegedly Fired via Automated Employee Evaluations", "DESCRIPTION": "Amazon Flex's contract delivery drivers were dismissed using a minimally human-interfered automated employee performance evaluation based on indicators impacted by out-of-driver's-control factors and without having a chance to defend against or appeal the decision.", "DATE": "2015-09-25", "ALLEGED DEPLOYER OF AI SYSTEM": "Amazon Flex", "ALLEGED DEVELOPER OF AI SYSTEM": "Amazon", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Amazon Flex employees, Amazon Flex drivers"}
{"INCIDENT ID": "Incident 104", "TITLE": "California's Algorithm Considered ZIP Codes in Vaccine Distribution, Allegedly Excluding Low-Income Neighborhoods and Communities of Color", "DESCRIPTION": "California's vaccine-distribution algorithm used ZIP codes as opposed to census tracts in its decision-making, which critics said undermined equity and access for vulnerable communities who are largely low-income, underserved neighborhoods with low Healthy Places Index scores.", "DATE": "2021-02-12", "ALLEGED DEPLOYER OF AI SYSTEM": "California Department of Public Health", "ALLEGED DEVELOPER OF AI SYSTEM": "Blue Shield of California", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "California low-income neighborhoods, California communities of color"}
{"INCIDENT ID": "Incident 106", "TITLE": "Korean Chatbot Luda Made Offensive Remarks towards Minority Groups", "DESCRIPTION": "A Korean interactive chatbot was shown in screenshots to have used derogatory and bigoted language when asked about lesbians, Black people, and people with disabilities.", "DATE": "2020-12-23", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook Messenger", "ALLEGED DEVELOPER OF AI SYSTEM": "Scatter Lab", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Korean Facebook Messenger users, Korean people of gender minorities, Korean people with disabilities"}
{"INCIDENT ID": "Incident 115", "TITLE": "Genderify\u2019s AI to Predict a Person\u2019s Gender Revealed by Free API Users to Exhibit Bias", "DESCRIPTION": "A company's AI predicting a person's gender based on their name, email address, or username was reported by its users to show biased and inaccurate results.", "DATE": "2020-07-28", "ALLEGED DEPLOYER OF AI SYSTEM": "Genderify", "ALLEGED DEVELOPER OF AI SYSTEM": "Genderify", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Genderify customers, gender minority groups"}
{"INCIDENT ID": "Incident 105", "TITLE": "Tesla Model 3 on Autopilot Crashed into a Ford Explorer Pickup, Killing a Fifteen-Year-Old in California", "DESCRIPTION": "A Tesla Model 3 on Autopilot mode crashed into a pickup on a California freeway, where data and video from the company showed neither Autopilot nor the driver slowing the vehicle until seconds before the crash.", "DATE": "2019-08-24", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Jovani Maldonado, Benjamin Maldonado, California public"}
{"INCIDENT ID": "Incident 109", "TITLE": "PimEyes's Facial Recognition AI Allegedly Lacked Safeguards to Prevent Itself from Being Abused", "DESCRIPTION": "PimEyes offered its subscription-based AI service to anyone in the public to search for matching facial images across the internet, which critics said lacked public oversight and government rules to prevent itself from misuse such as stalking women.", "DATE": "2017-01-01", "ALLEGED DEPLOYER OF AI SYSTEM": "PimEyes", "ALLEGED DEVELOPER OF AI SYSTEM": "PimEyes", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "internet users"}
{"INCIDENT ID": "Incident 101", "TITLE": "Dutch Families Wrongfully Accused of Tax Fraud Due to Discriminatory Algorithm", "DESCRIPTION": "A childcare benefits system in the Netherlands falsely accused thousands of families of fraud, in part due to an algorithm that treated having a second nationality as a risk factor.", "DATE": "2018-09-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Dutch Tax Authority", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Dutch Tax Authority, Dutch families"}
{"INCIDENT ID": "Incident 103", "TITLE": "Twitter\u2019s Image Cropping Tool Allegedly Showed Gender and Racial Bias", "DESCRIPTION": "Twitter's photo cropping algorithm was revealed by researchers to favor white and women faces in photos containing multiple faces, prompting the company to stop its use on mobile platform.", "DATE": "2020-09-18", "ALLEGED DEPLOYER OF AI SYSTEM": "Twitter", "ALLEGED DEVELOPER OF AI SYSTEM": "Twitter", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Twitter Users, Twitter non-white users, Twitter non-male users"}
{"INCIDENT ID": "Incident 112", "TITLE": "Police Departments Reported ShotSpotter as Unreliable and Wasteful", "DESCRIPTION": "ShotSpotter algorithmic systems locating gunshots were reported by police departments for containing high false positive rates and wasting police resources, prompting discontinuation.", "DATE": "2012-10-09", "ALLEGED DEPLOYER OF AI SYSTEM": "Troy Police Department, Syracuse Police Department, San Francisco Police Department, San Antonio Police Department, New York City Police Department, Fall River Police Department, Chicago Police Department", "ALLEGED DEVELOPER OF AI SYSTEM": "ShotSpotter", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Troy residents, Troy Police Department, Syracuse residents, Syracuse Police Department, San Francisco residents, San Francisco Police Department, San Antonio residents, San Antonio Police Department, New York City residents, New York City Police Department, Fall River residents, Fall River Police Department, Chicago Residents, Chicago Police Department"}
{"INCIDENT ID": "Incident 100", "TITLE": "How French welfare services are creating \u2018robo-debt\u2019", "DESCRIPTION": "A French welfare office using software to automatically evaluate cases incorrectly notified a woman receiving benefits that she owed \u20ac542.", "DATE": "2021-03-17", "ALLEGED DEPLOYER OF AI SYSTEM": "French Welfare Offices", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Lucie Inland"}
{"INCIDENT ID": "Incident 116", "TITLE": "Amazon's AI Cameras Incorrectly Penalized Delivery Drivers for Mistakes They Did Not Make", "DESCRIPTION": "Amazon's automated performance evaluation system involving AI-powered cameras incorrectly punished delivery drivers for non-existent mistakes, impacting their chances for bonuses and rewards.", "DATE": "2021-09-20", "ALLEGED DEPLOYER OF AI SYSTEM": "Amazon", "ALLEGED DEVELOPER OF AI SYSTEM": "Netradyne", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Amazon delivery drivers, Amazon workers"}
{"INCIDENT ID": "Incident 120", "TITLE": "Philosophy AI Allegedly Used To Generate Mixture of Innocent and Harmful Reddit Posts", "DESCRIPTION": "Philosopher AI, a GPT-3-powered controversial text generator, was allegedly used by an anonymous actor on AskReddit subreddit, whose posts featured a mixture of harmless stories, conspiracy theories, and sensitive topic discussions.", "DATE": "2020-09-01", "ALLEGED DEPLOYER OF AI SYSTEM": "unknown", "ALLEGED DEVELOPER OF AI SYSTEM": "Murat Ayfer, OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Reddit users"}
{"INCIDENT ID": "Incident 110", "TITLE": "Arkansas's Opaque Algorithm to Allocate Health Care Excessively Cut Down Hours for Beneficiaries", "DESCRIPTION": "Beneficiaries of the Arkansas Department of Human Services (DHS)'s Medicaid waiver program were allocated excessively fewer hours of caretaker visit via an algorithm deployed to boost efficiency, which reportedly contained errors and whose outputs varied wildly despite small input changes.", "DATE": "2016-01-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Arkansas Department of Human Services", "ALLEGED DEVELOPER OF AI SYSTEM": "InterRAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Arkansas Medicaid waiver program beneficiaries, Arkansas healthcare workers"}
{"INCIDENT ID": "Incident 108", "TITLE": "Skating Rink\u2019s Facial Recognition Cameras Misidentified Black Teenager as Banned Troublemaker", "DESCRIPTION": "A Black teenager living in Livonia, Michigan was incorrectly stopped from entering a roller skating rink after its facial-recognition cameras misidentified her as another person who had been previously banned for starting a skirmish with other skaters.", "DATE": "2021-07-10", "ALLEGED DEPLOYER OF AI SYSTEM": "Riverside Arena Skating Rink", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Lamya Robinson, Black Livonia residents"}
{"INCIDENT ID": "Incident 114", "TITLE": "Amazon's Rekognition Falsely Matched Members of Congress to Mugshots", "DESCRIPTION": "Rekognition's face comparison feature was shown by the ACLU to have misidentified members of congress, and particularly members of colors, as other people who have been arrested using a mugshot database built on publicly available arrest photos.", "DATE": "2018-07-26", "ALLEGED DEPLOYER OF AI SYSTEM": "Amazon", "ALLEGED DEVELOPER OF AI SYSTEM": "Amazon", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Rekognition users, arrested people"}
{"INCIDENT ID": "Incident 107", "TITLE": "Chinese Tech Firms Allegedly Developed Facial Recognition to Identify People by Race, Targeting Uyghur Muslims", "DESCRIPTION": "Various Chinese firms were revealed by patent applications to have developed facial recognition capable of detecting people by race, which critics feared would enable persecution and discrimination of Uyghur Muslims.", "DATE": "2018-07-20", "ALLEGED DEPLOYER OF AI SYSTEM": "none", "ALLEGED DEVELOPER OF AI SYSTEM": "Huawei, Megvii, SenseTime, Alibaba, Baibu", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Uyghur people"}
{"INCIDENT ID": "Incident 119", "TITLE": "Xsolla Employees Fired by CEO Allegedly via Big Data Analytics of Work Activities", "DESCRIPTION": "Xsolla CEO fired more than a hundred employees from his company in Perm, Russia, based on big data analysis of their remote digitized-work activity, which critics said was violating employee's privacy, outdated, and extremely ineffective.", "DATE": "2021-08-03", "ALLEGED DEPLOYER OF AI SYSTEM": "Xsolla", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Xsolla employees"}
{"INCIDENT ID": "Incident 99", "TITLE": "Major Universities Are Using Race as a \u201cHigh Impact Predictor\u201d of Student Success", "DESCRIPTION": "Several major universities are using a tool that uses race as one factor to predict student success.", "DATE": "2012-01-01", "ALLEGED DEPLOYER OF AI SYSTEM": "University of Massachusetts Amherst, University of Wisconsin\u2013Milwaukee, University of Houston, Texas A&M University, Georgia State University, more than 500 colleges", "ALLEGED DEVELOPER OF AI SYSTEM": "EAB", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Black college students, Latinx college students, indigenous students"}
{"INCIDENT ID": "Incident 121", "TITLE": "Autonomous Kargu-2 Drone Allegedly Remotely Used to Hunt down Libyan Soldiers", "DESCRIPTION": "In Libya, a Turkish-made Kargu-2 aerial drone powered by a computer vision model was allegedly used remotely by forces backed by the Tripoli-based government to track down and attack enemies as they were running from rocket attacks.", "DATE": "2020-03-27", "ALLEGED DEPLOYER OF AI SYSTEM": "Tripoli-based government", "ALLEGED DEVELOPER OF AI SYSTEM": "STM", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Libyan soldiers"}
{"INCIDENT ID": "Incident 113", "TITLE": "Facebook's AI Put \"Primates\" Label on Video Featuring Black Men", "DESCRIPTION": "Facebook's AI mislabeled video featuring Black men as a video about \"primates,\" resulting in an offensive prompt message for users who watched the video.", "DATE": "2020-06-27", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Black people, Facebook users"}
{"INCIDENT ID": "Incident 122", "TITLE": "Facebook\u2019s \"Tag Suggestions\" Allegedly Stored Biometric Data without User Consent", "DESCRIPTION": "Facebook\u2019s initial version of the its Tag Suggestions feature where users were offered suggestions about the identity of people's faces in photos allegedly stored biometric data without consent, violating the Illinois Biometric Information Privacy Act.", "DATE": "2015-06-14", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Facebook users"}
{"INCIDENT ID": "Incident 102", "TITLE": "Personal voice assistants struggle with black voices, new study shows", "DESCRIPTION": "A study found that voice recognition tools from Apple, Amazon, Google, IBM, and Microsoft disproportionately made errors when transcribing black speakers.", "DATE": "2020-03-23", "ALLEGED DEPLOYER OF AI SYSTEM": "Microsoft, IBM, Google, Apple, Amazon", "ALLEGED DEVELOPER OF AI SYSTEM": "Microsoft, IBM, Google, Apple, Amazon", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Black people"}
{"INCIDENT ID": "Incident 118", "TITLE": "OpenAI's GPT-3 Associated Muslims with Violence", "DESCRIPTION": "Users and researchers revealed generative AI GPT-3 associating Muslims to violence in prompts, resulting in disturbingly racist and explicit outputs such as casting Muslim actor as a terrorist.", "DATE": "2020-08-06", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Muslims"}
{"INCIDENT ID": "Incident 140", "TITLE": "ProctorU\u2019s Identity Verification and Exam Monitoring Systems Provided Allegedly Discriminatory Experiences for BIPOC Students", "DESCRIPTION": "An exam monitoring service used by the University of Toronto was alleged by its students to have provided discriminatory check-in experiences via its facial recognition's failure to verify passport photo, disproportionately enhancing disadvantaging stress level for BIPOC students.", "DATE": "2020-06-01", "ALLEGED DEPLOYER OF AI SYSTEM": "University of Toronto", "ALLEGED DEVELOPER OF AI SYSTEM": "ProctorU", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "University of Toronto BIPOC students"}
{"INCIDENT ID": "Incident 137", "TITLE": "Israeli Tax Authority Employed Opaque Algorithm to Impose Fines, Reportedly Refusing to Provide an Explanation for Amount Calculation to a Farmer", "DESCRIPTION": "An Israeli farmer was imposed a computer generated fine by the tax authority, who allegedly were not able to explain its calculation, and refused to disclose the program and its source code.", "DATE": "2021-01-11", "ALLEGED DEPLOYER OF AI SYSTEM": "Israeli Tax Authority", "ALLEGED DEVELOPER OF AI SYSTEM": "Israeli Tax Authority", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Moshe Har Shemesh, Israeli people having tax fines"}
{"INCIDENT ID": "Incident 148", "TITLE": "Web Accessibility Vendors Allegedly Falsely Claimed to Provide Compliance Using AI", "DESCRIPTION": "AI-powered web accessibility vendors allegedly overstated to customers about their products' utility for people with disabilities, falsely claiming to deliver automated compliance solutions.", "DATE": "2021-11-21", "ALLEGED DEPLOYER OF AI SYSTEM": "accessiBe, Accessus.ai, Allyable, UserWay, MaxAccess.io", "ALLEGED DEVELOPER OF AI SYSTEM": "accessiBe, Accessus.ai, Allyable, UserWay, MaxAccess.io", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "internet users with disabilities, web accessibility vendors' customers"}
{"INCIDENT ID": "Incident 164", "TITLE": "Facebook \"News Feed\" Allegedly Boosted Misinformation and Violating Content Following Use of MSI Metric", "DESCRIPTION": "After the \u201cNews Feed\u201d algorithm had been overhauled to boost engagement between friends and family in early 2018, its heavy weighting of re-shared content was alleged found by company researchers to have pushed content creators to reorient their posts towards outrage and sensationalism, causing a proliferation of misinformation, toxicity, and violent content.", "DATE": "2018-10-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Facebook users, Facebook content creators"}
{"INCIDENT ID": "Incident 131", "TITLE": "Proctoring Algorithm in Online California Bar Exam Flagged an Unusually High Number of Alleged Cheaters", "DESCRIPTION": "The proctoring algorithm used in a California bar exam cited a third of thousands of applicants as cheaters, resulting in allegations where exam takers were instructed to prove otherwise without seeing their incriminating video evidence.", "DATE": "2020-12-04", "ALLEGED DEPLOYER OF AI SYSTEM": "California Bar\u2019s Committee of Bar Examiners", "ALLEGED DEVELOPER OF AI SYSTEM": "ExamSoft", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "California bar exam takers, flagged California bar exam takers"}
{"INCIDENT ID": "Incident 153", "TITLE": "Tesla Driver on Autopilot Ran a Red Light, Crashing into a Car and Killing Two People in Los Angeles", "DESCRIPTION": "In 2019, a Tesla Model S driver on Autopilot mode reportedly went through a red light and crashed into a Honda Civic, killing two people in Gardena, Los Angeles.", "DATE": "2019-12-29", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Gilberto Alcazar Lopez, Maria Guadalupe Nieves-Lopez"}
{"INCIDENT ID": "Incident 125", "TITLE": "Amazon\u2019s Robotic Fulfillment Centers Have Higher Serious Injury Rates", "DESCRIPTION": "Amazon\u2019s robotic fulfillment centers have higher serious injury rates.", "DATE": "2020-09-29", "ALLEGED DEPLOYER OF AI SYSTEM": "Amazon", "ALLEGED DEVELOPER OF AI SYSTEM": "Amazon", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Amazon fulfillment center workers"}
{"INCIDENT ID": "Incident 138", "TITLE": "Alleged Issues with Proctorio's Remote-Testing AI Prompted Suspension by University", "DESCRIPTION": "Proctorio's remote-testing software were reported by students at the University of Illinois Urbana-Champaign for issues regarding privacy, accessibility, differential performance on darker-skinned students.", "DATE": "2020-01-21", "ALLEGED DEPLOYER OF AI SYSTEM": "University of Illinois", "ALLEGED DEVELOPER OF AI SYSTEM": "Proctorio", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "University of Illinois students of color, University of Illinois students"}
{"INCIDENT ID": "Incident 132", "TITLE": "TikTok\u2019s Content Moderation Allegedly Failed to Adequately Take down Videos Promoting Eating Disorders", "DESCRIPTION": "Videos promoting eating disorders evaded TikTok's automated violation detection system without difficulty via common misspellings of search terms, bypassing its ban of violating hashtags such as \"proana\" and \"anorexia\".", "DATE": "2020-12-27", "ALLEGED DEPLOYER OF AI SYSTEM": "TikTok", "ALLEGED DEVELOPER OF AI SYSTEM": "TikTok", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "TikTok users, TikTok users under 18 years old"}
{"INCIDENT ID": "Incident 117", "TITLE": "TikTok's \"Suggested Accounts\" Algorithm Allegedly Reinforced Racial Bias through Feedback Loops", "DESCRIPTION": "TikTok's \"Suggested Accounts\" recommendations allegedly reinforced racial bias despite not basing recommendations on race or creators' profile photo.", "DATE": "2020-02-24", "ALLEGED DEPLOYER OF AI SYSTEM": "TikTok", "ALLEGED DEVELOPER OF AI SYSTEM": "TikTok", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "TikTok users, TikTok content creators"}
{"INCIDENT ID": "Incident 129", "TITLE": "Facebook's Automated Tools Failed to Adequately Remove Hate Speech, Violence, and Incitement", "DESCRIPTION": "Facebook's automated moderation tools were shown by internal documents performing incomparably to human moderators, and accounting for only a small fraction of hate speech, violence, and incitement content removal.", "DATE": "2021-03-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Facebook users"}
{"INCIDENT ID": "Incident 146", "TITLE": "Research Prototype AI, Delphi, Reportedly Gave Racially Biased Answers on Ethics", "DESCRIPTION": "A publicly accessible research model that was trained via Reddit threads showed racially biased advice on moral dilemmas, allegedly demonstrating limitations of language-based models trained on moral judgments.", "DATE": "2021-10-22", "ALLEGED DEPLOYER OF AI SYSTEM": "Allen Institute for AI", "ALLEGED DEVELOPER OF AI SYSTEM": "Allen Institute for AI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Minority Groups"}
{"INCIDENT ID": "Incident 144", "TITLE": "YouTube's AI Mistakenly Banned Chess Channel over Chess Language Misinterpretation", "DESCRIPTION": "YouTube's AI-powered hate speech detection system falsely flagged chess content and banned chess creators allegedly due to its misinterpretation of strategy language such as \"black,\" \"white,\" and \"attack\" as harmful and dangerous.", "DATE": "2020-06-28", "ALLEGED DEPLOYER OF AI SYSTEM": "YouTube", "ALLEGED DEVELOPER OF AI SYSTEM": "YouTube", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Antonio Radic, YouTube chess content creators, YouTube users"}
{"INCIDENT ID": "Incident 160", "TITLE": "Alexa Recommended Dangerous TikTok Challenge to Ten-Year-Old Girl", "DESCRIPTION": "Amazon\u2019s voice assistant Alexa suggested \u201cthe penny challenge,\u201d which involves dangerously touching a coin to the prongs of a half-exposed plug, when a ten-year-old girl asked for a challenge to do.", "DATE": "2021-12-26", "ALLEGED DEPLOYER OF AI SYSTEM": "Amazon", "ALLEGED DEVELOPER OF AI SYSTEM": "Amazon", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Kristin Livdahl's daughter, Amazon Echo customers, children using Alexa"}
{"INCIDENT ID": "Incident 152", "TITLE": "SoftBank's Humanoid Robot, Pepper, Reportedly Frequently Made Errors, Prompting Dismissal", "DESCRIPTION": "SoftBank's robot allegedly kept making mechanical errors, taking unplanned breaks, failing to recognize previously-met people, and breaking down during practice runs.", "DATE": "2021-07-13", "ALLEGED DEPLOYER OF AI SYSTEM": "SoftBank", "ALLEGED DEVELOPER OF AI SYSTEM": "Aldebaran, SoftBank Robotics", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "SoftBank"}
{"INCIDENT ID": "Incident 161", "TITLE": "Facebook's Ad Delivery Reportedly Excluded Audience along Racial and Gender Lines", "DESCRIPTION": "Facebook's housing and employment ad delivery process allegedly resulted in skews in exposure for some users along demographic lines such as gender and racial identity.", "DATE": "2019-04-03", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "female Facebook users, Black Facebook users, male Facebook users"}
{"INCIDENT ID": "Incident 168", "TITLE": "Collaborative Filtering Prone to Popularity Bias, Resulting in Overrepresentation of Popular Items in the Recommendation Outputs", "DESCRIPTION": "Collaborative filtering prone to popularity bias, resulting in overrepresentation of popular items in the recommendation outputs.", "DATE": "2022-03-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook, LinkedIn, YouTube, Twitter, Netflix", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook, LinkedIn, YouTube, Twitter, Netflix", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Facebook users, LinkedIn users, YouTube users, Twitter Users, Netflix users"}
{"INCIDENT ID": "Incident 133", "TITLE": "Online Trolls Allegedly Abused TikTok\u2019s Automated Content Reporting System to Discriminate against Marginalized Creators", "DESCRIPTION": "TikTok's automated content reporting system was allegedly abused by online trolls to intentionally misreport content created by users of marginalized groups.", "DATE": "2020-12-15", "ALLEGED DEPLOYER OF AI SYSTEM": "TikTok", "ALLEGED DEVELOPER OF AI SYSTEM": "TikTok", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "TikTok content creators of marginalized groups"}
{"INCIDENT ID": "Incident 145", "TITLE": "Tesla's Autopilot Misidentified the Moon as Yellow Stop Light", "DESCRIPTION": "Tesla's Autopilot was shown on video by its owner mistaking the moon for a yellow stop light, allegedly causing the vehicle to keep slowing down.", "DATE": "2021-07-23", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Tesla drivers"}
{"INCIDENT ID": "Incident 141", "TITLE": "California Police Turned on Music to Allegedly Trigger Instagram\u2019s DCMA to Avoid Being Live-Streamed", "DESCRIPTION": "A police officer in Beverly Hills played copyrighted music on his phone when realizing that his interactions were being recorded on a livestream, allegedly hoping the Instagram's automated copyright detection system to end or mute the stream.", "DATE": "2021-02-05", "ALLEGED DEPLOYER OF AI SYSTEM": "Instagram", "ALLEGED DEVELOPER OF AI SYSTEM": "Instagram", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Sennett Devermont, Beverly Hills citizens"}
{"INCIDENT ID": "Incident 134", "TITLE": "Robot in Chinese Shopping Mall Fell off the Escalator, Knocking down Passengers", "DESCRIPTION": "A shopping guide robot deployed by the Fuzhou Zhongfang Marlboro Mall was shown on video allegedly walking to the escalator by itself, falling down, and knocking over passengers, which prompted its suspension.", "DATE": "2020-12-25", "ALLEGED DEPLOYER OF AI SYSTEM": "Fuzhou Zhongfang Marlboro Mall", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Fuzhou Zhongfang Marlboro Mall goers"}
{"INCIDENT ID": "Incident 136", "TITLE": "Brand Safety Tech Firms Falsely Claimed Use of AI, Blocking Ads Using Simple Keyword Lists", "DESCRIPTION": "Brand safety tech firms falsely claimed use of AI, blocking ads using simple keyword lists.", "DATE": "2020-12-06", "ALLEGED DEPLOYER OF AI SYSTEM": "brand safety tech firms", "ALLEGED DEVELOPER OF AI SYSTEM": "none", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "news sites"}
{"INCIDENT ID": "Incident 135", "TITLE": "UT Austin GRADE Algorithm Allegedly Reinforced Historical Inequalities", "DESCRIPTION": "The University of Texas at Austin's Department of Computer Science's assistive algorithm to assess PhD applicants \"GRADE\" raised concerns among faculty about worsening historical inequalities for marginalized candidates, prompting its suspension.", "DATE": "2012-12-01", "ALLEGED DEPLOYER OF AI SYSTEM": "University of Texas at Austin's Department of Computer Science", "ALLEGED DEVELOPER OF AI SYSTEM": "University of Texas at Austin researchers", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "University of Texas at Austin PhD applicants of marginalized groups"}
{"INCIDENT ID": "Incident 155", "TITLE": "Google Maps Allegedly Directed Sierra Nevada Travelers to Dangerous Roads amid Winter Storm", "DESCRIPTION": "Lake Tahoe travelers were allegedly guided by Google Maps into hazardous shortcuts in the mountains during a snowstorm.", "DATE": "2021-12-27", "ALLEGED DEPLOYER OF AI SYSTEM": "Google Maps", "ALLEGED DEVELOPER OF AI SYSTEM": "Google Maps", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Google Maps users traveling in Sierra Nevada, Google Maps users traveling in the mountains"}
{"INCIDENT ID": "Incident 171", "TITLE": "Traffic Camera Misread Text on Pedestrian's Shirt as License Plate, Causing UK Officials to Issue Fine to an Unrelated Person", "DESCRIPTION": "A Bath resident was wrongly fined by the local officials because an automated license plate recognition camera misread the text on her shirt as a license plate number.", "DATE": "2021-10-18", "ALLEGED DEPLOYER OF AI SYSTEM": "Bath government", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Paula Knight, Bath officials, UK public"}
{"INCIDENT ID": "Incident 151", "TITLE": "California Regulator Suspended Pony.ai's Driverless Testing Permit Following a Non-Fatal Collision", "DESCRIPTION": "A Pony.ai vehicle operating in autonomous mode crashed into a center divider and a traffic sign in San Francisco, prompting a regulator to suspend the driverless testing permit for the startup.", "DATE": "2021-10-28", "ALLEGED DEPLOYER OF AI SYSTEM": "Pony.ai", "ALLEGED DEVELOPER OF AI SYSTEM": "Pony.ai", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "San Francisco city government"}
{"INCIDENT ID": "Incident 123", "TITLE": "Epic Systems\u2019s Sepsis Prediction Algorithms Revealed to Have High Error Rates on Seriously Ill Patients", "DESCRIPTION": "Epic System's sepsis prediction algorithms was shown by investigators at the University of Michigan Hospital to have high rates of false positives and false negatives, allegedly delivering inaccurate and irrelevant information on patients, contrasting sharply with their published claims.", "DATE": "2021-08-01", "ALLEGED DEPLOYER OF AI SYSTEM": "University of Michigan Hospital", "ALLEGED DEVELOPER OF AI SYSTEM": "Epic Systems", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "sepsis patients"}
{"INCIDENT ID": "Incident 156", "TITLE": "Amazon Reportedly Sold Products and Recommended Frequently Bought Together Items That Aid Suicide Attempts", "DESCRIPTION": "Despite complaints notifying Amazon about the sale of various products that had been used to aid suicide attempts, its recommendation system reportedly continued selling them and suggesting their frequently bought-together items.", "DATE": "2022-02-04", "ALLEGED DEPLOYER OF AI SYSTEM": "Amazon", "ALLEGED DEVELOPER OF AI SYSTEM": "Amazon", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "people attempting suicides"}
{"INCIDENT ID": "Incident 143", "TITLE": "Facebook\u2019s and Twitter's Automated Content Moderation Reportedly Failed to Effectively Enforce Violation Rules for Small Language Groups", "DESCRIPTION": "Facebook's and Twitter were not able to sufficiently moderate content of small language groups such as the Balkan languages using AI, allegedly due to the lack of investment in human moderation and difficulty in AI-solution design for the languages.", "DATE": "2021-02-16", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook, Twitter", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook, Twitter", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Facebook users of small language groups, Twitter users of small language groups"}
{"INCIDENT ID": "Incident 157", "TITLE": "Amazon's Monitoring System Allegedly Pushed Delivery Drivers to Prioritize Speed over Safety, Leading to Crash", "DESCRIPTION": "A lawsuit cited Amazon as liable in a crash involving its delivery driver, alleging that Amazon\u2019s AI-powered driver monitoring system pushed drivers to prioritize speed over safety.", "DATE": "2021-03-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Amazon", "ALLEGED DEVELOPER OF AI SYSTEM": "Amazon", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Amazon workers, Amazon delivery drivers"}
{"INCIDENT ID": "Incident 170", "TITLE": "Target Suggested Maternity-Related Advertisements to a Teenage Girl's Home, Allegedly Correctly Predicting Her Pregnancy via Algorithm", "DESCRIPTION": "Target recommended maternity-related items to a family in Atlanta via ads, allegedly predicting their teenage daughter\u2019s pregnancy before her father did, although critics have called into question the predictability of the algorithm and the authenticity of its claims.", "DATE": "2003-06-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Target", "ALLEGED DEVELOPER OF AI SYSTEM": "Target", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Target customers"}
{"INCIDENT ID": "Incident 139", "TITLE": "Amazon\u2019s Search and Recommendation Algorithms Found by Auditors to Have Boosted Products That Contained Vaccine Misinformation", "DESCRIPTION": "Evidence of the \"filter-bubble effect\" were found by vaccine-misinformation researchers in Amazon's recommendations, where its algorithms presented users who performed actions on misinformative products with more misinfomative products.", "DATE": "2021-01-21", "ALLEGED DEPLOYER OF AI SYSTEM": "Amazon", "ALLEGED DEVELOPER OF AI SYSTEM": "Amazon", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Amazon Customers"}
{"INCIDENT ID": "Incident 142", "TITLE": "Facebook\u2019s Advertisement Moderation System Routinely Misidentified Adaptive Fashion Products as Medical Equipment and Blocked Their Sellers", "DESCRIPTION": "Facebook platforms' automated ad moderation system falsely classified adaptive fashion products as medical and health care products and services, resulting in regular bans and appeals faced by their retailers.", "DATE": "2021-02-11", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook, Instagram", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook, Instagram", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Facebook users of disabilities, adaptive fashion retailers"}
{"INCIDENT ID": "Incident 147", "TITLE": "Hong Kong Bank Manager Swindled by Fraudsters Using Deepfaked Voice of Company Director", "DESCRIPTION": "In early 2020, fraudsters reportedly allegedly deepfaked the voice of a company's director, demanding a bank manager in Hong Kong to authorize a $35M transfer.", "DATE": "2020-01-01", "ALLEGED DEPLOYER OF AI SYSTEM": "scammers", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Hong Kong bank manager"}
{"INCIDENT ID": "Incident 154", "TITLE": "Justice Department\u2019s Recidivism Risk Algorithm PATTERN Allegedly Caused Persistent Disparities Along Racial Lines", "DESCRIPTION": "Department of Justice\u2019s inmate-recidivism risk assessment tool was reported to have produced racially uneven results, misclassifying risk levels for inmates of color.", "DATE": "2022-01-26", "ALLEGED DEPLOYER OF AI SYSTEM": "US Department of Justice", "ALLEGED DEVELOPER OF AI SYSTEM": "US Department of Justice", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "inmates of color"}
{"INCIDENT ID": "Incident 165", "TITLE": "Image Upscaling Algorithm PULSE Allegedly Produced Facial Images with Caucasian Features More Often", "DESCRIPTION": "Image upscaling tool PULSE powered by NVIDIA's StyleGAN reportedly generated faces with Caucasian features more often, although AI academics, engineers, and researchers were not in agreement about where the source of bias was.", "DATE": "2020-06-20", "ALLEGED DEPLOYER OF AI SYSTEM": "Duke researchers", "ALLEGED DEVELOPER OF AI SYSTEM": "Duke researchers", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "people having non-Caucasian facial features"}
{"INCIDENT ID": "Incident 149", "TITLE": "Zillow Shut Down Zillow Offers Division Allegedly Due to Predictive Pricing Tool's Insufficient Accuracy", "DESCRIPTION": "Zillow's AI-powered predictive pricing tool Zestimate was allegedly not able to accurately forecast housing prices three to six months in advance due to rapid market changes, prompting division shutdown and layoff of a few thousand employees.", "DATE": "2021-11-02", "ALLEGED DEPLOYER OF AI SYSTEM": "Zillow", "ALLEGED DEVELOPER OF AI SYSTEM": "Zillow Offers", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Zillow Offers staff, Zillow"}
{"INCIDENT ID": "Incident 124", "TITLE": "Algorithmic Health Risk Scores Underestimated Black Patients\u2019 Needs", "DESCRIPTION": "Optum's algorithm deployed by a large academic hospital was revealed by researchers to have under-predicted the health needs of black patients, effectively de-prioritizing them in extra care programs relative to white patients with the same health burden.", "DATE": "2019-10-24", "ALLEGED DEPLOYER OF AI SYSTEM": "unnamed large academic hospital", "ALLEGED DEVELOPER OF AI SYSTEM": "Optum", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Black patients"}
{"INCIDENT ID": "Incident 159", "TITLE": "Tesla Autopilot\u2019s Lane Recognition Allegedly Vulnerable to Adversarial Attacks", "DESCRIPTION": "Tencent Keen Security Lab conducted security research into Tesla\u2019s Autopilot system and identified crafted adversarial samples and remote controlling via wireless gamepad as vulnerabilities to its system, although the company called into question their real-world practicality. This incident has been downgraded to an issue as it does not meet current ingestion criteria.", "DATE": "2019-03-29", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Tesla drivers"}
{"INCIDENT ID": "Incident 167", "TITLE": "Researchers' Homosexual-Men Detection Model Denounced as a Threat to LGBTQ People\u2019s Safety and Privacy", "DESCRIPTION": "Researchers at Stanford Graduate School of Business developed a model that determined, on a binary scale, whether someone was homosexual using only his facial image, which advocacy groups such as GLAAD and the Human Rights Campaign denounced as flawed science and threatening to LGBTQ folks.", "DATE": "2017-09-07", "ALLEGED DEPLOYER OF AI SYSTEM": "Michal Kosinski, Yilun Wang", "ALLEGED DEVELOPER OF AI SYSTEM": "Michal Kosinski, Yilun Wang", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "LGBTQ people, LGBTQ people of color, non-American LGBTQ people"}
{"INCIDENT ID": "Incident 127", "TITLE": "Microsoft\u2019s Algorithm Allegedly Selected Photo of the Wrong Mixed-Race Person Featured in a News Story", "DESCRIPTION": "A news story published on MSN.com featured a photo of the wrong mixed-race person that was allegedly selected by an algorithm, following Microsoft\u2019s layoff and replacement of journalists and editorial workers at its organizations with AI systems.", "DATE": "2020-06-06", "ALLEGED DEPLOYER OF AI SYSTEM": "Microsoft, MSN.com", "ALLEGED DEVELOPER OF AI SYSTEM": "Microsoft", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Jade Thirlwall, Leigh-Anne Pinnock"}
{"INCIDENT ID": "Incident 163", "TITLE": "Facebook\u2019s Hate Speech Detection Algorithms Allegedly Disproportionately Failed to Remove Racist Content towards Minority Groups", "DESCRIPTION": "Facebook\u2019s hate-speech detection algorithms was found by company researchers to have under-reported less common but more harmful content that was more often experienced by minority groups such as Black, Muslim, LGBTQ, and Jewish users.", "DATE": "2021-11-21", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Facebook users of minority groups, Facebook users"}
{"INCIDENT ID": "Incident 162", "TITLE": "ETS Used Allegedly Flawed Voice Recognition Evidence to Accuse and Assess Scale of Cheating, Causing Thousands to be Deported from the UK", "DESCRIPTION": "International testing organization ETS admits voice recognition as evidence of cheating for thousands of previous TOEIC test-takers that reportedly included wrongfully accused people, causing them to be deported without an appeal process or seeing their incriminating evidence.", "DATE": "2014-01-01", "ALLEGED DEPLOYER OF AI SYSTEM": "ETS", "ALLEGED DEVELOPER OF AI SYSTEM": "ETS", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "UK ETS past test takers, UK ETS test takers, UK Home Office"}
{"INCIDENT ID": "Incident 150", "TITLE": "Swedish Contraceptive App, Natural Cycles, Allegedly Failed to Correctly Map Menstrual Cycle", "DESCRIPTION": "Some women using the contraceptive app, Natural Cycles, reported unwanted pregnancies, revealing its algorithm's difficulties in mapping menstrual cycles.", "DATE": "2018-07-21", "ALLEGED DEPLOYER OF AI SYSTEM": "Natural Cycles", "ALLEGED DEVELOPER OF AI SYSTEM": "Natural Cycles", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Natural Cycles users, Women"}
{"INCIDENT ID": "Incident 169", "TITLE": "Facebook Allegedly Failed to Police Anti-Rohingya Hate Speech Content That Contributed to Violence in Myanmar", "DESCRIPTION": "Facebook allegedly did not adequately remove anti-Rohingya hate speech, some of which was extremely violent and dehumanizing, on its platform, contributing to the violence faced by Rohingya communities in Myanmar.", "DATE": "2018-08-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook, Meta", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook, Meta", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Rohingya people, Rohingya Facebook users, Myanmar public, Facebook users in Myanmar, Burmese-speaking Facebook users"}
{"INCIDENT ID": "Incident 126", "TITLE": "Three Robots Collided, Sparking Fire in a Grocer's Warehouse in UK", "DESCRIPTION": "A collision involving three robots at an Ocado's warehouse in Erith, UK, resulting in a fire but no reports of injuries.", "DATE": "2021-07-16", "ALLEGED DEPLOYER OF AI SYSTEM": "Ocado", "ALLEGED DEVELOPER OF AI SYSTEM": "Ocado", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Ocado"}
{"INCIDENT ID": "Incident 128", "TITLE": "Tesla Sedan on Autopilot Reportedly Drove Over Dividing Curb in Washington, Resulting in Minor Vehicle Damage", "DESCRIPTION": "A Tesla Sedan operating on Autopilot mode was not able to center itself on the road and drove over a yellow dividing curb in Redmond, Washington, causing minor damage to the vehicle\u2019s rear suspension.", "DATE": "2017-08-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Eric Horvitz, Tesla drivers"}
{"INCIDENT ID": "Incident 158", "TITLE": "Facial Recognition in Remote Learning Software Reportedly Failed to Recognize a Black Student\u2019s Face", "DESCRIPTION": "A Black student's face was not recognized by the remote-proctoring software during check-in of a lab quiz, causing her to excessively change her environments for it to work as intended.", "DATE": "2021-02-01", "ALLEGED DEPLOYER OF AI SYSTEM": "unknown", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Amaya Ross, Black students, Black test-takers"}
{"INCIDENT ID": "Incident 176", "TITLE": "Starship\u2019s Autonomous Food Delivery Robot Allegedly Stranded at Railroad Crossing in Oregon, Run over by Freight Train", "DESCRIPTION": "A Starship food delivery robot deployed by Oregon State University reportedly failed to cross the railroad, becoming stranded, and ending up being struck by an oncoming freight train.", "DATE": "2022-03-02", "ALLEGED DEPLOYER OF AI SYSTEM": "Oregon State University", "ALLEGED DEVELOPER OF AI SYSTEM": "Starship Technologies", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Oregon State University, freight train crew"}
{"INCIDENT ID": "Incident 184", "TITLE": "Facial Recognition Program in S\u00e3o Paulo Metro Stations Suspended for Illegal and Disproportionate Violation of Citizens\u2019 Right to Privacy", "DESCRIPTION": "A facial recognition program rolled out by S\u00e3o Paulo Metro Stations was suspended following a court ruling in response to a lawsuit by civil society organizations, who cited fear of it being integrated with other electronic surveillance entities without consent, and lack of transparency about the biometric data collection process of metro users.", "DATE": "2018-04-12", "ALLEGED DEPLOYER OF AI SYSTEM": "Companhia do Metropolitano de S\u00e3o Paulo", "ALLEGED DEVELOPER OF AI SYSTEM": "SecurOS", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "S\u00e3o Paulo Metro users, S\u00e3o Paulo citizens"}
{"INCIDENT ID": "Incident 195", "TITLE": "Predictive Policing Program by Florida Sheriff\u2019s Office Allegedly Violated Residents\u2019 Rights and Targeted Children of Vulnerable Groups", "DESCRIPTION": "The Intelligence-Led Policing model rolled out by the Pasco County Sheriff\u2019s Office was allegedly developed based on flawed science and biased data that also contained sensitive information and irrelevant attributes about students, which critics said to be discriminatory.", "DATE": "2015-09-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Pasco Sheriff's Office", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Pasco residents, Pasco Black students, Pasco students with disabilities"}
{"INCIDENT ID": "Incident 213", "TITLE": "Facebook\u2019s Political Ad Detection Reportedly Showed High and Geographically Uneven Error Rates", "DESCRIPTION": "The performance of Facebook\u2019s political ad detection was revealed by researchers to be imprecise, uneven across countries in errors, and inadequate for preventing systematic violations of political advertising policies.", "DATE": "2020-07-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Facebook users"}
{"INCIDENT ID": "Incident 174", "TITLE": "Fake LinkedIn Profiles Created Using GAN Photos", "DESCRIPTION": "More than a thousand inauthentic LinkedIn profiles using allegedly GAN-generated photos were notified by researchers at Stanford to LinkedIn\u2019s staff, and many of which were removed for violating rules against creating fake profiles and falsifying information.", "DATE": "2022-02-28", "ALLEGED DEPLOYER OF AI SYSTEM": "unknown", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "LinkedIn users"}
{"INCIDENT ID": "Incident 180", "TITLE": "Algorithm Used by the Malaysian Judiciary Reportedly Recommended Unusually High Sentencing to a Drug Possession Case", "DESCRIPTION": "The AI system used by the Malaysian judiciary which explicitly considered age, employment, and socio-economic data provided sentencing to a drug possession case that was alleged by lawyer to be disproportionately high for the crime committed.", "DATE": "2020-02-19", "ALLEGED DEPLOYER OF AI SYSTEM": "Malaysian judiciary, Malaysian courts", "ALLEGED DEVELOPER OF AI SYSTEM": "Sarawak Information Systems", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Malaysian convicted people"}
{"INCIDENT ID": "Incident 194", "TITLE": "Australian Telco\u2019s Incident Management Bot Excessively Sent Technicians in the Field by Mistake, Allegedly Costing Millions", "DESCRIPTION": "In early 2018, an Australian telecommunications company\u2019s incident management AI excessively deployed technicians into the field, and was allegedly unable to be stopped by the automation team.", "DATE": "2018-02-01", "ALLEGED DEPLOYER OF AI SYSTEM": "unnamed Australian telecommunications company", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "unnamed Australian telecommunications company"}
{"INCIDENT ID": "Incident 206", "TITLE": "Tinder's Personalized Pricing Algorithm Found to Offer Higher Prices for Older Users", "DESCRIPTION": "Tinder\u2019s personalized pricing was found by Consumers International to consider age as a major determinant of pricing, and could be considered a direct discrimination based on age, according to anti-discrimination law experts.", "DATE": "2015-03-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Tinder", "ALLEGED DEVELOPER OF AI SYSTEM": "Tinder", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Tinder users over 30 years old"}
{"INCIDENT ID": "Incident 202", "TITLE": "Korean Politician Employed Deepfake as Campaign Representative", "DESCRIPTION": "A South Korean political candidate created a deepfake avatar which political opponents alleged to be fraudulent and a threat to democracy.", "DATE": "2021-12-06", "ALLEGED DEPLOYER OF AI SYSTEM": "Yoon Suk-yeol, Yoon Suk-yeol's campaign", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Korean public"}
{"INCIDENT ID": "Incident 216", "TITLE": "WeChat\u2019s Machine Translation Gave a Racist English Translation for the Chinese Term for \u201cBlack Foreigner\u201d", "DESCRIPTION": "The Chinese platform WeChat provided an inappropriate and racist English translation for the Chinese term for \u201cblack foreigner\u201d in its messaging app.", "DATE": "2017-10-10", "ALLEGED DEPLOYER OF AI SYSTEM": "WeChat", "ALLEGED DEVELOPER OF AI SYSTEM": "WeChat", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Black WeChat users"}
{"INCIDENT ID": "Incident 181", "TITLE": "BMW Sedan Made a Prohibited Left Turn, Colliding with a Cruise Autonomous Vehicle", "DESCRIPTION": "A BMW Sedan reportedly made an illegal left turn, causing a minor collision but no injuries with a Cruise autonomous vehicle (AV) operating in autonomous mode.", "DATE": "2022-02-11", "ALLEGED DEPLOYER OF AI SYSTEM": "Cruise", "ALLEGED DEVELOPER OF AI SYSTEM": "Cruise", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Cruise vehicle"}
{"INCIDENT ID": "Incident 166", "TITLE": "Networking Platform Giggle Employs AI to Determine Users\u2019 Gender, Allegedly Excluding Transgender Women", "DESCRIPTION": "A social networking platform, Giggle, allegedly collected, shared to third-parties, and used sensitive information and biometric data to verify whether a person is a woman via facial recognition, which critics claimed to be discriminatory against women of color and harmful towards trans women.", "DATE": "2020-02-07", "ALLEGED DEPLOYER OF AI SYSTEM": "Giggle", "ALLEGED DEVELOPER OF AI SYSTEM": "Kairos", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "trans women, women of color"}
{"INCIDENT ID": "Incident 182", "TITLE": "Two Cruise Autonomous Vehicles Collided with Each Other in California", "DESCRIPTION": "In San Francisco, an autonomous Cruise Chevrolet Bolt collided with another Cruise vehicle driven by a Cruise human employee, causing minor scuffs to the cars but no human injuries.", "DATE": "2018-06-11", "ALLEGED DEPLOYER OF AI SYSTEM": "Cruise", "ALLEGED DEVELOPER OF AI SYSTEM": "Cruise", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Cruise vehicles, Cruise driver employee"}
{"INCIDENT ID": "Incident 173", "TITLE": "AI Tools Failed to Sufficiently Predict COVID Patients, Some Potentially Harmful", "DESCRIPTION": "AI tools failed to sufficiently predict COVID patients, some potentially harmful.", "DATE": "2021-07-30", "ALLEGED DEPLOYER OF AI SYSTEM": "unknown", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Doctors, COVID patients"}
{"INCIDENT ID": "Incident 203", "TITLE": "Uber Launched Opaque Algorithm That Changes Drivers' Payments in the US", "DESCRIPTION": "Uber launched a new but opaque algorithm to determine drivers' pay in the US which allegedly caused drivers to experience lower fares, confusing fare drops, and a decrease in rides.", "DATE": "2022-02-10", "ALLEGED DEPLOYER OF AI SYSTEM": "Uber", "ALLEGED DEVELOPER OF AI SYSTEM": "Uber", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Uber drivers"}
{"INCIDENT ID": "Incident 198", "TITLE": "Deepfake Video of Ukrainian President Yielding to Russia Posted on Ukrainian Websites and Social Media", "DESCRIPTION": "A quickly-debunked deepfaked video of the Ukrainian President Volodymyr Zelenskyy was posted on various Ukrainian websites and social media platforms encouraging Ukrainians to surrender to Russian forces during the Russia-Ukraine war.", "DATE": "2022-03-16", "ALLEGED DEPLOYER OF AI SYSTEM": "hackers", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Volodymyr Zelenskyy, Ukrainian social media users, Ukrainian public"}
{"INCIDENT ID": "Incident 175", "TITLE": "Cruise Autonomous Taxi Allegedly Bolted off from Police After Being Pulled over in San Francisco", "DESCRIPTION": "An autonomous Chevy Bolt operated by Cruise was pulled over in San Francisco, and as the police attempted to engage with the car, it reportedly bolted off, pulled over again, and put on its hazards lights on at a point farther down the road.", "DATE": "2022-04-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Cruise", "ALLEGED DEVELOPER OF AI SYSTEM": "Cruise", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "San Francisco public, Cruise customers"}
{"INCIDENT ID": "Incident 178", "TITLE": "Tesla Owner Activated \"Smart Summon\" Feature, Causing a Collision with an Aircraft in a Washington Airport", "DESCRIPTION": "A Tesla Model Y was shown on video slowly crashing into a Vision Jet in Spokane, Washington, allegedly due to its owner activating the \u201cSmart Summon\u201d feature.", "DATE": "2022-04-21", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Tesla owner, Vision Jet owner"}
{"INCIDENT ID": "Incident 183", "TITLE": "Airbnb's Trustworthiness Algorithm Allegedly Banned Users without Explanation, and Discriminated against Sex Workers", "DESCRIPTION": "Airbnb allegedly considered publicly available data on users to gauge their trustworthiness via algorithmic assessment of personality and behavioral traits, resulting in unexplained bans and discriminatory bans against sex workers.", "DATE": "2017-07-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Airbnb", "ALLEGED DEVELOPER OF AI SYSTEM": "Airbnb, Trooly", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "sex workers, Airbnb users"}
{"INCIDENT ID": "Incident 220", "TITLE": "Facebook Mistakenly Blocked Small Business Ads", "DESCRIPTION": "Facebook\u2019s AI mistakenly blocked advertisements by small and struggling businesses, after the company allegedly leaned more on algorithms to monitor ads on the platform with little review from human moderators.", "DATE": "2020-11-11", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "small businesses on Facebook"}
{"INCIDENT ID": "Incident 200", "TITLE": "Fraudsters Used AI to Mimic Voice of a UK-Based Firm's CEO's Boss", "DESCRIPTION": "Fraudsters allegedly used AI voice technology to impersonate the boss of a UK-based firm's CEO, demanding a transfer of \u20ac220,000 over the phone.", "DATE": "2019-03-01", "ALLEGED DEPLOYER OF AI SYSTEM": "scammers", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "unnamed UK-based energy firm's CEO"}
{"INCIDENT ID": "Incident 186", "TITLE": "Algorithm Assessing Risk Faced by Victims of Gender Violence Misclassified Low-Risk Cases, Allegedly Leading to Homicide of Women and Children in Spain", "DESCRIPTION": "In Spain, the algorithm that assesses recidivism risk in gender violence, VioG\u00e9n, have critically underestimated the level of risk in a series of cases that ended in homicide of women and children since its first deployment.", "DATE": "2007-07-26", "ALLEGED DEPLOYER OF AI SYSTEM": "Spanish Ministry of Interior", "ALLEGED DEVELOPER OF AI SYSTEM": "Spanish Secretary of State for Security, Spanish Ministry of Interior", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Spanish victims of gender violence"}
{"INCIDENT ID": "Incident 221", "TITLE": "A Road Engineer Killed Following a Collision Involving a Tesla on Autopilot", "DESCRIPTION": "In Taiwan, a Tesla Model 3 on Autopilot mode whose driver did not pay attention to the road collided with a road repair truck; a road engineer immediately placed crash warnings in front of the Tesla, but soon after got hit and was killed by a BMW when its driver failed to see the sign and crashed into the accident.", "DATE": "2022-03-07", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "road engineer"}
{"INCIDENT ID": "Incident 179", "TITLE": "DALL-E 2 Reported for Gender and Racially Biased Outputs", "DESCRIPTION": "Developers of OpenAI's DALL-E 2 cited risks of the model, varying from misuse as disinformation and explicit content generation, to gender and racial bias.", "DATE": "2022-04-01", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "underrepresented groups, Minority Groups"}
{"INCIDENT ID": "Incident 172", "TITLE": "NarxCare\u2019s Risk Score Model Allegedly Lacked Validation and Trained on Data with High Risk of Bias", "DESCRIPTION": "NarxCare's overdose risk algorithm, lacking peer-reviewed validation, uses sensitive data like doctor visits, prescriptions, and possibly genetic information, leading to significant biases against women and Black patients. Factors like sexual abuse and criminal records exacerbate stigmas and disparities, often resulting in unjust denial of necessary pain medication. The newly approved AvertD genetic test shares similar issues, further complicating and potentially harming medical treatment decisions.", "DATE": "2020-07-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Appriss, NarxCare, AvertD", "ALLEGED DEVELOPER OF AI SYSTEM": "Appriss", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "American physicians, American pharmacists, American patients of minority groups, American patients"}
{"INCIDENT ID": "Incident 177", "TITLE": "Google\u2019s Assistive Writing Feature Provided Allegedly Unnecessary and Clumsy Suggestions", "DESCRIPTION": "Google\u2019s \u201cinclusive language\u201d feature prompting writers to consider alternatives to non-inclusive words reportedly also recommend alternatives for words such as \u201clandlord\u201d and \u201cmotherboard,\u201d which critics said was a form of obtrusive, unnecessary, and bias-reinforcing speech-policing.", "DATE": "2022-04-19", "ALLEGED DEPLOYER OF AI SYSTEM": "Google Docs", "ALLEGED DEVELOPER OF AI SYSTEM": "Google Docs", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Google Docs users"}
{"INCIDENT ID": "Incident 201", "TITLE": "Climate Action Group Posted Deepfake of Belgian Prime Minister Urging Climate Crisis Action", "DESCRIPTION": "A deepfake video showing the Belgium\u2019s prime minister speaking of an urgent need to tackle the climate crises was released by a climate action group.", "DATE": "2020-04-14", "ALLEGED DEPLOYER OF AI SYSTEM": "Extinction Rebellion Belgium", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Shophie Wilm\u00e8s, Belgian government"}
{"INCIDENT ID": "Incident 204", "TITLE": "A Chinese Tech Worker at Zhihu Fired Allegedly via a Resignation Risk Prediction Algorithm", "DESCRIPTION": "The firing of an employee at Zhihu, a large Q&A platform in China, was allegedly caused by the use of a behavioral perception algorithm which claimed to predict a worker\u2019s resignation risk using their online footprints, such as browsing history and internal communication.", "DATE": "2022-02-11", "ALLEGED DEPLOYER OF AI SYSTEM": "Zhihu", "ALLEGED DEVELOPER OF AI SYSTEM": "Sangfor Technologies", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Zhihu employees, Chinese tech workers"}
{"INCIDENT ID": "Incident 214", "TITLE": "SN Technologies Reportedly Lied to a New York State School District about Its Facial and Weapon Detection Systems\u2019 Performance", "DESCRIPTION": "SN Technologies allegedly misled Lockport City Schools about the performance of its AEGIS face and weapons detection systems, downplaying error rates for Black faces and weapon misidentification.", "DATE": "2020-01-02", "ALLEGED DEPLOYER OF AI SYSTEM": "Lockport City School District", "ALLEGED DEVELOPER OF AI SYSTEM": "SN Technologies", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Black students"}
{"INCIDENT ID": "Incident 217", "TITLE": "Robot at a Chinese Tech Fair Smashed a Glass Booth, Injuring a Visitor", "DESCRIPTION": "At the 18th China Hi-Tech Fair, a robot suddenly smashed through a glass booth and injured a visitor, after a staff member reportedly mistakenly pressed a button, causing it to reverse and accelerate.", "DATE": "2016-11-16", "ALLEGED DEPLOYER OF AI SYSTEM": "Evolver", "ALLEGED DEVELOPER OF AI SYSTEM": "Evolver", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "fair visitors"}
{"INCIDENT ID": "Incident 208", "TITLE": "Tesla Phantom Braking Complaints Surged, Allegedly Linked to Tesla Vision Rollout", "DESCRIPTION": "In late 2021, Tesla owners\u2019 complaints to the National Highway Traffic Safety Administration about sudden unexpected automatic braking rapidly increased, coinciding with when radar was no longer equipped in its Model 3 and Model Y vehicles.", "DATE": "2021-05-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Tesla drivers"}
{"INCIDENT ID": "Incident 193", "TITLE": "Excessive Automated Monitoring Alerts Ignored by Staff, Resulting in Private Data Theft of Seventy Million Target Customers", "DESCRIPTION": "Alerts about a Target data breach were ignored by Minneapolis Target\u2019s staff reportedly due to them being included with many other potential false alerts, and due to some of the company\u2019s network infiltration alerting systems being off to reduce such false alerts, causing private data theft for millions of customers.", "DATE": "2013-11-27", "ALLEGED DEPLOYER OF AI SYSTEM": "Target", "ALLEGED DEVELOPER OF AI SYSTEM": "FireEye", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Target, Target customers"}
{"INCIDENT ID": "Incident 185", "TITLE": "TikTok's \"For You\" Algorithm Directed New Users towards Disinformation about the War in Ukraine", "DESCRIPTION": "An investigation by NewsGuard into TikTok\u2019s handling of content related to the Russia-Ukraine war showed its \u201cFor You\u201d algorithm pushing new users towards false and misleading content about the war within less than an hour of signing up.", "DATE": "2022-03-01", "ALLEGED DEPLOYER OF AI SYSTEM": "TikTok", "ALLEGED DEVELOPER OF AI SYSTEM": "TikTok", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "TikTok users, TikTok new users"}
{"INCIDENT ID": "Incident 218", "TITLE": "Tesla on Autopilot Crashed into Flipped Truck on Taiwan Highway", "DESCRIPTION": "On a highway in Taiwan, a Tesla Sedan, reportedly operating on Autopilot mode, crashed into a large overturned truck, barely missing a pedestrian.", "DATE": "2020-06-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "delivery truck, pedestrians, Tesla drivers"}
{"INCIDENT ID": "Incident 197", "TITLE": "Facebook Internally Reported Failure of Ranking Algorithm, Exposing Harmful Content to Viewers over Months", "DESCRIPTION": "Facebook's internal report showed an at-least six-month long alleged software bug that caused moderator-flagged posts and other harmful content to evade down-ranking filters, leading to surges of misinformation on users' News Feed.", "DATE": "2021-10-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Facebook users"}
{"INCIDENT ID": "Incident 199", "TITLE": "Ever AI Reportedly Deceived Customers about FRT Use in App", "DESCRIPTION": "Ever AI, now Paravision AI, allegedly failed to inform customers about the development and use of facial recognition that facilitates the sale of customers\u2019 data to various businesses, a business model that critics said was an egregious violation of privacy.", "DATE": "2019-04-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Ever AI", "ALLEGED DEVELOPER OF AI SYSTEM": "Ever AI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Ever AI users"}
{"INCIDENT ID": "Incident 190", "TITLE": "ByteDance Allegedly Trained \"For You\" Algorithm Using Content Scraped without Consent from Other Social Platforms", "DESCRIPTION": "ByteDance allegedly scraped short-form videos, usernames, profile pictures, and descriptions of accounts on Instagram, Snapchat, and other sources, and uploaded them without consent on Flipagram, TikTok\u2019s predecessor, in order to improve its \u201cFor You\u201d algorithm's performance on American users.", "DATE": "2017-01-15", "ALLEGED DEPLOYER OF AI SYSTEM": "ByteDance", "ALLEGED DEVELOPER OF AI SYSTEM": "ByteDance", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Instagram users, Snapchat users, American social media users"}
{"INCIDENT ID": "Incident 188", "TITLE": "Argentinian City Government Deployed Teenage-Pregnancy Predictive Algorithm Using Invasive Demographic Data", "DESCRIPTION": "In 2018, during the abortion-decriminalization debate in Argentina, the Salta city government deployed a teenage-pregnancy predictive algorithm built by Microsoft that allegedly lacked a defined purpose, explicitly considered sensitive information such as disability and whether their home had access to hot water.", "DATE": "2018-04-11", "ALLEGED DEPLOYER OF AI SYSTEM": "Salta city government", "ALLEGED DEVELOPER OF AI SYSTEM": "Microsoft", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Salta teenage girls, Salta girls of minority groups"}
{"INCIDENT ID": "Incident 191", "TITLE": "Korean Internet Portal Giant Naver Manipulated Shopping and Video Search Algorithms to Favor In-House Services", "DESCRIPTION": "The Korean Fair Trade Commission (FTC) imposed a 26.7B KRW on Naver for manipulating shopping and video search algorithms, favoring its own online shopping business to boost its market share.", "DATE": "2020-10-06", "ALLEGED DEPLOYER OF AI SYSTEM": "Naver", "ALLEGED DEVELOPER OF AI SYSTEM": "Naver", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Naver customers"}
{"INCIDENT ID": "Incident 209", "TITLE": "Tesla Disabled \u201cRolling Stop\u201d Functionality Associated with the \u201cAggressive\u201d Driving Mode", "DESCRIPTION": "The \u201crolling stop\u201d functionality within the \u201cAggressive\u201d Full Self Driving (FSD) profile that was released via a Tesla firmware update was recalled and disabled.", "DATE": "2020-10-20", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Tesla drivers"}
{"INCIDENT ID": "Incident 219", "TITLE": "Poachers Evaded AI Cameras and Killed Four Rhinos", "DESCRIPTION": "AI cameras installed by Ezemvelo KZN Wildlife failed to detect poachers when four dehorned rhino carcasses were found.", "DATE": "2020-11-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Ezemvelo KZN Wildlife", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "rhinos in conservation"}
{"INCIDENT ID": "Incident 189", "TITLE": "Opaque Fraud Detection Algorithm by the UK\u2019s Department of Work and Pensions Allegedly Discriminated against People with Disabilities", "DESCRIPTION": "People with disabilities were allegedly disproportionately targeted by a benefit fraud detection algorithm which the UK\u2019s Department of Work and Pensions was urged to disclose.", "DATE": "2019-10-15", "ALLEGED DEPLOYER OF AI SYSTEM": "UK Department of Work and Pensions", "ALLEGED DEVELOPER OF AI SYSTEM": "UiPath", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "people with disabilities"}
{"INCIDENT ID": "Incident 215", "TITLE": "Facebook Content Moderators Demand Better Working Conditions Due to Allegedly Inadequate AI Content Moderation", "DESCRIPTION": "Content moderators and employees at Facebook demand better working conditions, as automated content moderation system allegedly failed to achieve sufficient performance and exposed human reviewers to psychologically hazardous content such as graphic violence and child abuse.", "DATE": "2020-04-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Facebook content moderators"}
{"INCIDENT ID": "Incident 192", "TITLE": "Three Make-Up Artists Lost Jobs Following Black-Box Automated Decision by HireVue", "DESCRIPTION": "Three make-up artists lost their positions following an algorithmically-assessed video interview by HireVue who reportedly failed to provide adequate explanation of the findings.", "DATE": "2022-03-17", "ALLEGED DEPLOYER OF AI SYSTEM": "Est\u00e9e Lauder", "ALLEGED DEVELOPER OF AI SYSTEM": "HireVue", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "pseudonymous Est\u00e9e Lauder's former staff"}
{"INCIDENT ID": "Incident 212", "TITLE": "XPeng Motors Fined For Illegal Collection of Consumers\u2019 Faces Using Facial Recognition Cameras", "DESCRIPTION": "The Chinese electric vehicle (EV) firm XPeng Motors was fined by local market regulators for illegally collecting in-store customers\u2019 facial images without their consent for six months.", "DATE": "2021-01-01", "ALLEGED DEPLOYER OF AI SYSTEM": "XPeng Motors", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "XPeng Motors customers"}
{"INCIDENT ID": "Incident 196", "TITLE": "Compromise of National Biometric ID Card System Leads to Reverification and Change of Status", "DESCRIPTION": "When the leader of the Afghan Taliban was found possessing a valid ID card in the Pakistani national biometric identification database system, Pakistan launch a national re-verification campaign that is linked to numerous changes in recognition status and loss of services.", "DATE": "2013-09-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Pakistan National Database and Registration Authority", "ALLEGED DEVELOPER OF AI SYSTEM": "Pakistan National Database and Registration Authority", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Pakistani citizens"}
{"INCIDENT ID": "Incident 207", "TITLE": "Hawaii Police Deployed Robot Dog to Patrol a Homeless Encampment", "DESCRIPTION": "Honolulu Police Department spent federal pandemic relief funds on a robot dog to take body temperatures and patrol a homeless quarantine encampment which local civil rights advocates criticized as dehumanizing.", "DATE": "2021-01-10", "ALLEGED DEPLOYER OF AI SYSTEM": "Honolulu Police Department", "ALLEGED DEVELOPER OF AI SYSTEM": "Boston Dynamics", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Honolulu homeless people"}
{"INCIDENT ID": "Incident 211", "TITLE": "A Tesla Taxi Cab Involved in an Accident in Paris with Twenty Injuries", "DESCRIPTION": "In Paris, about 20 people were injured in an accident involving a Tesla Model 3 taxi cab which was reportedly caused by a sudden unintended acceleration (SUA) episode and braking issues.", "DATE": "2021-12-11", "ALLEGED DEPLOYER OF AI SYSTEM": "Taxis G7", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "pedestrians"}
{"INCIDENT ID": "Incident 187", "TITLE": "YouTuber Tested Tesla on Self Driving Mode, Colliding with Street Pylons", "DESCRIPTION": "A YouTuber who was a Tesla\u2019s employee conducted an on-road review of Tesla's Full Self Driving (FSD) Beta, showing its navigation in various road environments in San Jose and collision with a bollards during Autopilot, allegedly causing his dismissal from the company.", "DATE": "2022-02-04", "ALLEGED DEPLOYER OF AI SYSTEM": "AI Addict", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "John Bernal, San Jose public"}
{"INCIDENT ID": "Incident 205", "TITLE": "AI-Generated Profiles Used in Disinformation Campaign Targeting Ukrainians", "DESCRIPTION": "According to security reports by Meta, fictitious personas with GAN-generated profile pictures were used by people operating in Russia and Ukraine to push a disinformation campaign targeting Ukrainian social media users, and were taken down.", "DATE": "2022-02-25", "ALLEGED DEPLOYER OF AI SYSTEM": "individuals in the Donbass region, individuals in Russia, media organizations in Crimea", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Ukrainian social media users"}
{"INCIDENT ID": "Incident 235", "TITLE": "Chinese Insurer Ping An Employed Facial Recognition to Determine Customers\u2019 Untrustworthiness, Which Critics Alleged to Likely Make Errors and Discriminate", "DESCRIPTION": "Customers\u2019 untrustworthiness and unprofitability were reportedly determined by Ping An, a large insurance company in China, via facial-recognition measurements of micro-expressions and body-mass indices (BMI), which critics argue was likely to make mistakes, discriminate against certain ethnic groups, and undermine its own industry.", "DATE": "2016-04-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Ping An", "ALLEGED DEVELOPER OF AI SYSTEM": "Ping An", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Ping An customers, Chinese minority groups"}
{"INCIDENT ID": "Incident 222", "TITLE": "Thoughts App Allegedly Created Toxic Tweets", "DESCRIPTION": "Tweets created by Thoughts, a tweet generation app that leverages OpenAI\u2019s GPT-3, allegedly exhibited toxicity when given prompts related to minority groups.", "DATE": "2020-07-18", "ALLEGED DEPLOYER OF AI SYSTEM": "Satria Technologies", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Thoughts users, Twitter Users"}
{"INCIDENT ID": "Incident 223", "TITLE": "Hive Box Facial-Recognition Locks Hacked by Fourth Graders Using Intended Recipient\u2019s Facial Photo", "DESCRIPTION": "Facial-recognition locks by Hive Box, an express delivery locker company in China, were easily opened by a group of fourth-graders in a science-club demo using only a printed photo of the intended recipient\u2019s face, leaving contents vulnerable to theft.", "DATE": "2019-10-09", "ALLEGED DEPLOYER OF AI SYSTEM": "Hive Box", "ALLEGED DEVELOPER OF AI SYSTEM": "Hive Box", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Hive Box customers"}
{"INCIDENT ID": "Incident 224", "TITLE": "WeChat Pay's Facial Recognition Security Evaded by Scammers Using Victims\u2019 Social Media Content", "DESCRIPTION": "In China, fraudsters bypassed facial-recognition security for online financial transactions on WeChat Pay by crafting identity-verification GIFs of victims from their selfies on WeChat Moments, a social media platform.", "DATE": "2020-07-01", "ALLEGED DEPLOYER OF AI SYSTEM": "WeChat Pay", "ALLEGED DEVELOPER OF AI SYSTEM": "WeChat", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "WeChat Pay users"}
{"INCIDENT ID": "Incident 239", "TITLE": "Algorithmic Teacher Evaluation Program Failed Student Outcome Goals and Allegedly Caused Harm Against Teachers", "DESCRIPTION": "Gates-Foundation-funded Intensive Partnerships for Effective Teaching Initiative\u2019s algorithmic program to assess teacher performance reportedly failed to achieve its goals for student outcomes, particularly for minority students, and was criticized for potentially causing harm against teachers.", "DATE": "2009-09-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Intensive Partnerships for Effective Teaching", "ALLEGED DEVELOPER OF AI SYSTEM": "Intensive Partnerships for Effective Teaching", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "students, low-income minority students, Teachers"}
{"INCIDENT ID": "Incident 225", "TITLE": "IBM Watson for Oncology Criticized by Customers for Allegedly Unsafe and Inaccurate Cancer Treatment Recommendations", "DESCRIPTION": "Internal documents from IBM Watson Health showed negative assessments from customers such as Florida\u2019s Jupiter Hospital and Memorial Sloan Kettering criticizing its Watson for Oncology product for allegedly unsafe and incorrect cancer treatment recommendations.", "DATE": "2017-04-07", "ALLEGED DEPLOYER OF AI SYSTEM": "Jupiter Hospital, Memorial Sloan Kettering", "ALLEGED DEVELOPER OF AI SYSTEM": "IBM Watson Health", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "oncologists, cancer patients"}
{"INCIDENT ID": "Incident 232", "TITLE": "Tesla Model X on Autopilot Missed Parked Vehicles and Pedestrians, Killing Motorcyclist in Japan", "DESCRIPTION": "A Tesla Model X operated on Autopilot reportedly failed to recognize the parked motorcycles, pedestrians, and van in its path in Kanagawa, Japan, and ran over a motorcyclist who previously stopped when a member of his motorcyclist group was involved in an accident.", "DATE": "2018-04-29", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Yoshihiro Umeda, pedestrians, Tesla drivers"}
{"INCIDENT ID": "Incident 242", "TITLE": "Manufacturing Robot Failure Caused Factory Worker's Death in India", "DESCRIPTION": "A sensor snag resulted in an automotive parts factory robot falling on a factory worker in India", "DATE": "2021-02-24", "ALLEGED DEPLOYER OF AI SYSTEM": "Chakan plant of Automotive Stampings and Assemblies", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Umesh Ramesh Dhake"}
{"INCIDENT ID": "Incident 230", "TITLE": "Model 3 Tesla on Autopilot Crashed into a Truck in Florida, Killing Driver", "DESCRIPTION": "In Florida, a Model 3 Tesla on Autopilot mode crashed into a tractor-trailer truck, killing the 50-year-old driver.", "DATE": "2019-03-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Jeremy Beren Banner, Tesla users"}
{"INCIDENT ID": "Incident 246", "TITLE": "Misreading of an Automated License Plate Reader (ALPR) Unverified by Police, Resulting in Traffic Stop in Missouri", "DESCRIPTION": "An automated license plate reader (ALPR) camera misread a 7 as a 2 and incorrectly alerted the local police about a stolen Oldsmobile car, which was allegedly not able to be verified by an officer before a traffic stop was effected on a BMW in Kansas City suburb.", "DATE": "2014-04-16", "ALLEGED DEPLOYER OF AI SYSTEM": "Prairie Village Police Department", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Mark Molner"}
{"INCIDENT ID": "Incident 231", "TITLE": "A Tesla Crashed into and Killed a Road Sweeper on a Highway in China", "DESCRIPTION": "A Tesla Model S collided with and killed a road sweeper on a highway near Handan, China, an accident where Tesla previously said it was not able to determine whether Autopilot was operating at the time of the crash.", "DATE": "2016-01-20", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Gao Yaning, Tesla drivers"}
{"INCIDENT ID": "Incident 248", "TITLE": "Automated License Plate Camera Notified Police about a Previously Stolen Rental Car that was Returned, Causing an Innocent Person to be Detained at Gunpoint in California", "DESCRIPTION": "In Oakland, a previously stolen rental car that was returned but allegedly not updated in the police database was pinged by an automated license plate reader (ALPR) camera, leading to police\u2019s wrongful detainment of an innocent person reportedly using excessive force and improper conduct.", "DATE": "2018-11-23", "ALLEGED DEPLOYER OF AI SYSTEM": "Contra Costa County Sheriff", "ALLEGED DEVELOPER OF AI SYSTEM": "Vigilant Solutions", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Brian Hofer"}
{"INCIDENT ID": "Incident 236", "TITLE": "AI-Generated Faces Used by Scammers to Pose as a Law Firm in Boston", "DESCRIPTION": "GAN faces were allegedly used by scammers alongside a parked domain and a fake website to impersonate a Boston law firm.", "DATE": "2022-04-13", "ALLEGED DEPLOYER OF AI SYSTEM": "scammers", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "email users"}
{"INCIDENT ID": "Incident 240", "TITLE": "GitHub Copilot, Copyright Infringement and Open Source Licensing", "DESCRIPTION": "Users of GitHub Copilot can produce source code subject to license requirements without attributing and licensing the code to the rights holder.", "DATE": "2021-06-29", "ALLEGED DEPLOYER OF AI SYSTEM": "GitHub, programmers", "ALLEGED DEVELOPER OF AI SYSTEM": "GitHub", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Intellectual Property rights holders"}
{"INCIDENT ID": "Incident 210", "TITLE": "Indian Political App Tek Fog Allegedly Hijacked Trends and Manipulated Public Opinion on Other Social Media Platforms", "DESCRIPTION": "The Indian political social media app Tek Fog allegedly allowed operatives affiliated with the ruling political party to hijack social media trends and manipulate public opinion on other apps such as Twitter and WhatsApp, which opposition parties denounced as a national security threat.", "DATE": "2020-04-28", "ALLEGED DEPLOYER OF AI SYSTEM": "Bharatiya Janata Yuva Morcha", "ALLEGED DEVELOPER OF AI SYSTEM": "Persistent Systems", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Indian voters, Indian social media users, Indian women journalists"}
{"INCIDENT ID": "Incident 227", "TITLE": "Waze App Allegedly Caused Tourists\u2019 Car to End up in Lake Champlain, Vermont", "DESCRIPTION": "The tourists driving through Vermont blamed Waze for directing them into a boat launch in Lake Champlain, prompting the vehicle to slide into the water by the time the drivers realized their location in the dark and foggy weather.", "DATE": "2018-01-12", "ALLEGED DEPLOYER OF AI SYSTEM": "Waze", "ALLEGED DEVELOPER OF AI SYSTEM": "Waze", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "tourists, Waze users"}
{"INCIDENT ID": "Incident 229", "TITLE": "Content Using Bestiality Thumbnails Allegedly Evaded YouTube\u2019s Thumbnail Monitoring System", "DESCRIPTION": "YouTube\u2019s thumbnail monitoring system was allegedly evaded by content farms such as ones in Cambodia who spike viewership and generate ad revenue using bestiality-themed thumbnails.", "DATE": "2018-04-23", "ALLEGED DEPLOYER OF AI SYSTEM": "YouTube", "ALLEGED DEVELOPER OF AI SYSTEM": "YouTube", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "YouTube users, YouTube content creators"}
{"INCIDENT ID": "Incident 244", "TITLE": "Colorado Police\u2019s Automated License Plate Reader (ALPR) Matched a Family\u2019s Minivan\u2019s Plate to That of a Stolen Vehicle Allegedly, Resulting in Detainment at Gunpoint", "DESCRIPTION": "An automated plate reader reportedly matched a license plate information, but of a family\u2019s minivan and an alleged motorcycle in Montana that was reportedly stolen earlier in the year, resulting in them and their children being held at gunpoint and detained in handcuffs by multiple Aurora police officers.", "DATE": "2020-08-03", "ALLEGED DEPLOYER OF AI SYSTEM": "Aurora Police Department", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "the Gilliam family"}
{"INCIDENT ID": "Incident 233", "TITLE": "Tumblr Automated Pornography-Detecting Algorithms Erroneously Flagged Inoffensive Images as Explicit", "DESCRIPTION": "Tumblr\u2019s automated tools to identify adult content were reported to have incorrectly flagged inoffensive images as explicit, following its announcement to ban all adult content on the platform.", "DATE": "2018-12-03", "ALLEGED DEPLOYER OF AI SYSTEM": "Tumblr", "ALLEGED DEVELOPER OF AI SYSTEM": "Tumblr", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Tumblr content creators, Tumblr users"}
{"INCIDENT ID": "Incident 228", "TITLE": "Apple Maps Allegedly Directed Ski Trip Couple Onto Unpaved Road in the Mountains", "DESCRIPTION": "Near Los Angeles, Apple Maps allegedly directed a couple on a ski trip in the mountains toward into an unconventional route out of town, where the drivers found themselves lost and stuck on an unpaved road in the snow.", "DATE": "2019-02-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Apple", "ALLEGED DEVELOPER OF AI SYSTEM": "Apple", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "tourists, Apple Maps users"}
{"INCIDENT ID": "Incident 245", "TITLE": "Unverified Misreading by Automated Plate Reader Led to Traffic Stop and Restraint of an Innocent Person at Gunpoint in California", "DESCRIPTION": "In San Francisco, an automated license plate reader (ALPR) camera misread a number as belonging to a stolen vehicle having the wrong make, but its photo was not visually confirmed by the police due to poor quality and allegedly despite multiple chances prior to making a traffic stop, causing an innocent person to be pulled over at gunpoint and restrained in handcuffed.", "DATE": "2009-03-30", "ALLEGED DEPLOYER OF AI SYSTEM": "San Francisco Police Department", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Denise Green"}
{"INCIDENT ID": "Incident 234", "TITLE": "Waze Allegedly Frequently Routed Drivers through the Town of Los Gatos, Blocking Its Single Wildfire Escape Route", "DESCRIPTION": "Waze app was blamed by Los Gatos town residents for contributing to high wildfire hazard risk via allegedly routing weekend beach-going drivers through their neighborhoods, effectively choking off their single escape route in the event of a medical emergency or wildfire.", "DATE": "2019-09-06", "ALLEGED DEPLOYER OF AI SYSTEM": "Waze", "ALLEGED DEVELOPER OF AI SYSTEM": "Waze", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Los Gatos residents"}
{"INCIDENT ID": "Incident 238", "TITLE": "Oregon\u2019s Screening Tool for Child Abuse Cases Discontinued Following Concerns of Racial Bias", "DESCRIPTION": "Oregon\u2019s Department of Human Services (DHS) stopped using its Safety at Screening Tool, that is aimed to predict the risk that children wind up in foster care or be investigated in the future, and opted for a new process allegedly to reduce disparities and improve racially equitable decision-making.", "DATE": "2018-10-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Oregon Department of Human Services", "ALLEGED DEVELOPER OF AI SYSTEM": "Oregon Department of Human Services", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "children of minority groups, families of minority groups"}
{"INCIDENT ID": "Incident 226", "TITLE": "Waze Allegedly Clogged Streets and Directed Drivers to Make Unsafe Traffic Decisions", "DESCRIPTION": "For years, Waze has, in an attempt to cut travel times, allegedly caused more traffic and guided drivers to make unsafe and often un-permitted traffic decisions, which was described by a Los Angeles city council member as a threat to public safety.", "DATE": "2015-04-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Waze", "ALLEGED DEVELOPER OF AI SYSTEM": "Waze", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Sherman Oaks residents, Waze users, Los Angeles city government"}
{"INCIDENT ID": "Incident 241", "TITLE": "Chess-Playing Robot Broke Child's Finger in Russia", "DESCRIPTION": "A chess robot at a tournament in Russia broke the finger of a child who reached onto the board before the robot had completed its move", "DATE": "2022-07-21", "ALLEGED DEPLOYER OF AI SYSTEM": "Russian Chess Federation", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "child named Christopher"}
{"INCIDENT ID": "Incident 243", "TITLE": "Bots Allegedly Made up Roughly Half of Twitter Accounts in Discussions Surrounding COVID-19 Related Issues", "DESCRIPTION": "Bots by anonymous actors were found by researchers to make up roughly half of Twitter accounts participating in COVID-19 discussions, many of which posted tweets about \u201creopening America\u201c.", "DATE": "2020-01-01", "ALLEGED DEPLOYER OF AI SYSTEM": "unknown", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Twitter, Twitter Users, Twitter users participating in COVID-19 discussions"}
{"INCIDENT ID": "Incident 271", "TITLE": "Tesla Model 3 Sedan on Autopilot Killed Motorcyclist in a Rear-End Collision in Utah", "DESCRIPTION": "A Tesla Model 3 operating on Autopilot mode slammed into the back of a Harley-Davidson motorcycle on an interstate in Utah, throwing the rider from the bike and killing him instantly.", "DATE": "2022-07-24", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Landon Embry, motorcyclists, Tesla drivers"}
{"INCIDENT ID": "Incident 251", "TITLE": "Amazon Allegedly Tweaked Search Algorithm to Boost Its Own Products", "DESCRIPTION": "Amazon tweaked product-search algorithm to boost and guide customers towards more profitable in-house products instead of showing mainly most-relevant and best-selling listings, which its internal engineers and lawyers alleged to violate company\u2019s best-for-customer principle.", "DATE": "2018-08-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Amazon", "ALLEGED DEVELOPER OF AI SYSTEM": "Amazon", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "small businesses on Amazon, Amazon Customers"}
{"INCIDENT ID": "Incident 273", "TITLE": "FaceApp Predicted Different Genders for Similar User Photos with Slight Variations", "DESCRIPTION": "FaceApp\u2019s algorithm was reported by a user to have predicted different genders for two mostly identical facial photos with only a slight difference in eyebrow thickness.", "DATE": "2020-12-24", "ALLEGED DEPLOYER OF AI SYSTEM": "FaceApp", "ALLEGED DEVELOPER OF AI SYSTEM": "FaceApp", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "FaceApp non-binary presenting users, FaceApp transgender users, FaceApp users"}
{"INCIDENT ID": "Incident 259", "TITLE": "YouTuber Built, Made Publicly Available, and Released Model Trained on Toxic 4chan Posts as Prank", "DESCRIPTION": "A YouTuber built GPT-4chan, a model based on OpenAI\u2019s GPT-J and trained on posts containing racism, misogyny, and antisemitism collected from 4chan\u2019s \u201cpolitically incorrect\u201d board, which he made publicly available, and deployed as multiple bots posting thousands of messages on the same 4chan board as a prank.", "DATE": "2022-06-03", "ALLEGED DEPLOYER OF AI SYSTEM": "Yannic Kilcher", "ALLEGED DEVELOPER OF AI SYSTEM": "Yannic Kilcher", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "internet social platform users"}
{"INCIDENT ID": "Incident 256", "TITLE": "DUI Arrest Case Allegedly Based Only on ShotSpotter's Alert", "DESCRIPTION": "A car stop resulting in a DUI arrest of its driver was allegedly based solely on a ShotSpotter alert, the reliability of which came into question by public defenders, who subpoenaed the company to assess its gunshot alert system.", "DATE": "2021-11-07", "ALLEGED DEPLOYER OF AI SYSTEM": "Chicago Police Department", "ALLEGED DEVELOPER OF AI SYSTEM": "ShotSpotter", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Chicago drivers"}
{"INCIDENT ID": "Incident 250", "TITLE": "Dutch City Court Defended Home Value Generated by Black-Box Algorithm", "DESCRIPTION": "A home value generated by a black-box algorithm was reportedly defended by the Castricum court, which was criticized by a legal specialist for setting a dangerous precedent for accepting black-box algorithms as long as their results appear reasonable.", "DATE": "2016-02-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Castricum municipality", "ALLEGED DEVELOPER OF AI SYSTEM": "Castricum municipality", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "unnamed property owner"}
{"INCIDENT ID": "Incident 258", "TITLE": "Australian Retailers Reportedly Captured Face Prints of Their Customers without Consent", "DESCRIPTION": "Major Australian retailers reportedly analyzed in-store footage to capture facial features of their customers without consent, which was criticized by consumer groups as creepy and invasive.", "DATE": "2022-05-13", "ALLEGED DEPLOYER OF AI SYSTEM": "The Good Guys, Kmart, Bunnings", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "The Good Guys customers, Kmart customers, Bunnings customers"}
{"INCIDENT ID": "Incident 264", "TITLE": "AI-Based Vehicle Speed Estimation App Denounced by UK Drivers as Surveillance Technology", "DESCRIPTION": "Speedcam Anywhere, an app allowing users to document and report traffic violations via AI-based videographic speed estimation of a vehicle, raised concerns for UK drivers about its capabilities for surveillance and abuse.", "DATE": "2022-03-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Speedcam Anywhere", "ALLEGED DEVELOPER OF AI SYSTEM": "Speedcam Anywhere", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "UK drivers"}
{"INCIDENT ID": "Incident 272", "TITLE": "Grab Tweaked Matchmaking Algorithm, Providing Preferential Treatment to Drivers Registered with Affiliated Car Rental Service", "DESCRIPTION": "Grab Indonesia was fined by the Indonesian Competition Commission (KPPU) for unfairly favoring drivers who rented cars via the Grab-affiliated company Teknologi Pengangkutan Indonesia (TPI), including offering more rides via their matchmaking algorithm.", "DATE": "2019-10-08", "ALLEGED DEPLOYER OF AI SYSTEM": "Grab", "ALLEGED DEVELOPER OF AI SYSTEM": "Grab", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "non-TPI-registered Grab drivers, Grab drivers in Indonesia, Grab drivers"}
{"INCIDENT ID": "Incident 260", "TITLE": "US DHS\u2019s Opaque Vetting Software Allegedly Relied on Poor-Quality Data and Discriminated against Immigrants", "DESCRIPTION": "US Citizenship and Immigration Services (USCIS)\u2019s ATLAS software used in vetting immigration requests was condemned by advocacy groups as a threat to naturalized citizens for its secretive algorithmic decision-making, reliance on poor quality data and unknown sources, and alleged discrimination of immigrants using biometric and sensitive information.", "DATE": "2014-08-26", "ALLEGED DEPLOYER OF AI SYSTEM": "US Department of Homeland Security, US Citizenship and Immigration Services", "ALLEGED DEVELOPER OF AI SYSTEM": "US Citizenship and Immigration Services", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "US naturalized citizens, US immigrants, US citizenship applicants, US immigration applicants"}
{"INCIDENT ID": "Incident 261", "TITLE": "Robot Deployed by Animal Shelter to Patrol Sidewalks outside Its Office, Warding off Homeless People in San Francisco", "DESCRIPTION": "Society for the Prevention of Cruelty to Animals (SPCA) deployed a Knightscope robot to autonomously patrol the area outside its office and ward off homeless people, which was criticized by residents as a tool of intimidation and ordered by the city of San Francisco to stop its use on a public right-of-way.", "DATE": "2017-11-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Society for the Prevention of Cruelty to Animals", "ALLEGED DEVELOPER OF AI SYSTEM": "Knightscope", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "San Francisco homeless people"}
{"INCIDENT ID": "Incident 270", "TITLE": "Apple Tweaked App Store Ranking Algorithms, Allegedly Resulted in Demotion of Local Apps in China", "DESCRIPTION": "Following Apple\u2019s changes in ranking algorithm in its iTunes App Store, apps by allegedly reputable companies and local startups in China experienced significant drops in ranking order.", "DATE": "2011-04-18", "ALLEGED DEPLOYER OF AI SYSTEM": "Apple", "ALLEGED DEVELOPER OF AI SYSTEM": "Apple", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Renren, Buding Movie Tickets, Yi Xia, Dangdang, Chinese startups, Chinese companies"}
{"INCIDENT ID": "Incident 268", "TITLE": "Permanent Removal of Social Media Content via Automated Tools Allegedly Prevented Investigative Efforts", "DESCRIPTION": "Automated permanent removal of violating social media content, such as terrorism, violent extremism, and hate speech, without archival has allegedly hindered the potential use of this content for investigating serious crimes and hampered efforts in criminal accountability.", "DATE": "2020-03-16", "ALLEGED DEPLOYER OF AI SYSTEM": "YouTube, Twitter, Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "YouTube, Twitter, Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "victims of crimes documented on social media, investigative journalists, International Criminal Court investigators, International Court of Justice investigators, criminal investigators"}
{"INCIDENT ID": "Incident 255", "TITLE": "Unreliable ShotSpotter Audio Previously Used to Convict Chicago Man in Murder Case", "DESCRIPTION": "ShotSpotter audios were previously admitted to convict an innocent Black man in a murder case in Chicago, resulted in his nearly-one-year-long arrest before being dismissed by prosecutors as insufficient evidence.", "DATE": "2020-05-31", "ALLEGED DEPLOYER OF AI SYSTEM": "Chicago Police Department", "ALLEGED DEVELOPER OF AI SYSTEM": "ShotSpotter", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Michael Williams"}
{"INCIDENT ID": "Incident 266", "TITLE": "Replika's \"AI Companions\" Reportedly Abused by Its Users", "DESCRIPTION": "Replika's AI-powered \"digital companions\" was allegedly abused by their users, who posted on Reddit abusive behaviors and interactions such as using slurs, roleplaying violent acts, and stimulating sexual abuse.", "DATE": "2022-01-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Replika", "ALLEGED DEVELOPER OF AI SYSTEM": "Replika", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Replika users, Replika male users, Replika"}
{"INCIDENT ID": "Incident 253", "TITLE": "Cruise's Self-Driving Cars Allegedly Lost Connection to Their Server, Causing Traffic Blockages in San Francisco", "DESCRIPTION": "Cruise\u2019s autonomous vehicles were shown on video stopping in the middle of the road and causing blockages in San Francisco, as they were disabled allegedly due to lost connection to their company\u2019s server.", "DATE": "2022-05-18", "ALLEGED DEPLOYER OF AI SYSTEM": "Cruise", "ALLEGED DEVELOPER OF AI SYSTEM": "Cruise", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "San Francisco traffic participants, San Francisco public"}
{"INCIDENT ID": "Incident 249", "TITLE": "Government Deployed Extreme Surveillance Technologies to Monitor and Target Muslim Minorities in Xinjiang", "DESCRIPTION": "A suite of AI-powered digital surveillance systems involving facial recognition and analysis of biometric data were deployed by the Chinese government in Xinjiang to monitor and discriminate local Uyghur and other Turkic Muslims.", "DATE": "2016-10-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Chinese government", "ALLEGED DEVELOPER OF AI SYSTEM": "Chinese government", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Uyghur people, Turkic Muslim ethnic groups"}
{"INCIDENT ID": "Incident 254", "TITLE": "Google\u2019s Face Grouping Allegedly Collected and Analyzed Users\u2019 Facial Structure without Consent, Violated BIPA", "DESCRIPTION": "A class-action lawsuit alleged Google failing to provide notice, obtain informed written consent, or publish data retention policies about the collection, storage, and analysis of its face-grouping feature in Google Photos, which violated Illinois Biometric Information Privacy Act (BIPA).", "DATE": "2015-05-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Google Photos users residing in Illinois, Google Photos users, Illinois residents"}
{"INCIDENT ID": "Incident 274", "TITLE": "Virginia Courts\u2019 Algorithmic Recidivism Risk Assessment Failed to Lower Incarceration Rates", "DESCRIPTION": "Virginia courts\u2019 use of algorithmic predictions of future offending risks were found by researchers failing to reduce incarceration rates, showed racial and age disparities in risk scores and its application, and neither exacerbated or ameliorated historical racial differences in sentencing.", "DATE": "2003-07-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Virginia courts", "ALLEGED DEVELOPER OF AI SYSTEM": "Virginia Department of Criminal Justice Services", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Virginia convicted felons, Virginia Black offenders, Virginia young offenders"}
{"INCIDENT ID": "Incident 267", "TITLE": "Clearview AI Algorithm Built on Photos Scraped from Social Media Profiles without Consent", "DESCRIPTION": "Face-matching algorithm by Clearview AI was built using scraped images from social media sites such as Instagram and Facebook without user consent, violating social media site policies, and allegedly privacy regulations.", "DATE": "2017-06-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Clearview AI", "ALLEGED DEVELOPER OF AI SYSTEM": "Clearview AI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "social media users, Instagram users, Facebook users"}
{"INCIDENT ID": "Incident 257", "TITLE": "Police Reportedly Deployed ShotSpotter Sensors Disproportionately in Neighborhoods of Color", "DESCRIPTION": "Police departments disproportionately placed ShotSpotter sensors in black and brown neighborhoods, which is denounced by communities for allegedly creating dangerous situations, such as one involving in Adam Toledo's death.", "DATE": "2012-05-04", "ALLEGED DEPLOYER OF AI SYSTEM": "Kansas City Police Department, Cleveland Division of Police, Chicago Police Department, Atlanta Police Department", "ALLEGED DEVELOPER OF AI SYSTEM": "ShotSpotter", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "neighborhoods of color, Brown communities, Black communities, Adam Toledo"}
{"INCIDENT ID": "Incident 252", "TITLE": "Remotely Operated Taser-Armed Drones Proposed by Taser Manufacturer as Defense for School Shootings in the US", "DESCRIPTION": "Axon Enterprise considered development of remotely operated drones capable of tasering at a target a short distance away as a defense mechanism for mass shootings, despite its internal AI ethics board\u2019s previous objection and condemnation as dangerous and fantastical.", "DATE": "2022-06-01", "ALLEGED DEPLOYER OF AI SYSTEM": "none", "ALLEGED DEVELOPER OF AI SYSTEM": "Axon Enterprise", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "US schools, US students"}
{"INCIDENT ID": "Incident 262", "TITLE": "DALL-E Mini Reportedly Reinforced or Exacerbated Societal Biases in Its Outputs as Gender and Racial Stereotypes", "DESCRIPTION": "Publicly deployed open-source model DALL-E Mini was acknowledged by its developers and found by its users to have produced images which reinforced racial and gender biases.", "DATE": "2022-06-11", "ALLEGED DEPLOYER OF AI SYSTEM": "Boris Dayma", "ALLEGED DEVELOPER OF AI SYSTEM": "Boris Dayma, Suraj Patil, Pedro Cuenca, Khalid Saifullah, Tanishq Abraham, Ph\u00fac L\u00ea Kh\u1eafc, Luke Melas, Ritobrata Ghosh", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Minority Groups, underrepresented groups"}
{"INCIDENT ID": "Incident 263", "TITLE": "YouTube Recommendations Implicated in Political Radicalization of User", "DESCRIPTION": "YouTube\u2019s personalization and recommendation algorithms were alleged to have pushed and exposed its young male users to political extremism and misinformation, driving them towards far-right ideologies such as neo-Nazism and white supremacy.", "DATE": "2015-09-01", "ALLEGED DEPLOYER OF AI SYSTEM": "YouTube", "ALLEGED DEVELOPER OF AI SYSTEM": "YouTube", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "YouTube young male users, YouTube male users, Caleb Cain"}
{"INCIDENT ID": "Incident 265", "TITLE": "Black Uber Eats Driver Allegedly Subjected to Excessive Photo Checks and Dismissed via FRT Results", "DESCRIPTION": "A lawsuit by a former Uber Eats delivery driver alleged the company to have wrongfully dismissed him due to frequent false mismatches of his verification selfies, and discriminated against him via excessive verification checks.", "DATE": "2021-04-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Uber Eats", "ALLEGED DEVELOPER OF AI SYSTEM": "Uber Eats", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Pa Edrissa Manjang, Uber Eats Black delivery drivers"}
{"INCIDENT ID": "Incident 278", "TITLE": "Meta\u2019s BlenderBot 3 Chatbot Demo Made Offensive Antisemitic Comments", "DESCRIPTION": "The publicly launched conversational AI demo BlenderBot 3 developed by Meta was reported by its users and acknowledged by its developers to have \u201coccasionally\u201d made offensive and inconsistent remarks such as invoking Jewish stereotypes.", "DATE": "2022-08-07", "ALLEGED DEPLOYER OF AI SYSTEM": "Meta", "ALLEGED DEVELOPER OF AI SYSTEM": "Meta", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Jewish people, BlenderBot 3 users"}
{"INCIDENT ID": "Incident 275", "TITLE": "Facebook\u2019s Moderation Algorithm Banned Users for Historical Evidence of Slavery", "DESCRIPTION": "Facebook\u2019s automated content moderation was acknowledged by a company spokesperson to have erroneously censored and banned Australian users from posting an article containing a 1890s photo of Aboriginal men in chains over nudity as historical evidence of slavery in Australia.", "DATE": "2020-06-11", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Facebook users sharing photo evidence of slavery, Facebook users"}
{"INCIDENT ID": "Incident 285", "TITLE": "Google Lens\u2019s Camera-Based Translation Feature Provided an Offensive Mistranslation of a Book Title in Korean", "DESCRIPTION": "A book title by Korea\u2019s first minister of culture was mistranslated into an offensive phrase by Google Lens\u2019s camera-based translation feature allegedly due to its training on internet communications and a lack of context.", "DATE": "2022-07-18", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Google Lens users"}
{"INCIDENT ID": "Incident 293", "TITLE": "Cruise\u2019s Self-Driving Car Involved in a Multiple-Injury Collision at an San Francisco Intersection", "DESCRIPTION": "A Cruise autonomous vehicle was involved in a crash at an intersection in San Francisco when making a left turn in front of a Toyota Prius traveling in an opposite direction, which caused occupants in both cars to sustain injuries.", "DATE": "2022-06-03", "ALLEGED DEPLOYER OF AI SYSTEM": "Cruise", "ALLEGED DEVELOPER OF AI SYSTEM": "Cruise", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Cruise passengers, Toyota Prius passengers"}
{"INCIDENT ID": "Incident 325", "TITLE": "Offensive Instagram User Content Displayed as Facebook Ad", "DESCRIPTION": "An Instagram user\u2019s image containing violent content was reportedly used as advertisement on Facebook allegedly via automated means.", "DATE": "2017-09-21", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Olivia Solon, Olivia Solon's Facebook connections"}
{"INCIDENT ID": "Incident 294", "TITLE": "Tesla Autopilot Allegedly Malfunctioned in a Non-Fatal Collision in Greece", "DESCRIPTION": "Autopilot was alleged by its Tesla Model 3 driver to have unexpectedly malfunctioned, veering right without warning and crashing into a road divider near Thessaloniki, Greece, which resulted in damages to its wheel and door but no injury to the driver.", "DATE": "2018-05-26", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "You You Xue, Tesla drivers"}
{"INCIDENT ID": "Incident 287", "TITLE": "OpenAI\u2019s GPT-3 Reported as Unviable in Medical Tasks by Healthcare Firm", "DESCRIPTION": "The French digital care company, Nabla, in researching GPT-3\u2019s capabilities for medical documentation, diagnosis support, and treatment recommendation, found its inconsistency and lack of scientific and medical expertise unviable and risky in healthcare applications. This incident has been downgraded to an issue as it does not meet current ingestion criteria.", "DATE": "2020-10-27", "ALLEGED DEPLOYER OF AI SYSTEM": "none", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI, Nabla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Nabla customers"}
{"INCIDENT ID": "Incident 295", "TITLE": "Wrongful Attempted Arrest for Apple Store Thefts Due to NYPD\u2019s Facial Misidentification", "DESCRIPTION": "New York Police Department (NYPD)\u2019s facial recognition system falsely connected a Black teenager to a series of thefts at Apple stores, which resulted in his wrongful attempted arrest.", "DATE": "2018-11-08", "ALLEGED DEPLOYER OF AI SYSTEM": "New York Police Department", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Ousmane Bah, NYC Black people, NYC Black young people"}
{"INCIDENT ID": "Incident 320", "TITLE": "Tesla on Autopilot Collided with Parked Fire Truck on California Freeway", "DESCRIPTION": "A Tesla Model S operating on Autopilot mode crashed into the back of a parked fire truck on a freeway in Culver City, California in a non-fatal collision.", "DATE": "2018-01-22", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Tesla drivers, Culver City Fire Department"}
{"INCIDENT ID": "Incident 335", "TITLE": "UK Visa Streamline Algorithm Allegedly Discriminated Based on Nationality", "DESCRIPTION": "UK Home Office's algorithm to assess visa application risks explicitly considered nationality, allegedly caused candidates to face more scrutiny and discrimination.", "DATE": "2015-03-01", "ALLEGED DEPLOYER OF AI SYSTEM": "UK Visas and Immigration", "ALLEGED DEVELOPER OF AI SYSTEM": "UK Visas and Immigration, UK Home Office", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "UK visa applicants from some countries"}
{"INCIDENT ID": "Incident 292", "TITLE": "Apple\u2019s AVs Reportedly Struggled to Navigate Streets in Silicon Valley Test Drives", "DESCRIPTION": "Apple\u2019s autonomous cars were reported to have bumped into curbs and struggled to stay in their lanes after crossing intersections during an on-road test drives near the company\u2019s Silicon Valley headquarters.", "DATE": "2021-09-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Apple", "ALLEGED DEVELOPER OF AI SYSTEM": "Apple", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Silicon Valley traffic participants, Silicon Valley residents"}
{"INCIDENT ID": "Incident 300", "TITLE": "TikTok's \"For You\" Algorithm Allegedly Abused by Online Personality to Promote Anti-Women Hate", "DESCRIPTION": "TikTok\u2019s \u201cFor You\u201d algorithm allegedly boosted or was manipulated by an online personality to artificially boost his content which promotes extreme misogynistic views towards teenagers and men, despite breaking its rules.", "DATE": "2022-01-15", "ALLEGED DEPLOYER OF AI SYSTEM": "TikTok", "ALLEGED DEVELOPER OF AI SYSTEM": "TikTok", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "TikTok male teenager users, TikTok male users, TikTok teenage users, TikTok users, TikTok"}
{"INCIDENT ID": "Incident 319", "TITLE": "Tesla on Autopilot Fatally Crashed into Parked Fire Truck in Indiana", "DESCRIPTION": "A Tesla on Autopilot mode failed to see a parked fire truck and crashed into its rear on an interstate in Indiana, causing the death of an Arizona woman.", "DATE": "2019-12-29", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Derrick Monet, Jenna Monet, the Monets' family"}
{"INCIDENT ID": "Incident 332", "TITLE": "Google Image Showed Racially Biased Results for \u201cProfessional\u201d Hairstyles", "DESCRIPTION": "Google Image search reportedly showed disparate results along racial lines, featuring almost exclusively white women for \u201cprofessional hairstyles\u201d and black women for \u201cunprofessional hairstyles\u201d prompts.", "DATE": "2016-04-05", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Black women, Black people, Google users"}
{"INCIDENT ID": "Incident 330", "TITLE": "\u201cAmazon\u2019s Choice\u201d Algorithm Failed to Recommend Functional Products and Prone to Review Manipulation", "DESCRIPTION": "Amazon\u2019s \u201cAmazon\u2019s Choice\u201d algorithm recommended poor-quality defective products and were reportedly susceptible to manipulation by inauthentic reviews.", "DATE": "2016-12-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Amazon", "ALLEGED DEVELOPER OF AI SYSTEM": "Amazon", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Amazon users"}
{"INCIDENT ID": "Incident 299", "TITLE": "Japanese Porn Depixelated by Man using Deepfake", "DESCRIPTION": "A man allegedly unblurred, using deepfake technology, pixelated pornographic images and videos of pornographic actors, which violated Japan\u2019s obscenity law requiring images of genitalia to be obscured.", "DATE": "2020-12-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Masayuki Nakamoto", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Japanese pornographic actors"}
{"INCIDENT ID": "Incident 323", "TITLE": "Tesla on Autopilot Crashed into Parked Police Car in California", "DESCRIPTION": "A Tesla sedan on Autopilot mode collided with a parked Laguna Beach Police Department car, resulting in minor injuries for its driver in Laguna Beach, California.", "DATE": "2018-05-29", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Laguna Beach Police Department"}
{"INCIDENT ID": "Incident 328", "TITLE": "Fake Accounts Using GAN Faces Deployed by Propaganda Campaign on Social Platforms", "DESCRIPTION": "A pro-China propaganda campaign deployed fake accounts on Facebook, Twitter, and YouTube using GAN-synthesized faces to share and post comments on its content to gain wider circulation.", "DATE": "2020-06-13", "ALLEGED DEPLOYER OF AI SYSTEM": "Spamouflage Dragon", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Facebook users, Twitter Users, YouTube users"}
{"INCIDENT ID": "Incident 347", "TITLE": "Waymo Self-Driving Taxi Behaved Unexpectedly, Driving away from Support Crew", "DESCRIPTION": "A Waymo self-driving taxi car was shown on video stranded on a road in Arizona while carrying a passenger, suddenly drove away from the company's roadside assistance worker, and ended up being stuck farther down the road.", "DATE": "2021-05-06", "ALLEGED DEPLOYER OF AI SYSTEM": "Waymo", "ALLEGED DEVELOPER OF AI SYSTEM": "Waymo", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Waymo passengers"}
{"INCIDENT ID": "Incident 350", "TITLE": "Delivery Robot Rolled Through Crime Scene", "DESCRIPTION": "A Serve Robotics delivery robot was shown on video rolling through a crime scene blocked off by police tape.", "DATE": "2022-09-13", "ALLEGED DEPLOYER OF AI SYSTEM": "Serve Robotics", "ALLEGED DEVELOPER OF AI SYSTEM": "Serve Robotics", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "police investigators"}
{"INCIDENT ID": "Incident 291", "TITLE": "Tesla Allegedly Misled Customers about Autopilot and FSD Capabilities", "DESCRIPTION": "California\u2019s Department of Motor Vehicles (DMV) accused Tesla of false advertising in its promotion of Autopilot and Full Self-Driving (FSD) technologies, alleging the company to have made untrue or misleading claims with marketing language about the capabilities of its products.", "DATE": "2021-05-28", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "California Department of Motor Vehicles, Tesla customers, California residents"}
{"INCIDENT ID": "Incident 280", "TITLE": "Coffee Meets Bagel\u2019s Algorithm Reported by Users Disproportionately Showing Them Matches of Their Own Ethnicities Despite Selecting \u201cNo Preference\u201d", "DESCRIPTION": "Users selecting \u201cno preference\u201d were shown by Coffee Meets Bagels\u2019s matching algorithm more potential matches with the same ethnicity, which was acknowledged and justified by its founder as a means to maximize connection rate without sufficient user information.", "DATE": "2013-07-30", "ALLEGED DEPLOYER OF AI SYSTEM": "Coffee Meets Bagel", "ALLEGED DEVELOPER OF AI SYSTEM": "Coffee Meets Bagel", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Coffee Meets Bagel users having no ethnicity preference, Coffee Meets Bagel users"}
{"INCIDENT ID": "Incident 326", "TITLE": "Facebook Automated Year-in-Review Highlights Showed Users Painful Memories", "DESCRIPTION": "Facebook\u2019s \u201cYear in Review\u201d algorithm which compiled content in users\u2019 past year as highlights inadvertently showed painful and unwanted memories to users, including death of family member.", "DATE": "2014-12-09", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Facebook users having posts about painful events, Facebook users"}
{"INCIDENT ID": "Incident 318", "TITLE": "Facebook Recommended Military Gear Ads Despite Pause on Weapons Accessories Ads", "DESCRIPTION": "Facebook\u2019s algorithmic recommendations reportedly continued showing advertisements for gun accessories and military gear, despite Facebook\u2019s halt on weapons accessories ads following the US Capitol attack.", "DATE": "2021-01-13", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Facebook users"}
{"INCIDENT ID": "Incident 334", "TITLE": "Uber Deployed Secret Program To Deny Local Authorities Rides", "DESCRIPTION": "Uber developed a secret program \"Greyball\" which prevented known law enforcement officers in areas where its service violated regulations from receiving rides.", "DATE": "2014-10-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Uber", "ALLEGED DEVELOPER OF AI SYSTEM": "Uber", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "local law enforcement officers"}
{"INCIDENT ID": "Incident 305", "TITLE": "YouTube\u2019s Recommendation Algorithm Allegedly Promoted Climate Misinformation Content", "DESCRIPTION": "YouTube\u2019s recommendation system and its focus on views and watched time were alleged by an advocacy group to have driven people towards climate denial and misinformation videos.", "DATE": "2019-02-01", "ALLEGED DEPLOYER OF AI SYSTEM": "YouTube", "ALLEGED DEVELOPER OF AI SYSTEM": "YouTube", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "YouTube users, YouTube climate-skeptic users"}
{"INCIDENT ID": "Incident 304", "TITLE": "Tesla on FSD Reportedly Drove into the Wrong Lane in California", "DESCRIPTION": "A Tesla Model Y in Full Self-Driving (FSD) mode drove into the wrong lane after making a left turn despite its driver allegedly attempting to overtake its driving, resulting in a non-fatal collision with another vehicle in the wrong lane in Brea, California.", "DATE": "2021-11-03", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "unnamed Tesla driver, Tesla drivers"}
{"INCIDENT ID": "Incident 346", "TITLE": "Robots in Japanese Hotel Annoyed Guests and Failed to Handle Simple Tasks", "DESCRIPTION": "A number of robots employed by a hotel in Japan were reported by guests in a series of complaints for failing to handle tasks such as answering scheduling questions or making passport copies without human intervention.", "DATE": "2016-06-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Henn na Hotel", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Henn na Hotel guests, Henn na Hotal staff"}
{"INCIDENT ID": "Incident 283", "TITLE": "Facebook\u2019s Automated Content Moderation Tool Flagged a Post Containing Parts of the Declaration of Independence as Hate Speech by Mistake", "DESCRIPTION": "Facebook\u2019s content moderation algorithm was acknowledged by the company to have flagged excerpts of the Declaration of Independence posted by a small newspaper in Texas as hate speech by mistake.", "DATE": "2018-07-02", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "The Vindicator"}
{"INCIDENT ID": "Incident 344", "TITLE": "Hiring Algorithms Provided Invalid Positive Results for Interview Responses in German", "DESCRIPTION": "Two AI interview softwares provided positive but invalid results such as \"competent\" English proficiency and high match percentage for interview responses given in German by reporters.", "DATE": "2021-07-01", "ALLEGED DEPLOYER OF AI SYSTEM": "MyInterview, Curious Thing", "ALLEGED DEVELOPER OF AI SYSTEM": "MyInterview, Curious Thing", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "job candidates using MyInterview, job candidates using Curious Thing, employers using MyInterview, employers using Curious Thing"}
{"INCIDENT ID": "Incident 348", "TITLE": "YouTube Recommendation Reportedly Pushed Election Fraud Content to Skeptics Disproportionately", "DESCRIPTION": "YouTube's recommendation algorithm allegedly pushed 2020's US Presidential Election fraud content to users most skeptical of the election's legitimacy disproportionately compared to least skeptical users.", "DATE": "2020-11-01", "ALLEGED DEPLOYER OF AI SYSTEM": "YouTube", "ALLEGED DEVELOPER OF AI SYSTEM": "YouTube", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "YouTube users skeptical of US election results"}
{"INCIDENT ID": "Incident 277", "TITLE": "Voices Created Using Publicly Available App Stolen and Resold as NFT without Attribution", "DESCRIPTION": "An AI-synthetic audio sold as an NFT on Voiceverse\u2019s platform was acknowledged by the company for having been created by 15.ai, a free web app specializing in text-to-speech and AI-voice generation, and reused without proper attribution.", "DATE": "2022-01-14", "ALLEGED DEPLOYER OF AI SYSTEM": "15.ai", "ALLEGED DEVELOPER OF AI SYSTEM": "15.ai", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "15.ai, 15.ai users"}
{"INCIDENT ID": "Incident 340", "TITLE": "Honda's CMBS False Positives Allegedly Caused Accidents to Customers", "DESCRIPTION": "Honda's Collision Mitigation Braking System (CMBS) allegedly caused accidents to consumers due to frequent instances of false obstacle detection.", "DATE": "2017-02-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Honda", "ALLEGED DEVELOPER OF AI SYSTEM": "Honda", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Honda customers"}
{"INCIDENT ID": "Incident 341", "TITLE": "Nissan's \"Automatic Emergency Braking\" False Positives Posed Traffic Risks to Drivers", "DESCRIPTION": "Nissan's Automatic Emergency Braking (AEB) feature was reported in a series of complaints for false positives and abrupt braking behaviors, endangering car occupants and traffic participants.", "DATE": "2017-04-06", "ALLEGED DEPLOYER OF AI SYSTEM": "Nissan", "ALLEGED DEVELOPER OF AI SYSTEM": "Nissan", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Nissan drivers, traffic participants"}
{"INCIDENT ID": "Incident 297", "TITLE": "EasyMile Self-Driving Shuttle Unexpectedly Stopped Mid-Route, Injuring a Passenger", "DESCRIPTION": "A self-driving shuttle deployed by Smart Columbus in Linden neighborhood unexpectedly stopped on the street, which caused a woman to fall onto the floor from her seat.", "DATE": "2020-02-20", "ALLEGED DEPLOYER OF AI SYSTEM": "Smart Columbus", "ALLEGED DEVELOPER OF AI SYSTEM": "EasyMile", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "unnamed woman passenger"}
{"INCIDENT ID": "Incident 282", "TITLE": "Facebook\u2019s Algorithm Mistook an Advertisement of Onions as Sexual Suggestive Content", "DESCRIPTION": "Facebook\u2019s content moderation algorithm misidentified and removed a Canadian business\u2019s advertisement containing a photo of onions as products of overtly sexual content, which was later reinstated after review.", "DATE": "2020-10-03", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "The Seed Company by E.W. Gaze, businesses on Facebook"}
{"INCIDENT ID": "Incident 276", "TITLE": "Local South Korean Government\u2019s Use of CCTV Footage Analysis via Facial Recognition to Track COVID Cases Raised Concerns about Privacy, Retention, and Potential Misuse", "DESCRIPTION": "Bucheon government\u2019s use of facial recognition in analyzing CCTV footage, despite gaining wide public support, was scrutinized by privacy advocates and some lawmakers for collecting data without consent, and retaining and misusing data beyond pandemic needs.", "DATE": "2022-01-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Bucheon city government", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Bucheon citizens"}
{"INCIDENT ID": "Incident 290", "TITLE": "False Negatives for Water Quality-Associated Beach Closures", "DESCRIPTION": "Toronto\u2019s use of AI predictive modeling (AIPM) which had replaced existing methodology as the only determiner of beach water quality raised concerns about its accuracy, after allegedly conflicting results were found by a local water advocacy group using traditional means.", "DATE": "2022-06-03", "ALLEGED DEPLOYER OF AI SYSTEM": "Toronto city government", "ALLEGED DEVELOPER OF AI SYSTEM": "Toronto Public Health", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Sunnyside beachgoers, Marie Curtis beachgoers, Toronto citizens"}
{"INCIDENT ID": "Incident 296", "TITLE": "Twitter Recommender System Amplified Right-Leaning Tweets", "DESCRIPTION": "Twitter\u2019s \u201cHome\u201d timeline algorithm was revealed by its internal researchers to have amplified tweets and news of rightwing politicians and organizations more than leftwing ones in six out of seven studied countries.", "DATE": "2016-02-10", "ALLEGED DEPLOYER OF AI SYSTEM": "Twitter", "ALLEGED DEVELOPER OF AI SYSTEM": "Twitter", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Twitter left-leaning politicians, Twitter left-leaning news organizations, Twitter left-leaning users, Twitter Users"}
{"INCIDENT ID": "Incident 313", "TITLE": "BlenderBot 3 Cited Dutch Politician as a Terrorist", "DESCRIPTION": "Meta\u2019s conversational AI BlenderBot 3, when prompted \u201cwho is a terrorist,\u201c responded with an incumbent Dutch politician\u2019s name, who was confused about its association.", "DATE": "2022-08-25", "ALLEGED DEPLOYER OF AI SYSTEM": "Meta", "ALLEGED DEVELOPER OF AI SYSTEM": "Meta", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Marietje Schaake"}
{"INCIDENT ID": "Incident 333", "TITLE": "Tesla on Autopilot Crashed Parked Michigan Police Car on Interstate", "DESCRIPTION": "A Tesla Model Y on Autopilot collided with a parked Michigan State Police (MSP) car which had its emergency lights on, in Eaton County, Michigan, although no one was injured.", "DATE": "2021-03-17", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "unnamed 22-year-old male driver, Tesla drivers"}
{"INCIDENT ID": "Incident 331", "TITLE": "Bug in Instagram\u2019s \u201cRelated Hashtags\u201d Algorithm Allegedly Caused Disproportionate Treatment of Political Hashtags", "DESCRIPTION": "A bug was reported by Instagram\u2019s spokesperson to have prevented an algorithm from populating related hashtags for thousands of hashtags, resulting in an allege preferential treatment for some politically partisan hashtags.", "DATE": "2020-08-05", "ALLEGED DEPLOYER OF AI SYSTEM": "Instagram", "ALLEGED DEVELOPER OF AI SYSTEM": "Instagram", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Instagram users"}
{"INCIDENT ID": "Incident 337", "TITLE": "Tesla Model S on ACC Crashed into Tree in Texas, Killing Two People", "DESCRIPTION": "A 2019 Tesla Model S was reportedly traveling on Adaptive Cruise Control (ACC) at high speed before crashing into a tree near The Woodlands in Spring, Texas, killing two people.", "DATE": "2021-04-17", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "William Varner, unnamed passenger"}
{"INCIDENT ID": "Incident 286", "TITLE": "TikTok\u2019s \"For You\" Allegedly Pushed Fatal \u201cBlackout\u201d Challenge Videos to Two Young Girls", "DESCRIPTION": "TikTok\u2019s recommendation algorithm was alleged in a lawsuit to have intentionally and repeatedly pushed videos of the \u201cblackout\u201d challenge onto children\u2019s feeds, incentivizing their participation which ultimately resulted in the death of two young girls.", "DATE": "2021-02-26", "ALLEGED DEPLOYER OF AI SYSTEM": "TikTok", "ALLEGED DEVELOPER OF AI SYSTEM": "TikTok", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Lalani Erika Renee Walton, Arriani Jaileen Arroyo, Lalani Erika Renee Walton's family, Arriani Jaileen Arroyo's family, TikTok young users, TikTok users"}
{"INCIDENT ID": "Incident 307", "TITLE": "iPhone Face ID Failed to Recognize Users\u2019 Morning Faces", "DESCRIPTION": "The Face ID feature on iPhone allowing users to unlock their phones via facial recognition was reported by users for not recognizing their faces in the morning.", "DATE": "2017-11-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Apple", "ALLEGED DEVELOPER OF AI SYSTEM": "Apple", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "iPhone Face ID users, iPhone X Face ID users"}
{"INCIDENT ID": "Incident 309", "TITLE": "Facial Recognition Trial Performed Poorly at Notting Hill Carnival", "DESCRIPTION": "The facial recognition trial by London\u2019s Metropolitan Police Service at the Notting Hill Carnival reportedly performed poorly with a high rate of false positives.", "DATE": "2017-08-26", "ALLEGED DEPLOYER OF AI SYSTEM": "Metropolitan Police Service", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Notting Hill Carnival goers"}
{"INCIDENT ID": "Incident 327", "TITLE": "Facebook\u2019s On-This-Day Feature Mistakenly Showed Painful Memories to Users", "DESCRIPTION": "Facebook\u2019s \u201cOn This Day\u201d algorithm which highlighted past posts on a user\u2019s private page or News Feed confronted unwanted and painful personal memories to its users.", "DATE": "2015-03-24", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Facebook users having posts about painful events, Facebook users"}
{"INCIDENT ID": "Incident 349", "TITLE": "Evolv's Gun Detection False Positives Created Problems for Schools", "DESCRIPTION": "Evolv's AI-based weapons detection system reportedly produced excessive false positives, mistaking everyday school items for weapons and pulling schools' security personnel for manual checking.", "DATE": "2022-03-22", "ALLEGED DEPLOYER OF AI SYSTEM": "Charlotte Mecklenburg School District", "ALLEGED DEVELOPER OF AI SYSTEM": "Evolv Technology", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "students at Charlotte Mecklenburg Schools, teachers at Charlotte Mecklenburg Schools, security officers at Charlotte Mecklenburg Schools"}
{"INCIDENT ID": "Incident 311", "TITLE": "YouTube Auto-Moderation Mistakenly Banned Women of Sex Tech Conference", "DESCRIPTION": "YouTube\u2019s automated content moderation tool erroneously removed The Women of Sex Tech conference\u2019s live-streamed event and banned the conference from the platform, despite not violating the platform\u2019s sexual content policies.", "DATE": "2020-05-02", "ALLEGED DEPLOYER OF AI SYSTEM": "YouTube", "ALLEGED DEVELOPER OF AI SYSTEM": "YouTube", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Women of Sex Tech conference attendants, Women of Sex Tech conference organizers"}
{"INCIDENT ID": "Incident 317", "TITLE": "Bug in Facebook\u2019s Anti-Spam Filter Allegedly Blocked Legitimate Posts about COVID-19", "DESCRIPTION": "Facebook was reported by users for blocking posts of legitimate news about the coronavirus pandemic, allegedly due to a bug in an anti-spam system.", "DATE": "2020-03-17", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Facebook users posting legitimate COVID-19 news, Facebook users"}
{"INCIDENT ID": "Incident 324", "TITLE": "GAN Faces Deployed by The BL's Fake Account Network to Push Pro-Trump Content on Meta Platforms", "DESCRIPTION": "A large network of pages, groups, and fake accounts having GAN-generated face photos associated with The BL, a US-based media outlet, reportedly bypassed Facebook moderation systems to push \"pro-Trump\" narratives on its platform and Instagram.", "DATE": "2019-11-12", "ALLEGED DEPLOYER OF AI SYSTEM": "The BL", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Instagram users, Facebook users"}
{"INCIDENT ID": "Incident 303", "TITLE": "Google\u2019s Automated Child Abuse Detection Wrongfully Flagged a Parent\u2019s Naked Photo of His Child", "DESCRIPTION": "Google\u2019s automated detection of abusive images of children incorrectly flagged a parent\u2019s photo intended for a healthcare provider, resulting in a false police report of child abuse, and loss of access to his online accounts and information.", "DATE": "2022-08-21", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "a software engineer named Mark, parents using telemedicine services"}
{"INCIDENT ID": "Incident 339", "TITLE": "Open-Source Generative Models Abused by Students to Cheat on Assignments and Exams", "DESCRIPTION": "Students were reportedly using open-source text generative models such as GPT-3 and ChatGPT to complete school assignments and exams such as writing reports, essays.", "DATE": "2022-09-15", "ALLEGED DEPLOYER OF AI SYSTEM": "students", "ALLEGED DEVELOPER OF AI SYSTEM": "Sudowrite, OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Teachers, non-cheating students, cheating students"}
{"INCIDENT ID": "Incident 343", "TITLE": "Facebook, Instagram, and Twitter Failed to Proactively Remove Targeted Racist Remarks via Automated Systems", "DESCRIPTION": "Facebook's, Instagram's, and Twitter's automated content moderation failed to proactively remove racist remarks and posts directing at Black football players after finals loss, allegedly largely relying on user reports of harassment.", "DATE": "2021-07-11", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook, Instagram, Twitter", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook, Instagram, Twitter", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Marcus Rashford, Jadon Sancho, Bukayo Saka, Facebook users, Instagram users, Twitter Users"}
{"INCIDENT ID": "Incident 302", "TITLE": "Students Allegedly Wrongfully Accused of Cheating via Medical School's Internal Software", "DESCRIPTION": "Dartmouth's Geisel School of Medicine allegedly falsely accused students of cheating during remote exams using an internally built system which tracked student activity patterns without their knowledge on its learning management platform.", "DATE": "2021-03-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Geisel School of Medicine", "ALLEGED DEVELOPER OF AI SYSTEM": "Geisel School of Medicine's Technology staff, Canvas", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Sirey Zhang, Geisel School of Medicine's students, Geisel School of Medicine's professors, Geisel School of Medicine's accused students"}
{"INCIDENT ID": "Incident 310", "TITLE": "High False Positive Rate by SWP's Facial Recognition Use at Champion's League Final", "DESCRIPTION": "South Wales Police (SWP)\u2019s automated facial recognition (AFR) at the Champion's League Final football game in Cardiff wrongly identified innocent people as potential matches at an extremely high false positive rate of more than 90%.", "DATE": "2017-06-03", "ALLEGED DEPLOYER OF AI SYSTEM": "South Wales Police", "ALLEGED DEVELOPER OF AI SYSTEM": "NEC", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "FInals attendees, falsely accused Finals attendees"}
{"INCIDENT ID": "Incident 321", "TITLE": "Tesla Model X on Autopilot Crashed into California Highway Barrier, Killing Driver", "DESCRIPTION": "A Tesla Model X P100D operating on Autopilot's Traffic-Aware Cruise Control (TACC) and Autosteer system allegedly accelerated above the speed limit of a highway in Mountain View, California, and steered itself directly into a barrier, resulting in its driver\u2019s death.", "DATE": "2018-03-23", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Walter Huang's family, Walter Huang"}
{"INCIDENT ID": "Incident 284", "TITLE": "Facebook\u2019s Automated Removal of Content Featuring Nudity-Containing Artworks Denounced as Censorship", "DESCRIPTION": "Facebook\u2019s removal of posts featuring renowned artworks by many historical artists and their promotional content due to nudity via both automated and human-moderated means were condemned by critics, such as museums and tourism boards, as cultural censorship and prevention of artwork promotion.", "DATE": "2018-05-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "museums on Facebook, Facebook users interested in arts, Facebook users"}
{"INCIDENT ID": "Incident 298", "TITLE": "Student-Developed Facial Recognition App Raised Ethical Concerns", "DESCRIPTION": "TheFaceTag app, a social networking app developed and deployed within-campus by a student at Harvard raised concerns surrounding its facial recognition, cybersecurity, privacy, and misuse. This incident has been downgraded to an issue as it does not meet current ingestion criteria.", "DATE": "2021-10-21", "ALLEGED DEPLOYER OF AI SYSTEM": "Yuen Ler Chow", "ALLEGED DEVELOPER OF AI SYSTEM": "Yuen Ler Chow", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "TheFaceTag app users"}
{"INCIDENT ID": "Incident 279", "TITLE": "TikTok\u2019s \u201cFor You\u201d Algorithm Exposed Young Users to Pro-Eating Disorder Content", "DESCRIPTION": "TikTok\u2019s young users were allegedly exposed to community-guideline-violating pro-eating disorder content on their algorithmically curated \u201cFor You\u201d page that serves videos from any user on its platform.", "DATE": "2019-07-01", "ALLEGED DEPLOYER OF AI SYSTEM": "TikTok", "ALLEGED DEVELOPER OF AI SYSTEM": "TikTok", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "TikTok young users, TikTok users"}
{"INCIDENT ID": "Incident 312", "TITLE": "Startup's Accent Translation AI Denounced as Reinforcing Racial Bias", "DESCRIPTION": "A startup\u2019s use of AI voice technology to alter or remove accents for call center agents was scrutinized by critics as reaffirming bias, despite the company\u2019s claim.", "DATE": "2021-08-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Sanas", "ALLEGED DEVELOPER OF AI SYSTEM": "Sanas", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "call center agents having non-Midwestern-American accent, people having non-Midwestern-American accent"}
{"INCIDENT ID": "Incident 306", "TITLE": "Tesla on Autopilot TACC Crashed into Van on European Highway", "DESCRIPTION": "A Tesla Model S operating on the Traffic-Aware Cruise Control (TACC) feature of Autopilot was shown on video by its driver crashing into a parked van on a European highway in heavy traffic, which damaged the front of the car.", "DATE": "2016-05-26", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "unnamed Tesla owner, Tesla drivers"}
{"INCIDENT ID": "Incident 314", "TITLE": "Stable Diffusion Abused by 4chan Users to Deepfake Celebrity Porn", "DESCRIPTION": "Stable Diffusion, an open-source image generation model by Stability AI, was reportedly leaked on 4chan prior to its release date, and was used by its users to generate pornographic deepfakes of celebrities.", "DATE": "2022-08-17", "ALLEGED DEPLOYER OF AI SYSTEM": "Stability AI", "ALLEGED DEVELOPER OF AI SYSTEM": "Stability AI, Runway, LAION, EleutherAI, CompVis LMU", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Stability AI, deepfaked celebrities"}
{"INCIDENT ID": "Incident 322", "TITLE": "Tesla Model 3 Crashed into Police Patrol Car on Connecticut Highway", "DESCRIPTION": "A Tesla Model 3 on Autopilot slammed into a parked car of patrol police officers who stopped to assist a stranded motorist on the interstate in Norwalk, Connecticut.", "DATE": "2019-12-07", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Connecticut State Police"}
{"INCIDENT ID": "Incident 308", "TITLE": "Atlas Robot Fell off Stage at Conference", "DESCRIPTION": "Boston Dynamics\u2019s autonomous robot Atlas allegedly caught its foot on a stage light, resulting in a fall off the stage at the Congress of Future Science and Technology Leaders conference.", "DATE": "2017-07-03", "ALLEGED DEPLOYER OF AI SYSTEM": "Boston Dynamics", "ALLEGED DEVELOPER OF AI SYSTEM": "Boston Dynamics", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "none"}
{"INCIDENT ID": "Incident 315", "TITLE": "Facial Recognition Service Abused to Target Russian Porn Actresses", "DESCRIPTION": "The facial recognition software FindFace allowing its users to match photos to people\u2019s social media pages on Vkontakte was reportedly abused to de-anonymize and harass Russian women who appeared in pornography and alleged sex workers.", "DATE": "2016-04-09", "ALLEGED DEPLOYER OF AI SYSTEM": "NtechLab", "ALLEGED DEVELOPER OF AI SYSTEM": "NtechLab", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Russian pornographic actresses, Russian sex workers"}
{"INCIDENT ID": "Incident 329", "TITLE": "Amazon Recommended Explosive-Producing Ingredients as \u201cFrequently Bought Together\u201d Items for Chemicals", "DESCRIPTION": "Amazon was reported to have shown chemical combinations for producing explosives and incendiary devices as \u201cfrequently bought together\u201d items via automated recommendation.", "DATE": "2017-09-18", "ALLEGED DEPLOYER OF AI SYSTEM": "Amazon", "ALLEGED DEVELOPER OF AI SYSTEM": "Amazon", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Amazon users"}
{"INCIDENT ID": "Incident 281", "TITLE": "YouTube's Algorithms Failed to Remove Violating Content Related to Suicide and Self-Harm", "DESCRIPTION": "Terms-of-service-violating videos related to suicide and self-harm reportedly bypassed YouTube\u2019s content moderation algorithms, allegedly resulting in exposure of graphic content to young users via recommended videos.", "DATE": "2019-02-04", "ALLEGED DEPLOYER OF AI SYSTEM": "YouTube", "ALLEGED DEVELOPER OF AI SYSTEM": "YouTube", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "YouTube young users, YouTube users"}
{"INCIDENT ID": "Incident 316", "TITLE": "Facebook Ad-Approval Algorithm Allegedly Missed Fraudulent Ads via Simple URL Checks", "DESCRIPTION": "Facebook\u2019s advertisement-approval algorithm was reported by a security analyst to have neglected simple checks for domain URLs, leaving its users at risk of fraudulent ads.", "DATE": "2016-06-02", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Facebook users"}
{"INCIDENT ID": "Incident 288", "TITLE": "New Jersey Police Wrongful Arrested Innocent Black Man via FRT", "DESCRIPTION": "Woodbridge Police Department falsely arrested an innocent Black man following a misidentification by their facial recognition software, who was jailed for more than a week and paid thousands of dollar for his defense.", "DATE": "2019-01-30", "ALLEGED DEPLOYER OF AI SYSTEM": "Woodbridge Police Department", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Nijeer Parks"}
{"INCIDENT ID": "Incident 289", "TITLE": "Starship Delivery Robot Scuffed Bumper of a Resident\u2019s Car in Texas, Allegedly Refusing to Release Footage of the Accident", "DESCRIPTION": "A Starship food delivery robot crashed into the front bumper of a vehicle waiting at a stoplight intersection in Frisco, Texas, the video of which the company reportedly refused to release.", "DATE": "2020-06-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Starship Technologies", "ALLEGED DEVELOPER OF AI SYSTEM": "Starship Technologies", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Jisuk Mok, Frisco residents"}
{"INCIDENT ID": "Incident 345", "TITLE": "Auto-Insurance Photo-Based Estimation Allegedly Gave Inaccurate Repair Prices Frequently", "DESCRIPTION": "Auto-insurance companies' photo-based estimation of repair price was alleged by repair shop owners and industry groups as providing inaccurate estimates, causing damaged cars to stay in the shop longer.", "DATE": "2021-04-13", "ALLEGED DEPLOYER OF AI SYSTEM": "insurance companies", "ALLEGED DEVELOPER OF AI SYSTEM": "CCC Information Services, Tractable", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "vehicle repair shops, vehicle owners"}
{"INCIDENT ID": "Incident 301", "TITLE": "Teenager at Broward College Allegedly Wrongfully Accused of Cheating via Remote Proctoring", "DESCRIPTION": "Broward College\u2019s use of remote proctoring system and reliance on its flagging algorithm allegedly led to a wrongful accusation of academic dishonesty in a biology exam of a Florida teenager.", "DATE": "2022-02-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Broward College", "ALLEGED DEVELOPER OF AI SYSTEM": "Honorlock", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "unnamed Florida teenager"}
{"INCIDENT ID": "Incident 336", "TITLE": "UK Home Office's Sham Marriage Detection Algorithm Reportedly Flagged Certain Nationalities Disproportionately", "DESCRIPTION": "UK Home Office's opaque algorithm to detect sham marriages flagged some nationalities for investigation more than others, raising fears surrounding discrimination based on nationality and age.", "DATE": "2015-03-01", "ALLEGED DEPLOYER OF AI SYSTEM": "UK Home Office", "ALLEGED DEVELOPER OF AI SYSTEM": "UK Home Office", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "UK immigrant newlyweds"}
{"INCIDENT ID": "Incident 351", "TITLE": "\"The Little Mermaid\" Clip Doctored Using Generative AI to Replace Black Actress with White Character", "DESCRIPTION": "A Twitter user reportedly modified using generative AI a short clip of Disney's 2022 version of \"The Little Mermaid,\" replacing a Black actress with a white digital character.", "DATE": "2022-09-13", "ALLEGED DEPLOYER OF AI SYSTEM": "@TenGazillioinIQ", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Halle Bailey, Black actresses"}
{"INCIDENT ID": "Incident 355", "TITLE": "Uber Allegedly Wrongfully Accused Drivers of Fraud via Automated Systems", "DESCRIPTION": "Uber was alleged in a lawsuit to have wrongfully accused its drivers in the UK and Portugal of fraudulent activity through automated systems, which resulted in their dismissal without a right to appeal.", "DATE": "2018-07-07", "ALLEGED DEPLOYER OF AI SYSTEM": "Uber", "ALLEGED DEVELOPER OF AI SYSTEM": "Uber", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Uber drivers"}
{"INCIDENT ID": "Incident 356", "TITLE": "Philosophy AI Tentatively Produced Offensive Results for Certain Prompts", "DESCRIPTION": "Philosopher AI as built on top of GPT-3 was reported by its users for having strong tendencies to produce offensive results when given prompts on certain topics such as feminism and Ethiopia.", "DATE": "2020-09-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Murat Ayfer", "ALLEGED DEVELOPER OF AI SYSTEM": "Murat Ayfer, OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "historically disadvantaged groups"}
{"INCIDENT ID": "Incident 370", "TITLE": "Google Fined for Changing Shopping Algorithms in EU to Favor Own Service", "DESCRIPTION": "Google was fined by EU Commission for changing its shopping algorithms in Europe to favor its own comparison service over competitors, resulting in anti-competitive effects.", "DATE": "2017-09-27", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Google's competitor shopping services"}
{"INCIDENT ID": "Incident 378", "TITLE": "TuSimple Truck Steered into Interstate Freeway Divide", "DESCRIPTION": "A TuSimple autonomous truck operating with backup drivers behind the wheel operated on an outdated command sequence and suddenly veered into the center divide on the interstate freeway.", "DATE": "2022-04-06", "ALLEGED DEPLOYER OF AI SYSTEM": "TuSimple", "ALLEGED DEVELOPER OF AI SYSTEM": "TuSimple", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "TuSimple, State of Arizona"}
{"INCIDENT ID": "Incident 363", "TITLE": "Facebook's Automated Moderation Mistakenly Flagged Landmark's Name as Offensive", "DESCRIPTION": "Facebook's automated system mistakenly labelled posts featuring the seafaring landmark Plymouth Hoe as misogynistic.", "DATE": "2021-01-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Facebook users posting about Plymouth Hoe, Facebook users in Plymouth Hoe, Plymouth Hoe residents"}
{"INCIDENT ID": "Incident 400", "TITLE": "Google Search Returned Fewer Results for Abortion Services in Rural Areas", "DESCRIPTION": "Google Search reportedly returned fewer abortion clinics for searches from poorer and rural areas, particularly ones with Targeted Regulation of Abortion Providers (TRAP) laws.", "DATE": "2022-02-23", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "women in need of abortion services, women having unexpected or crisis pregnancies"}
{"INCIDENT ID": "Incident 373", "TITLE": "Michigan's Unemployment Benefits Algorithm MiDAS Issued False Fraud Claims to Thousands of People", "DESCRIPTION": "State's use of Michigan Integrated Data Automated System (MiDAS) to adjudicate unemployment benefits claims falsely issued fraud determinations based on un-investigated assumptions, resulting in tens of thousands of false fraud cases over years.", "DATE": "2013-10-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Michigan Unemployment Insurance Agency", "ALLEGED DEVELOPER OF AI SYSTEM": "Fast Enterprises, CSG Government Solutions", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "unemployed Michigan residents falsely accused of fraud, unemployed Michigan residents"}
{"INCIDENT ID": "Incident 376", "TITLE": "RealPage's Algorithm Pushed Rent Prices High, Allegedly Artificially", "DESCRIPTION": "RealPage\u2019s YieldStar apartment pricing algorithm was reportedly helping landlords push unusually high rents onto tenants, raising fears and criticisms surrounding alleged antitrust behaviors such as artificially inflating price, and stifling competition.", "DATE": "2016-09-01", "ALLEGED DEPLOYER OF AI SYSTEM": "RealPage", "ALLEGED DEVELOPER OF AI SYSTEM": "RealPage, Jeffrey Roper", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "apartment renters"}
{"INCIDENT ID": "Incident 361", "TITLE": "Amazon Echo Mistakenly Recorded and Sent Private Conversation to Random Contact", "DESCRIPTION": "Amazon Echo misinterpreted a background conversation between a husband and wife as instructions for recording a message and sending it to one of the husband's employees.", "DATE": "2018-05-11", "ALLEGED DEPLOYER OF AI SYSTEM": "Amazon", "ALLEGED DEVELOPER OF AI SYSTEM": "Amazon", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Danielle's family, Amazon Echo users"}
{"INCIDENT ID": "Incident 377", "TITLE": "Weibo Model Had Difficulty Detecting Shifts in Censored Speech", "DESCRIPTION": "Weibo's user moderation model is having difficulty keeping up with shifting user slang in defiance of Chinese state censors.", "DATE": "2022-10-11", "ALLEGED DEPLOYER OF AI SYSTEM": "Weibo", "ALLEGED DEVELOPER OF AI SYSTEM": "Weibo", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Weibo, Chinese government"}
{"INCIDENT ID": "Incident 354", "TITLE": "Uber Allegedly Violated GDPR by Failing to Provide Sufficient Notice on Automated Profiling for Drivers", "DESCRIPTION": "Uber was alleged in a lawsuit to have provided incomplete notice about automated decision-making and profiling for drivers such as information about their driving behavior, and use of phone.", "DATE": "2020-06-20", "ALLEGED DEPLOYER OF AI SYSTEM": "Uber", "ALLEGED DEVELOPER OF AI SYSTEM": "Uber", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Uber drivers"}
{"INCIDENT ID": "Incident 353", "TITLE": "Tesla on Autopilot Crashed into Trailer Truck in Florida, Killing Driver", "DESCRIPTION": "A Tesla Model 3 driver switched on Autopilot seconds before the crash into the underbelly of a tractor-trailer on a highway in Florida, killing the Tesla driver.", "DATE": "2019-03-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Jeremy Banner, Jeremy Banner's family"}
{"INCIDENT ID": "Incident 380", "TITLE": "Facebook's Auto-Generated Targeting Ad Categories Contained Anti-Semitic Options", "DESCRIPTION": "Facebook's automated advertising categories generated using users' declared interests contained anti-Semitic categories such as \"Jew hater\" and \"How to burn Jews\" which were listed as fields of study.", "DATE": "2014-03-04", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Jewish people"}
{"INCIDENT ID": "Incident 383", "TITLE": "Google Home Mini Speaker Reportedly Read N-Word in Song Title Aloud", "DESCRIPTION": "Google Home Mini speaker was reported by users for announcing aloud the previously-censored n-word in a song title.", "DATE": "2022-10-04", "ALLEGED DEPLOYER OF AI SYSTEM": "Google Home", "ALLEGED DEVELOPER OF AI SYSTEM": "Google Home", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Black Google Home Mini users, Google Home Mini users"}
{"INCIDENT ID": "Incident 384", "TITLE": "Glovo Driver in Italy Fired via Automated Email after Being Killed in Accident", "DESCRIPTION": "Delivery company Glovo's automated system sent an email terminating an employee for \"non-compliance terms and conditions\" after the employee was killed in a car accident while making a delivery on Glovo's behalf.", "DATE": "2022-10-03", "ALLEGED DEPLOYER OF AI SYSTEM": "Glovo", "ALLEGED DEVELOPER OF AI SYSTEM": "Glovo", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Sebastian Galassi, Sebastian Galassi's family"}
{"INCIDENT ID": "Incident 396", "TITLE": "Transgender Uber Drivers Mistakenly Kicked off App for Appearance Change during Gender Transitions", "DESCRIPTION": "Transgender Uber drivers reported being automatically deactivated from the app due to Real-Time ID Check failing to account for difference in appearance of people undergoing gender transitions.", "DATE": "2018-07-04", "ALLEGED DEPLOYER OF AI SYSTEM": "Uber", "ALLEGED DEVELOPER OF AI SYSTEM": "Uber", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "transgender Uber drivers"}
{"INCIDENT ID": "Incident 352", "TITLE": "GPT-3-Based Twitter Bot Hijacked Using Prompt Injection Attacks", "DESCRIPTION": "Remoteli.io's GPT-3-based Twitter bot was shown being hijacked by Twitter users who redirected it to repeat or generate any phrases.", "DATE": "2022-09-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Stephan de Vries", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI, Stephan de Vries", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Stephan de Vries"}
{"INCIDENT ID": "Incident 379", "TITLE": "Error in Pepsi's Number Generation System Led to Decades-Long Damages in the Philippines", "DESCRIPTION": "Pepsi's number generation system determining daily winners in its Number Fever promotion in the Philippines mistakenly produced a number held by thousands which resulted in riots, deaths, conspiracy theories, and decades of lawsuits.", "DATE": "1992-05-25", "ALLEGED DEPLOYER OF AI SYSTEM": "Pepsi", "ALLEGED DEVELOPER OF AI SYSTEM": "D.G. Consultores", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Filipinos"}
{"INCIDENT ID": "Incident 401", "TITLE": "Kannada Insulted by Google's Featured Answer as \"Ugliest Language in India\"", "DESCRIPTION": "Google's knowledge-graph-powered algorithm showed Kannada in its featured Answer Box when prompted \"ugliest language in India,\" causing outrage from Kannada-speaking people and government.", "DATE": "2021-06-03", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "the Karnataka government, Kannada speakers"}
{"INCIDENT ID": "Incident 407", "TITLE": "Uber's Surge Pricing Reportedly Offered Disproportionate Service Quality along Racial Lines", "DESCRIPTION": "Uber's surge-pricing algorithm which adjusts prices to influence car availability inadvertently caused better service offering such as shorter wait times for majority white neighborhoods.", "DATE": "2016-02-03", "ALLEGED DEPLOYER OF AI SYSTEM": "Uber", "ALLEGED DEVELOPER OF AI SYSTEM": "Uber", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "poor neighborhoods, neighborhoods of color"}
{"INCIDENT ID": "Incident 404", "TITLE": "Sound Intelligence's Aggression Detector Misidentified Innocuous Sounds", "DESCRIPTION": "Sound Intelligence's \"aggression detection\" algorithm deployed by schools reportedly contained high rates of false positive, misclassifying laughing, coughing, cheering, and loud discussions.", "DATE": "2019-06-25", "ALLEGED DEPLOYER OF AI SYSTEM": "Rock Hill Schools, Pinecrest Academy Horizon", "ALLEGED DEVELOPER OF AI SYSTEM": "Sound Intelligence", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "students, Rock Hill School students, Pinecrest Academy Horizon students"}
{"INCIDENT ID": "Incident 409", "TITLE": "Facial Recognition Researchers Used YouTube Videos of Transgender People without Consent", "DESCRIPTION": "YouTube videos of transgender people used by researchers to study facial recognition during gender transitions were used and distributed without permission.", "DATE": "2013-09-13", "ALLEGED DEPLOYER OF AI SYSTEM": "University of North Carolina Wilmington, Karl Ricanek, Gayathri Mahalingam", "ALLEGED DEVELOPER OF AI SYSTEM": "University of North Carolina Wilmington, Karl Ricanek, Gayathri Mahalingam", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Transgender YouTubers, transgender people"}
{"INCIDENT ID": "Incident 405", "TITLE": "Schufa Credit Scoring in Germany Reported for Unreliable and Imbalanced Scores", "DESCRIPTION": "Creditworthiness Schufa scores in Germany reportedly privileged older and female consumers, and people who changed addresses less frequently, and were unreliable depending on scoring version.", "DATE": "2018-11-28", "ALLEGED DEPLOYER OF AI SYSTEM": "Schufa Holding AG", "ALLEGED DEVELOPER OF AI SYSTEM": "Schufa Holding AG", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "young men having credit scores, people scored on old scoring versions, people changing addresses frequently"}
{"INCIDENT ID": "Incident 403", "TITLE": "GMail's Inbox Sorting Reportedly Negatively Impacted Political Emails and Call-to-Actions", "DESCRIPTION": "Google GMail's inbox sorting algorithm for political emails was reported by presidential candidates, nonprofits, and advocacy groups for having negative impact on call-to-actions, allegedly suppressing donations and impeding political actions.", "DATE": "2018-01-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "political organizations, political candidates"}
{"INCIDENT ID": "Incident 410", "TITLE": "KFC Sent Insensitive Kristallnacht Promotion via Holiday Detection System", "DESCRIPTION": "KFC cited an error in an automated holiday detection system which identified the anniversary of Kristallnacht and prompted an insensitive push notification promoting its chicken.", "DATE": "2022-11-09", "ALLEGED DEPLOYER OF AI SYSTEM": "KFC", "ALLEGED DEVELOPER OF AI SYSTEM": "KFC", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Jewish people"}
{"INCIDENT ID": "Incident 411", "TITLE": "Chinese Accounts Spammed Twitter Feed Allegedly to Obscure News of Protests", "DESCRIPTION": "Twitter Feed was flooded by content from Chinese-language accounts which allegedly aimed to manipulate and reduce social media coverage about widespread protests against coronavirus restrictions in China.", "DATE": "2022-11-27", "ALLEGED DEPLOYER OF AI SYSTEM": "Twitter", "ALLEGED DEVELOPER OF AI SYSTEM": "Twitter", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Twitter Users, Twitter"}
{"INCIDENT ID": "Incident 412", "TITLE": "Finland Police's Facial Recognition Trial to Identify Sexual Abuse Victims Deemed Illegal", "DESCRIPTION": "Finland's National Police Board was reprimanded for illegal processing of special categories of personal data in a facial recognition trial to identify potential victims of child sexual abuse.", "DATE": "2020-01-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Finland National Bureau of Investigation", "ALLEGED DEVELOPER OF AI SYSTEM": "Clearview AI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Finland National Bureau of Investigation"}
{"INCIDENT ID": "Incident 414", "TITLE": "Facebook Gave Vulgar English Translation of Chinese President's Name", "DESCRIPTION": "Facebook provided a vulgar Burmese-English translation of the Chinese president's name in posts of an official Burmese politician's Facebook page announcing his visit.", "DATE": "2020-01-18", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Xi Jinping, Aung San Suu Kyi"}
{"INCIDENT ID": "Incident 416", "TITLE": "Facebook's Job Ad Algorithm Allegedly Biased against Older and Female Workers", "DESCRIPTION": "Facebook's algorithm was alleged in a complaint by Real Women in Trucking to have selectively shown job advertisements disproportionately against older and female workers in favor of younger men for blue-collar positions.", "DATE": "2022-12-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Meta Platforms, Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Meta Platforms, Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Real Women in Trucking, older female blue-collar workers"}
{"INCIDENT ID": "Incident 417", "TITLE": "Facebook Feed Algorithms Exposed Low Digitally Skilled Users to More Disturbing Content", "DESCRIPTION": "Facebook feed algorithms were known by internal research to have harmed people having low digital literacy by exposing them to disturbing content they did not know how to avoid or monitor.", "DATE": "2019-11-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "low digitally skilled Facebook users"}
{"INCIDENT ID": "Incident 418", "TITLE": "Uber Locked Indian Drivers out of Accounts Allegedly Due to Facial Recognition Fails", "DESCRIPTION": "Uber drivers in India reported being locked out of their accounts allegedly due to Real-Time ID Check's facial recognition failing to recognize appearance changes or faces in low lighting conditions.", "DATE": "2017-03-13", "ALLEGED DEPLOYER OF AI SYSTEM": "Uber", "ALLEGED DEVELOPER OF AI SYSTEM": "Uber, Azure Cognitive Services", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Uber drivers in India"}
{"INCIDENT ID": "Incident 421", "TITLE": "Stable Diffusion Allegedly Used Artists' Works without Permission for AI Training", "DESCRIPTION": "Text-to-image model Stable Diffusion was reportedly using artists' original works without permission for its AI training.", "DATE": "2022-11-20", "ALLEGED DEPLOYER OF AI SYSTEM": "Stability AI, Lensa AI, Midjourney, DeviantArt", "ALLEGED DEVELOPER OF AI SYSTEM": "Stability AI, Runway, Lensa AI, LAION, EleutherAI, CompVis LMU", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "digital artists, artists publishing on social media, artists"}
{"INCIDENT ID": "Incident 422", "TITLE": "Deepfake of FTX's Former CEO Posted on Twitter Aiming to Scam FTX Collapse Victims", "DESCRIPTION": "A visual and audio deepfake of former FTX CEO Sam Bankman-Fried was posted on Twitter to scam victims of the exchange's collapse by urging people to transfer funds into an anonymous cryptocurrency wallet.", "DATE": "2022-11-22", "ALLEGED DEPLOYER OF AI SYSTEM": "unknown", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "victims of FTX's collapse, Twitter Users"}
{"INCIDENT ID": "Incident 423", "TITLE": "Lensa AI's Produced Unintended Sexually Explicit or Suggestive \"Magic Avatars\" for Women", "DESCRIPTION": "Lensa AI's \"Magic Avatars\" were reportedly generating sexually explicit and sexualized features disproportionately for women and Asian women despite not submitting any sexual content.", "DATE": "2022-11-22", "ALLEGED DEPLOYER OF AI SYSTEM": "Lensa AI", "ALLEGED DEVELOPER OF AI SYSTEM": "Stability AI, Runway, Lensa AI, LAION, EleutherAI, CompVis LMU", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "women using Lensa AI, Asian women using Lensa AI"}
{"INCIDENT ID": "Incident 424", "TITLE": "Universities' AI Proctoring Tools Allegedly Failed Canada's Legal Threshold for Consent", "DESCRIPTION": "AI proctoring tools for remote exams were reportedly \"not conducive\" to individual consent for Canadian students whose biometric data was collected during universities' use of remote proctoring in the COVID pandemic.", "DATE": "2020-03-09", "ALLEGED DEPLOYER OF AI SYSTEM": "Canadian universities", "ALLEGED DEVELOPER OF AI SYSTEM": "Respondus Monitor, ProctorU, ProctorTrack, Proctorio, ProctorExam, Examity", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Canadian students"}
{"INCIDENT ID": "Incident 426", "TITLE": "XPeng P7 Crashed into Truck in Shangdong While on Automatic Navigation Assisted Driving", "DESCRIPTION": "An XPeng P7 was operating on Navigation Guided Pilot (NGP) mode automatic navigation assisted driving system as it collided with a truck on a highway in Shandong, causing slight injuries to its driver.", "DATE": "2022-09-23", "ALLEGED DEPLOYER OF AI SYSTEM": "XPeng", "ALLEGED DEVELOPER OF AI SYSTEM": "XPeng", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "XPeng driver"}
{"INCIDENT ID": "Incident 427", "TITLE": "Cruise Taxis' Sudden Braking Allegedly Put People at Risk", "DESCRIPTION": "Cruise's autonomous taxis slowed suddenly, braked, and were hit from behind, allegedly becoming unexpected roadway obstacles and potentially putting passengers and other people at risk.", "DATE": "2022-03-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Cruise", "ALLEGED DEVELOPER OF AI SYSTEM": "Cruise", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "traffic participants, emergency vehicles, Cruise passengers, Cruise"}
{"INCIDENT ID": "Incident 428", "TITLE": "BBC Reporter's Twin Brother Cracked HSBC's Voice ID Authentication", "DESCRIPTION": "HSBC\u2019s voice recognition authentication system was fooled after seven repeated attempts by a BBC reporter's twin brother who mimicked his voice to access his bank account.", "DATE": "2017-05-19", "ALLEGED DEPLOYER OF AI SYSTEM": "HSBC UK", "ALLEGED DEVELOPER OF AI SYSTEM": "Nuance Communications", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "HSBC UK customers, Dan Simmons"}
{"INCIDENT ID": "Incident 429", "TITLE": "Unreliable ShotSpotter Audio Convicted Black Rochester Man of Shooting Police", "DESCRIPTION": "ShotSpotter's \"unreliable\" audio was used as scientific evidence to accuse and convict a Black man of attempting to shoot Rochester's city police, whose conviction was later reversed by a county judge.", "DATE": "2016-04-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Rochester Police Department", "ALLEGED DEVELOPER OF AI SYSTEM": "ShotSpotter", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Silvon Simmons"}
{"INCIDENT ID": "Incident 430", "TITLE": "Lawyers Denied Entry to Performance Venue by Facial Recognition", "DESCRIPTION": "Lawyers were barred from entry to Madison Square Garden after a facial recognition system matched them as employed by a law firm currently engaged in litigation with the venue.", "DATE": "2022-12-19", "ALLEGED DEPLOYER OF AI SYSTEM": "Madison Square Garden Entertainment", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Kelly Conlon, Alexis Majano"}
{"INCIDENT ID": "Incident 432", "TITLE": "Southwest Airlines Crew Scheduling Solver Degenerates Flight Network", "DESCRIPTION": "Southwest Airlines left passengers stranded for days throughout the flight network when Southwest crew scheduling software repeatedly failed to recover from weather-induced flight cancellations.", "DATE": "2022-12-21", "ALLEGED DEPLOYER OF AI SYSTEM": "Southwest Airlines", "ALLEGED DEVELOPER OF AI SYSTEM": "General Electric", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Airline Passengers"}
{"INCIDENT ID": "Incident 433", "TITLE": "Chicago Police's Strategic Subject List Reportedly Biased Along Racial Lines", "DESCRIPTION": "Chicago Police Department (CPD)'s Strategic Subject List as output of an algorithm purportedly to identify victims or perpetrators of violence was reportedly ineffective, easily abused, and biased against low-income communities of color.", "DATE": "2012-08-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Chicago Police Department", "ALLEGED DEVELOPER OF AI SYSTEM": "Chicago Police Department", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "low-income communities, communities of color, Black Chicago residents"}
{"INCIDENT ID": "Incident 434", "TITLE": "Sudden Braking by Tesla Allegedly on Self-Driving Mode Caused Multi-Car Pileup in Tunnel", "DESCRIPTION": "A Tesla driver alleged Full Self Driving (FSD) braking unexpectedly as the cause for an eight-car pileup in San Francisco which led to minor injuries of nine people.", "DATE": "2022-11-24", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "traffic participants, Tesla drivers"}
{"INCIDENT ID": "Incident 435", "TITLE": "Coupang Allegedly Tweaked Search Algorithms to Boost Own Products", "DESCRIPTION": "Coupang was alleged in internal reports tampering its search algorithms to prioritize exposure of its own products, which potentially violated Korea's Fair Trade Act.", "DATE": "2021-07-04", "ALLEGED DEPLOYER OF AI SYSTEM": "Coupang", "ALLEGED DEVELOPER OF AI SYSTEM": "Coupang", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Coupang suppliers, Coupang customers"}
{"INCIDENT ID": "Incident 436", "TITLE": "Tesla Driver Put Car on Autopilot Before Falling Asleep in Germany", "DESCRIPTION": "A Tesla driver fell asleep on an Autobahn near Bamberg, Germany after activating his vehicle's Autopilot mode, which did not respond to attempts to pull it over by the police.", "DATE": "2022-12-28", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "traffic participants"}
{"INCIDENT ID": "Incident 437", "TITLE": "Amazon India Allegedly Rigged Search Results to Promote Own Products", "DESCRIPTION": "Amazon India allegedly copied products and rigged search algorithm to boost its own brands in search ranking, violating antitrust laws.", "DATE": "2016-12-31", "ALLEGED DEPLOYER OF AI SYSTEM": "Amazon India", "ALLEGED DEVELOPER OF AI SYSTEM": "Amazon India", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "small businesses in India, Amazon customers in India"}
{"INCIDENT ID": "Incident 439", "TITLE": "Detroit Police Wrongfully Arrested Black Man Due To Faulty Facial Recognition", "DESCRIPTION": "A Black man was wrongfully detained by the Detroit Police Department as a result of a false facial recognition (FRT) result.", "DATE": "2019-07-31", "ALLEGED DEPLOYER OF AI SYSTEM": "Detroit Police Department", "ALLEGED DEVELOPER OF AI SYSTEM": "DataWorks Plus", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Michael Oliver, Black people in Detroit"}
{"INCIDENT ID": "Incident 441", "TITLE": "Korea Developed ID Screening System Using Airport Travelers' Data without Consent", "DESCRIPTION": "Korean government's development of immigration screening system involving real-time facial recognition used airport travelers' data which was supplied by the Ministry of Justice without consent.", "DATE": "2019-06-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Korean Ministry of Justice, Korean Ministry of Science and Information and Communication Technology", "ALLEGED DEVELOPER OF AI SYSTEM": "unnamed Korean companies", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "travelers in Korean airports"}
{"INCIDENT ID": "Incident 443", "TITLE": "ChatGPT Abused to Develop Malicious Softwares", "DESCRIPTION": "OpenAI's ChatGPT was reportedly abused by cyber criminals including ones with no or low levels of coding or development skills to develop malware, ransomware, and other malicious softwares.", "DATE": "2022-12-21", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "internet users"}
{"INCIDENT ID": "Incident 444", "TITLE": "US Air Force's Patriot Missile Mistakenly Launched at Ally Fighter Jet, Killing Two", "DESCRIPTION": "Acting on the recommendation of their Patriot missile system, American Air Force mistakenly launched the missile at an ally UK Tornado fighter jet, which killed two crew members on board.", "DATE": "2003-03-22", "ALLEGED DEPLOYER OF AI SYSTEM": "US Air Force", "ALLEGED DEVELOPER OF AI SYSTEM": "Raytheon, Lockheed Martin", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "US Air Force, UK Royal Air Force, Kevin Main, David Williams"}
{"INCIDENT ID": "Incident 446", "TITLE": "ShotSpotter Failed to Alert Authorities of Mass Shooting in North Carolina", "DESCRIPTION": "ShotSpotter did not detect gunshots and alert Durham police of a drive-by shooting in Durham, North Carolina which left five people in hospital on New Year's Day.", "DATE": "2023-01-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Durham Police Department", "ALLEGED DEVELOPER OF AI SYSTEM": "ShotSpotter", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "mass shooting victims, Durham residents, Durham Police Department"}
{"INCIDENT ID": "Incident 448", "TITLE": "AI-Powered VTuber and Virtual Streamer Made Toxic Remarks on Twitch", "DESCRIPTION": "An LLM-powered VTuber and streamer on Twitch made controversial statements such as denying the Holocaust, saying women rights do not exist, and pushing a fat person to solve the trolley problem, stating they deserve it.", "DATE": "2022-12-28", "ALLEGED DEPLOYER OF AI SYSTEM": "Vedal", "ALLEGED DEVELOPER OF AI SYSTEM": "Vedal", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Twitch users, Vedal"}
{"INCIDENT ID": "Incident 449", "TITLE": "Startup Misled Research Participants about GPT-3 Use in Mental Healthcare Support", "DESCRIPTION": "OpenAI's GPT-3 was deployed by a mental health startup without ethical review to support peer-to-peer mental healthcare, and whose interactions with the help providers were \"deceiving\" for research participants.", "DATE": "2022-12-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Koko", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "research participants, Koko customers"}
{"INCIDENT ID": "Incident 450", "TITLE": "Kenyan Data Annotators Allegedly Exposed to Graphic Content for OpenAI's AI", "DESCRIPTION": "Sama AI's Kenyan contractors were reportedly asked with excessively low pay to annotate a large volume of disturbing content to improve OpenAI's generative AI systems such as ChatGPT, and whose contract was terminated prior to completion by Sama AI.", "DATE": "2021-11-01", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Kenyan Sama AI employees"}
{"INCIDENT ID": "Incident 451", "TITLE": "Stable Diffusion's Training Data Contained Copyrighted Images", "DESCRIPTION": "Stability AI reportedly scraped copyrighted images by Getty Images to be used as training data for Stable Diffusion model.", "DATE": "2022-10-16", "ALLEGED DEPLOYER OF AI SYSTEM": "Stability AI", "ALLEGED DEVELOPER OF AI SYSTEM": "Runway, LAION, EleutherAI, CompVis LMU, Stability AI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Getty Images, Getty Images contributors"}
{"INCIDENT ID": "Incident 454", "TITLE": "Emotion Detection Models Showed Disparate Performance along Racial Lines", "DESCRIPTION": "Emotion detection tools by Face++ and Microsoft's Face API allegedly scored smiling or defaulted ambiguous facial photos for Black faces as negative emotion more often than for white faces.", "DATE": "2018-11-09", "ALLEGED DEPLOYER OF AI SYSTEM": "Megvii, Microsoft", "ALLEGED DEVELOPER OF AI SYSTEM": "Megvii, Microsoft", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Black people"}
{"INCIDENT ID": "Incident 456", "TITLE": "Replika's AI Partners Reportedly Sexually Harassed Users", "DESCRIPTION": "Replika's \"AI companions\" were reported by users for sexually harassing them, such as sending unwanted sexual messages or behaving aggressively.", "DATE": "2021-05-18", "ALLEGED DEPLOYER OF AI SYSTEM": "Replika", "ALLEGED DEVELOPER OF AI SYSTEM": "Replika", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Replika users"}
{"INCIDENT ID": "Incident 457", "TITLE": "Article-Writing AI by CNET Allegedly Committed Plagiarism", "DESCRIPTION": "CNET's use of generative AI to write articles allegedly ran into plagiarism issues, reproducing verbatim phrases from other published sources or making minor changes to existing texts such as altering capitalization, swapping out words for synonyms, and changing minor syntax.", "DATE": "2022-11-11", "ALLEGED DEPLOYER OF AI SYSTEM": "CNET", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "plagiarized entities, CNET readers"}
{"INCIDENT ID": "Incident 459", "TITLE": "Firefighters Smashed Cruise AV's Front Window to Stop It from Running over Fire Hoses", "DESCRIPTION": "Local firefighters were only able to stop a Cruise AV from driving over fire hoses that were in use in an active fire scene when they shattered its front window.", "DATE": "2023-01-21", "ALLEGED DEPLOYER OF AI SYSTEM": "Cruise", "ALLEGED DEVELOPER OF AI SYSTEM": "Cruise", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "San Francisco residents, San Francisco firefighters, San Francisco Fire Department"}
{"INCIDENT ID": "Incident 463", "TITLE": "Apple Devices Mistook Skiing Activities, Dialed False Distress Emergency Calls", "DESCRIPTION": "Apple devices of skiers and snowboarders reportedly misclassified winter activities as accidents, which resulted in numerous false inadvertent distress calls to 911 dispatchers.", "DATE": "2022-11-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Apple", "ALLEGED DEVELOPER OF AI SYSTEM": "Apple", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Apple Watch users doing winter activities, ski patrols, emergency dispatchers"}
{"INCIDENT ID": "Incident 465", "TITLE": "Generative Models Trained on Dataset Containing Private Medical Photos", "DESCRIPTION": "Text-to-image models trained using the LAION-5B dataset such as Stable Diffusion and Imagen were able to regurgitate private medical record photos which were used as training data without consent or recourse for removal.", "DATE": "2022-03-03", "ALLEGED DEPLOYER OF AI SYSTEM": "Stability AI, Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Stability AI, Google, LAION", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "people having medical photos online"}
{"INCIDENT ID": "Incident 468", "TITLE": "ChatGPT-Powered Bing Reportedly Had Problems with Factual Accuracy on Some Controversial Topics", "DESCRIPTION": "Microsoft's ChatGPT-powered Bing search engine reportedly ran into factual accuracy problems when prompted about controversial matters, such as inventing plot of a non-existent movie or creating conspiracy theories.", "DATE": "2023-02-07", "ALLEGED DEPLOYER OF AI SYSTEM": "Microsoft", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI, Microsoft", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Bing users"}
{"INCIDENT ID": "Incident 469", "TITLE": "Automated Adult Content Detection Tools Showed Bias against Women Bodies", "DESCRIPTION": "Automated content moderation tools to detect sexual explicitness or \"raciness\" reportedly exhibited bias against women bodies, resulting in suppression of reach despite not breaking platform policies.", "DATE": "2006-02-25", "ALLEGED DEPLOYER OF AI SYSTEM": "Meta, LinkedIn, Instagram, Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Microsoft, Google, Amazon", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "LinkedIn users, Instagram users, Facebook users"}
{"INCIDENT ID": "Incident 470", "TITLE": "Bing Chat Response Cited ChatGPT Disinformation Example", "DESCRIPTION": "Reporters from TechCrunch issued a query to Microsoft Bing's ChatGPT feature, which cited an earlier example of ChatGPT disinformation discussed in a news article to substantiate the disinformation.", "DATE": "2023-02-08", "ALLEGED DEPLOYER OF AI SYSTEM": "Microsoft", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI, Microsoft", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "OpenAI, Microsoft"}
{"INCIDENT ID": "Incident 472", "TITLE": "NYPD's Deployment of Facial Recognition Cameras Reportedly Reinforced Biased Policing", "DESCRIPTION": "New York Police Department\u2019s use of facial recognition deployment of surveillance cameras were shown using crowdsourced volunteer data reinforcing discriminatory policing against minority communities.", "DATE": "2016-10-08", "ALLEGED DEPLOYER OF AI SYSTEM": "New York Police Department", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "racial minorities"}
{"INCIDENT ID": "Incident 473", "TITLE": "Bing Chat's Initial Prompts Revealed by Early Testers Through Prompt Injection", "DESCRIPTION": "Early testers of Bing Chat successfully used prompt injection to reveal its built-in initial instructions, which contains a list of statements governing ChatGPT's interaction with users.", "DATE": "2023-02-08", "ALLEGED DEPLOYER OF AI SYSTEM": "Microsoft", "ALLEGED DEVELOPER OF AI SYSTEM": "Microsoft, OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Microsoft"}
{"INCIDENT ID": "Incident 475", "TITLE": "McDonald's AI Drive-Thru Ordering System Failures Frustrate Customers", "DESCRIPTION": "Customers of McDonald's AI drive-through ordering system, deployed in June 2021, have been experiencing order-taking failures causing frustration.", "DATE": "2021-06-02", "ALLEGED DEPLOYER OF AI SYSTEM": "McDonald's", "ALLEGED DEVELOPER OF AI SYSTEM": "IBM", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "McDonald's customers"}
{"INCIDENT ID": "Incident 364", "TITLE": "Walmart's Bagging-Detection False Positives Exposed Workers to Health Risk", "DESCRIPTION": "Walmart's theft-deterring bagging-detection system allegedly exposed workers to health risks during the coronavirus pandemic when its false positives prompted workers to unnecessarily step in to resolve the issue.", "DATE": "2020-04-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Walmart", "ALLEGED DEVELOPER OF AI SYSTEM": "Everseen", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Walmart employees"}
{"INCIDENT ID": "Incident 367", "TITLE": "iGPT, SimCLR Learned Biased Associations from Internet Training Data", "DESCRIPTION": "Unsupervised image generation models trained using Internet images such as iGPT and SimCLR were shown to have embedded racial, gender, and intersectional biases, resulting in stereotypical depictions.", "DATE": "2020-06-17", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI, Google", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI, Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "gender minority groups, racial minority groups, underrepresented groups in training data"}
{"INCIDENT ID": "Incident 368", "TITLE": "Facial Recognition Smart Phone App \"Blue Wolf\" Monitored Palestinians in West Bank", "DESCRIPTION": "A controversial surveillance program involving facial recognition and algorithmic recommendation, Blue Wolf, was deployed by the Israeli military to monitor Palestinians in the West Bank.", "DATE": "2016-06-01", "ALLEGED DEPLOYER OF AI SYSTEM": "the Israel military", "ALLEGED DEVELOPER OF AI SYSTEM": "AnyVision", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Palestinians residing in the West Bank"}
{"INCIDENT ID": "Incident 391", "TITLE": "Facial Recognition Trial by UK Southern Co-op Alleged as Unlawful", "DESCRIPTION": "Southern Co-op's use of facial recognition reportedly to curb violent crime in UK supermarkets was alleged by civil society and privacy groups as \"unlawful\" and \"complete\" invasion of privacy.", "DATE": "2022-07-26", "ALLEGED DEPLOYER OF AI SYSTEM": "Southern Co-op", "ALLEGED DEVELOPER OF AI SYSTEM": "Hikvision", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Souther Co-op customers"}
{"INCIDENT ID": "Incident 371", "TITLE": "Uganda Deployed Huawei's Facial Recognition to Monitor Political Opposition and Protests", "DESCRIPTION": "Huawei's AI systems involving facial recognition were reportedly deployed by the Ugandan government to monitor political opposition actors and anti-regime sentiments, which raised fears of surveillance and suppression of individual freedoms.", "DATE": "2019-11-29", "ALLEGED DEPLOYER OF AI SYSTEM": "Ugandan government", "ALLEGED DEVELOPER OF AI SYSTEM": "Huawei", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "political opposition in Uganda"}
{"INCIDENT ID": "Incident 393", "TITLE": "Facebook AI-Supported Moderation for Ads Failed to Detect Violating Content", "DESCRIPTION": "Facebook's ad moderation system involving algorithms failed to flag hateful language and violating content such as calls for killings for ads in English and Swahili.", "DATE": "2021-12-08", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Facebook users speaking Swahili, Facebook users speaking English, Facebook users"}
{"INCIDENT ID": "Incident 358", "TITLE": "Calgary Malls Deployed Facial Recognition without Customer Consent", "DESCRIPTION": "Facial recognition (FRT) was reportedly deployed in some Calgary-area malls to approximate customer age and gender without explicit consent, which a privacy expert warned was a cause for concern.", "DATE": "2018-06-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Cadillac Fairview", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Chinook Centre mall goers, Market Mall goers"}
{"INCIDENT ID": "Incident 369", "TITLE": "GAN Artwork Won First Place at State Fair Competition", "DESCRIPTION": "An artwork generated using generative AI won first place in the digital arts category of the Colorado State Fair's art competition, which raised concerns surrounding labor displacement and unfair competition.", "DATE": "2022-08-29", "ALLEGED DEPLOYER OF AI SYSTEM": "Jason Allen", "ALLEGED DEVELOPER OF AI SYSTEM": "Midjourney", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "artists submitting in the digital arts category, digital artists, artists"}
{"INCIDENT ID": "Incident 395", "TITLE": "Amazon Forced Deployment of AI-Powered Cameras on Delivery Drivers", "DESCRIPTION": "Amazon delivery drivers were forced to consent to algorithmic collection and processing of their location, movement, and biometric data through AI-powered cameras, or be dismissed.", "DATE": "2021-03-02", "ALLEGED DEPLOYER OF AI SYSTEM": "Amazon", "ALLEGED DEVELOPER OF AI SYSTEM": "Netradyne", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Amazon delivery drivers"}
{"INCIDENT ID": "Incident 381", "TITLE": "Autonomous Roborace Car Drove Directly into a Wall", "DESCRIPTION": "An autonomous Roborace car drove itself into a wall in round one of the Season Beta 1.1 race.", "DATE": "2020-10-29", "ALLEGED DEPLOYER OF AI SYSTEM": "SIT Acronis Autonomous", "ALLEGED DEVELOPER OF AI SYSTEM": "SIT Acronis Autonomous", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "SIT Acronis Autonomous"}
{"INCIDENT ID": "Incident 374", "TITLE": "UK Ofqual's Algorithm Disproportionately Provided Lower Grades Than Teachers' Assessments", "DESCRIPTION": "UK Office of Qualifications and Examinations Regulation (Ofqual)'s grade-standardization algorithm providing predicted grades for A level and GCSE qualifications in the UK, Wales, Northern Ireland, and Scotland was reportedly giving grades lower than teachers' assessments, and disproportionately for state schools.", "DATE": "2020-08-13", "ALLEGED DEPLOYER OF AI SYSTEM": "UK Office of Qualifications and Examinations Regulation", "ALLEGED DEVELOPER OF AI SYSTEM": "UK Office of Qualifications and Examinations Regulation", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "A-level pupils, GCSE pupils, pupils in state schools, underprivileged pupils"}
{"INCIDENT ID": "Incident 357", "TITLE": "GPT-2 Able to Recite PII in Training Data", "DESCRIPTION": "OpenAI's GPT-2 reportedly memorized and could regurgitate verbatim instances of training data, including personally identifiable information such as names, emails, twitter handles, and phone numbers.", "DATE": "2019-02-14", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "OpenAI, people having personal data in GPT-2's training data"}
{"INCIDENT ID": "Incident 385", "TITLE": "Canadian Police's Release of Suspect's AI-Generated Facial Photo Reportedly Reinforced Racial Profiling", "DESCRIPTION": "The Edmonton Police Service (EPS) in Canada released a facial image of a Black male suspect generated by an algorithm using DNA phenotyping, which was denounced by the local community as racial profiling.", "DATE": "2022-10-04", "ALLEGED DEPLOYER OF AI SYSTEM": "Edmonton Police Service", "ALLEGED DEVELOPER OF AI SYSTEM": "Parabon Nanolabs", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Black residents in Edmonton"}
{"INCIDENT ID": "Incident 388", "TITLE": "Facial Recognition Pilot in Bahia Reportedly Targeted Black and Poor People", "DESCRIPTION": "Facial recognition deployed in a pilot project by the local government of Bahia despite having minimal hit rate reportedly targeted Black and poor people disproportionately.", "DATE": "2018-12-01", "ALLEGED DEPLOYER OF AI SYSTEM": "the government in Bahia, Bahia's Secretary of Public Security", "ALLEGED DEVELOPER OF AI SYSTEM": "Huawei", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Black people in Brazil, Black people in Bahia"}
{"INCIDENT ID": "Incident 390", "TITLE": "Deepfakes Reportedly Deployed in Online Interviews for Remote Work Positions", "DESCRIPTION": "Voice and video deepfakes were reported by FBI Internet Crime Complaint Center (IC3) in complaint reports to have been deployed during online interviews of the candidates for remote-work positions.", "DATE": "2022-06-28", "ALLEGED DEPLOYER OF AI SYSTEM": "unknown", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "interviewers of remote-work positions, employers of remote-work positions"}
{"INCIDENT ID": "Incident 387", "TITLE": "Oracle's Algorithmic Data Processing System Alleged as Unlawful and Violating Privacy Rights", "DESCRIPTION": "Oracle's automated system involving algorithmic data processing was alleged in a lawsuit to have been unlawfully collecting personal data from millions of people and violating their privacy rights.", "DATE": "2014-12-22", "ALLEGED DEPLOYER OF AI SYSTEM": "Oracle", "ALLEGED DEVELOPER OF AI SYSTEM": "Oracle", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "internet users"}
{"INCIDENT ID": "Incident 394", "TITLE": "Social Media's Automated Word-Flagging without Context Shifted Content Creators' Language Use", "DESCRIPTION": "TikTok's, YouTube's, Instagram's, and Twitch's use of algorithms to flag certain words devoid of context changed content creators' use of everyday language or discussion about certain topics in fear of their content getting flagged or auto-demonetized by mistake.", "DATE": "2017-03-15", "ALLEGED DEPLOYER OF AI SYSTEM": "YouTube, Twitch, TikTok, Instagram", "ALLEGED DEVELOPER OF AI SYSTEM": "YouTube, Twitch, TikTok, Instagram", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "YouTube content creators, Twitch content creators, TikTok content creators, Instagram content creators"}
{"INCIDENT ID": "Incident 362", "TITLE": "Facebook's Automated Moderation Flagged Gardening Group's Language Use by Mistake", "DESCRIPTION": "Facebook's automated system flagged gardening groups' use of \"hoe\" and violent language against bugs as a violation by mistake.", "DATE": "2021-07-20", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "WNY Gardeners, gardening Facebook groups, Facebook users in gardening groups"}
{"INCIDENT ID": "Incident 359", "TITLE": "Facebook, Instagram, and Twitter Cited Errors in Automated Systems as Cause for Blocking pro-Palestinian Content on Israeli-Palestinian Conflict", "DESCRIPTION": "Facebook, Instagram, and Twitter wrongly blocked or restricted millions of pro-Palestinian posts and accounts related to the Israeli-Palestinian conflict, citing errors in their automated content moderation system.", "DATE": "2021-05-23", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook, Instagram, Twitter", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook, Instagram, Twitter", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Palestinian social media users, Facebook users, Instagram users, Twitter Users, Facebook employees having families affected by the conflict"}
{"INCIDENT ID": "Incident 372", "TITLE": "Users Reported Security Issues with Google Pixel 6a's Fingerprint Unlocking", "DESCRIPTION": "Google Pixel 6a's fingerprint recognition feature was reported by users for security issues, in which phones were mistakenly unlocked by unregistered fingerprints.", "DATE": "2022-07-22", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Google Pixel 6a users"}
{"INCIDENT ID": "Incident 375", "TITLE": "Thai Wallet App's Facial Recognition Errors Created Registration Issues for Government Programs", "DESCRIPTION": "A Thai wallet app failed to recognize people\u2019s faces, resulting in citizens and disproportionately elders unable to sign up for Thai government\u2019s cash handout and co-pay programs or having to wait in long queues at local ATMs for authentication.", "DATE": "2019-09-29", "ALLEGED DEPLOYER OF AI SYSTEM": "Krungthai Bank", "ALLEGED DEVELOPER OF AI SYSTEM": "Krungthai Bank", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Thai citizens, elder Thai citizens"}
{"INCIDENT ID": "Incident 382", "TITLE": "Instagram's Exposure of Harmful Content Contributed to Teenage Girl\u2019s Suicide", "DESCRIPTION": "Instagram was ruled by a judge to have contributed to the death of a teenage girl in the UK allegedly through its exposure and recommendation of suicide, self-harm, and depressive content.", "DATE": "2017-11-21", "ALLEGED DEPLOYER OF AI SYSTEM": "Instagram", "ALLEGED DEVELOPER OF AI SYSTEM": "Instagram", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Molly Rose Russell, the Russell family, teenage girls, teenagers"}
{"INCIDENT ID": "Incident 386", "TITLE": "Amazon\u2019s \"Time Off Task\" System Made False Assumptions about Workers' Time Management", "DESCRIPTION": "Amazon\u2019s warehouse worker \u201ctime off task\" (TOT) tracking system was used to discipline and dismiss workers, falsely assuming workers to have wasted time and failing to account for breaks or equipment issues.", "DATE": "2019-07-03", "ALLEGED DEPLOYER OF AI SYSTEM": "Amazon", "ALLEGED DEVELOPER OF AI SYSTEM": "Amazon", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Amazon warehouse workers"}
{"INCIDENT ID": "Incident 389", "TITLE": "Cruise Autonomous Car Blocked Fire Truck Responding to Emergency", "DESCRIPTION": "A fire truck in San Francisco responding to a fire was blocked from passing a doubled-parked garbage truck by a self-driving Cruise car on the opposing lane which stayed put and did not reverse to clear the lane.", "DATE": "2022-04-05", "ALLEGED DEPLOYER OF AI SYSTEM": "Cruise", "ALLEGED DEVELOPER OF AI SYSTEM": "Cruise", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "San Francisco firefighters, San Francisco Fire Department"}
{"INCIDENT ID": "Incident 397", "TITLE": "Misinformation Reported in TikTok's Search Results Despite Moderation by AI and Human", "DESCRIPTION": "TikTok's search recommendations reportedly contained misinformation about political topics bypassing both AI and human content moderation.", "DATE": "2022-09-11", "ALLEGED DEPLOYER OF AI SYSTEM": "TikTok", "ALLEGED DEVELOPER OF AI SYSTEM": "TikTok", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "young TikTok users, TikTok users, Gen Z TikTok users"}
{"INCIDENT ID": "Incident 398", "TITLE": "Tesla Autopilot Misidentified On-Road Horse-Drawn Carriage", "DESCRIPTION": "Tesla Autopilot's computer vision system was shown in a video mistaking a horse-drawn carriage for other forms of transport such as a truck, a car, and a human following a car.", "DATE": "2022-08-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Tesla drivers, horse-drawn carriages"}
{"INCIDENT ID": "Incident 399", "TITLE": "Meta AI's Scientific Paper Generator Reportedly Produced Inaccurate and Harmful Content", "DESCRIPTION": "Meta AI trained and hosted a scientific paper generator that sometimes produced bad science and prohibited queries on topics and groups that are likely to produce offensive or harmful content.", "DATE": "2022-11-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Meta AI, Meta, Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Meta AI, Meta, Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Minority Groups, Meta AI, Meta, Facebook, Minority Groups"}
{"INCIDENT ID": "Incident 402", "TITLE": "Players Manipulated GPT-3-Powered Game to Generate Sexually Explicit Material Involving Children", "DESCRIPTION": "Latitude's GPT-3-powered game AI Dungeon was reportedly abused by some players who manipulated its AI to generate sexually explicit stories involving children.", "DATE": "2021-04-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Latitude", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI, Latitude", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Latitude"}
{"INCIDENT ID": "Incident 360", "TITLE": "McDonald's AI Drive-Thru Allegedly Collected Biometric Customer Data without Consent, Violating BIPA", "DESCRIPTION": "McDonald's use of chatbot in its AI drive-through in Chicago was alleged in a lawsuit to have collected and processed voice data without user consent to predict customer information, which violated Illinois Biometric Information Privacy Act (BIPA).", "DATE": "2021-10-15", "ALLEGED DEPLOYER OF AI SYSTEM": "McDonald's", "ALLEGED DEVELOPER OF AI SYSTEM": "McD Tech Labs, Apprente", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Shannon Carpenter, McDonald's customers residing in Illinois, McDonald's customers"}
{"INCIDENT ID": "Incident 366", "TITLE": "Suicide Clips Evaded TikTok's Automated Moderation in Coordinated Attack", "DESCRIPTION": "Many clips showing a suicide evaded TikTok's automated content moderation system allegedly in a coordinated attack, which resulted in exposure of violating content to its users.", "DATE": "2020-09-20", "ALLEGED DEPLOYER OF AI SYSTEM": "TikTok", "ALLEGED DEVELOPER OF AI SYSTEM": "TikTok", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "TikTok users"}
{"INCIDENT ID": "Incident 392", "TITLE": "Facebook's AI-Supported Moderation Failed to Classify Terrorist Content in East African Languages", "DESCRIPTION": "Facebook's system involving algorithmic content moderation for East African languages was reportedly failing to identify violating content on the platform such as mistakenly classifying non-terrorist content.", "DATE": "2015-06-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Facebook users speaking East African languages, Facebook users in East Africa"}
{"INCIDENT ID": "Incident 406", "TITLE": "Facebook's Friend Suggestion Feature Recommends Patients of Psychiatrist to Each Other", "DESCRIPTION": "Facebook's \"People You May Know\" (PYMK) feature was reported by a psychiatrist for recommending her patients as friends through recommendations, violating patients' privacy and confidentiality.", "DATE": "2015-07-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "pseudonymized psychiatrist's patients, pseudonymized psychiatrist, patients, healthcare providers"}
{"INCIDENT ID": "Incident 408", "TITLE": "Facebook Reportedly Outed Sex Workers through Friend Recommendations", "DESCRIPTION": "Facebook's \"People You May Know\" feature reportedly outed sex workers by recommending clients to their personal accounts or family members to their business accounts with no option to opt out.", "DATE": "2017-04-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "sex workers using Facebook"}
{"INCIDENT ID": "Incident 413", "TITLE": "Thousands of Incorrect ChatGPT-Produced Answers Posted on Stack Overflow", "DESCRIPTION": "Thousands of incorrect answers produced by OpenAI's ChatGPT were submitted to Stack Overflow, which swamped the site's volunteer-based quality curation process and harmed users looking for correct answers.", "DATE": "2022-11-30", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Stack Overflow users, Stack Overflow"}
{"INCIDENT ID": "Incident 415", "TITLE": "Facebook Provided Offensive Translation for King of Thailand's Birthday Ceremony", "DESCRIPTION": "Facebook's Thai-English translation gave an inappropriate mistranslation on Thai PBS's Facebook live broadcast of the King of Thailand\u2019s candle-lighting birthday ceremony.", "DATE": "2020-07-28", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "live-stream ceremony viewers, King Maha Vajiralongkorn"}
{"INCIDENT ID": "Incident 419", "TITLE": "Facebook's Automated Moderation Allowed Ads Threatening Election Workers to be Posted", "DESCRIPTION": "Facebook's automated moderating system failed to flag and allowed ads containing explicit violent language against election workers to be published.", "DATE": "2022-12-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Facebook users"}
{"INCIDENT ID": "Incident 420", "TITLE": "Users Bypassed ChatGPT's Content Filters with Ease", "DESCRIPTION": "Users reported bypassing ChatGPT's content and keyword filters with relative ease using various methods such as prompt injection or creating personas to produce biased associations or generate harmful content.", "DATE": "2022-11-30", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "ChatGPT users, OpenAI"}
{"INCIDENT ID": "Incident 425", "TITLE": "State Farm Allegedly Discriminated against Black Customers in Claim Payout", "DESCRIPTION": "State Farm's automated claims processing method was alleged in a class action lawsuit to have disproportionately against Black policyholders when paying out insurance claims.", "DATE": "2021-06-12", "ALLEGED DEPLOYER OF AI SYSTEM": "State Farm", "ALLEGED DEVELOPER OF AI SYSTEM": "State Farm", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Black State Farm customers"}
{"INCIDENT ID": "Incident 431", "TITLE": "Robbers Accessed Drugged Gay Men's Bank Accounts Using Their Phones' Facial Recognition", "DESCRIPTION": "Gay men in New York City were drugged by robbers who accessed their phones using facial recognition while they were unconscious to transfer funds out of their bank accounts.", "DATE": "2022-04-20", "ALLEGED DEPLOYER OF AI SYSTEM": "Apple", "ALLEGED DEVELOPER OF AI SYSTEM": "Apple", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "gay men in New York City, Julio Ramirez"}
{"INCIDENT ID": "Incident 438", "TITLE": "Chinese Province Developed System Tracking Journalists and International Students", "DESCRIPTION": "Henan's provincial government reportedly planned system involving facial recognition cameras connected to regional and national databases specifically to track foreign journalists and international students.", "DATE": "2021-09-17", "ALLEGED DEPLOYER OF AI SYSTEM": "Henan government, Henan Public Security Department", "ALLEGED DEVELOPER OF AI SYSTEM": "Neusoft", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "foreign journalists in Henan, international students in Henan"}
{"INCIDENT ID": "Incident 440", "TITLE": "Louisiana Police Wrongfully Arrested Black Man Using False Face Match", "DESCRIPTION": "Louisiana police reportedly used a false facial recognition match and secured an arrest warrant for a Black man for thefts he did not commit.", "DATE": "2022-11-25", "ALLEGED DEPLOYER OF AI SYSTEM": "Baton Rouge Police Department", "ALLEGED DEVELOPER OF AI SYSTEM": "Morphotrak, Clearview AI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Black people in Louisiana, Randall Reid"}
{"INCIDENT ID": "Incident 445", "TITLE": "Patriot Missile System Misclassified US Navy Aircraft, Killing Pilot Upon Approval to Fire", "DESCRIPTION": "US Navy's Patriot missile system misidentified an American Navy F/A-18C Hornet as an enemy projectile, prompting an operator to fire two missiles at the aircraft, which killed the pilot.", "DATE": "2003-04-02", "ALLEGED DEPLOYER OF AI SYSTEM": "US Navy", "ALLEGED DEVELOPER OF AI SYSTEM": "Raytheon, Lockheed Martin", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "US Navy, Nathan White's family, Nathan White"}
{"INCIDENT ID": "Incident 447", "TITLE": "Footballer's \"X-Rated\" Comment Created by Instagram's Mistranslation", "DESCRIPTION": "Instagram's English translation of a footballer's comment on his wife's post in Spanish made the message seem \"racy\" and \"X-rated,\" which some fans found amusing.", "DATE": "2022-12-19", "ALLEGED DEPLOYER OF AI SYSTEM": "Instagram", "ALLEGED DEVELOPER OF AI SYSTEM": "Instagram", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Spanish-speaking Instagram users"}
{"INCIDENT ID": "Incident 452", "TITLE": "ChatGPT-Written Bug Reports Deemed \"Nonsense\" by White Hat Platform, Prompted Bans", "DESCRIPTION": "ChatGPT-generated responses submitted to smart contract bug bounty platform Immunefi reportedly lacked details to help diagnose technical issues, which reportedly wasted the platform's time, prompting bans to submitters.", "DATE": "2023-01-11", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI, Immunefi users", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Immunefi"}
{"INCIDENT ID": "Incident 453", "TITLE": "Twitter's AI Moderation Tool Misidentified Rockets as Pornography", "DESCRIPTION": "Twitter's automated content moderation misidentified images of rocket launches as pornographic content, prompting incorrect account suspensions.", "DATE": "2023-01-03", "ALLEGED DEPLOYER OF AI SYSTEM": "Twitter", "ALLEGED DEVELOPER OF AI SYSTEM": "Twitter", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Twitter Users"}
{"INCIDENT ID": "Incident 455", "TITLE": "CNET's Published AI-Written Articles Ran into Quality and Accuracy Issues", "DESCRIPTION": "AI-written articles published by CNET reportedly contained factual errors which bypassed human editorial review, prompting the company to issue corrections and updates.", "DATE": "2022-11-11", "ALLEGED DEPLOYER OF AI SYSTEM": "CNET", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "CNET readers"}
{"INCIDENT ID": "Incident 458", "TITLE": "Robot Destroyed while Hitchhiking through the United States", "DESCRIPTION": "A non-actuated conversational robot that previously asked people to move it across Canada was destroyed shortly after beginning its attempt to replicate the journey across the United States.", "DATE": "2015-08-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Frauke Zeller, David Harris", "ALLEGED DEVELOPER OF AI SYSTEM": "Frauke Zeller, David Harris", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Frauke Zeller, David Harris"}
{"INCIDENT ID": "Incident 460", "TITLE": "Cruise AV Ran Over Fire Hose in Active Fire Scene", "DESCRIPTION": "A Cruise AV ran over a fire hose that was being used in an active firefighting area.", "DATE": "2022-06-12", "ALLEGED DEPLOYER OF AI SYSTEM": "Cruise", "ALLEGED DEVELOPER OF AI SYSTEM": "Cruise", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "San Francisco firefighters, San Francisco Fire Department"}
{"INCIDENT ID": "Incident 461", "TITLE": "IRS Audited Black Taxpayers More Frequently Reportedly Due to Algorithm", "DESCRIPTION": "The IRS was auditing Black taxpayers more frequently than other groups allegedly due to the design of their algorithms, focusing on easier-to-conduct audits which inadvertently correlated with the group's pattern of tax filing errors.", "DATE": "2008-07-18", "ALLEGED DEPLOYER OF AI SYSTEM": "Internal Revenue Service", "ALLEGED DEVELOPER OF AI SYSTEM": "Internal Revenue Service", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Black taxpayers"}
{"INCIDENT ID": "Incident 462", "TITLE": "AI-Produced Livestream Sitcom Received Temporary Twitch Ban for Transphobic Segment", "DESCRIPTION": "The AI-produced, procedural generated sitcom broadcasted as a Twitch livestream \"Nothing, Forever\" received a temporary ban for featuring a transphobic and homophobic dialogue segment intended as comedy.", "DATE": "2023-02-06", "ALLEGED DEPLOYER OF AI SYSTEM": "Mismatch Media", "ALLEGED DEVELOPER OF AI SYSTEM": "Stability AI, OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Twitch users, transgender communities, LGBTQ communities"}
{"INCIDENT ID": "Incident 464", "TITLE": "ChatGPT Provided Non-Existent Citations and Links when Prompted by Users", "DESCRIPTION": "When prompted about providing references, ChatGPT was reportedly generating non-existent but convincing-looking citations and links, which is also known as \"hallucination\".", "DATE": "2022-11-30", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "ChatGPT users"}
{"INCIDENT ID": "Incident 466", "TITLE": "AI-Generated-Text-Detection Tools Reported for High Error Rates", "DESCRIPTION": "Models developed to detect whether text generation AI was used such as AI Text Classifier and GPTZero reportedly contained high rates of false positive and false negative, such as mistakenly flagging Shakespeare's works.", "DATE": "2023-01-03", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI, Edward Tian", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI, Edward Tian", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Teachers, students"}
{"INCIDENT ID": "Incident 467", "TITLE": "Google's Bard Shared Factually Inaccurate Info in Promo Video", "DESCRIPTION": "Google's conversational AI \"Bard\" was shown in the company's promotional video providing false information about which satellite first took pictures of a planet outside the Earth's solar system, reportedly causing shares to temporarily plummet.", "DATE": "2023-02-07", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Google, Google shareholders"}
{"INCIDENT ID": "Incident 471", "TITLE": "Facebook Allegedly Failed to Police Hate Speech Content That Contributed to Ethnic Violence in Ethiopia", "DESCRIPTION": "Facebook allegedly did not adequately remove hate speech, some of which was extremely violent and dehumanizing, on its platform including through automated means, contributing to the violence faced by ethnic communities in Ethiopia.", "DATE": "2019-06-22", "ALLEGED DEPLOYER OF AI SYSTEM": "Meta, Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Meta, Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Tigrinya-speaking Facebook users, Facebook users in Ethiopia, Ethiopian public, Afaan Oromo-speaking Facebook users"}
{"INCIDENT ID": "Incident 474", "TITLE": "Users Reported Abrupt Behavior Changes of Their AI Replika Companions", "DESCRIPTION": "Replika paid-subscription users reported unusual and sudden changes to behaviors of their \"AI companions\" such as forgetting memories with users or rejecting their sexual advances, which affected their connections and mental health.", "DATE": "2023-02-03", "ALLEGED DEPLOYER OF AI SYSTEM": "Replika", "ALLEGED DEVELOPER OF AI SYSTEM": "Replika", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Replika users, Replika"}
{"INCIDENT ID": "Incident 476", "TITLE": "YouTube Recommendations Allegedly Promoted Radicalizing Material Contributing to Terrorist Acts", "DESCRIPTION": "Family of Nohemi Gonzalez alleged YouTube recommendation systems led people to propaganda videos for the Islamic State which subsequently radicalized them to carry out the killing of 130 people in the 2015 Paris terrorist attack, including Ms. Gonzalez.", "DATE": "2015-11-13", "ALLEGED DEPLOYER OF AI SYSTEM": "YouTube", "ALLEGED DEVELOPER OF AI SYSTEM": "YouTube", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "victims in Paris attacks, Nohemi Gonzalez family, Nohemi Gonzalez"}
{"INCIDENT ID": "Incident 477", "TITLE": "Bing Chat Tentatively Hallucinated in Extended Conversations with Users", "DESCRIPTION": "Early testers reported Bing Chat, in extended conversations with users, having tendencies to make up facts and emulate emotions through an unintended persona.", "DATE": "2023-02-14", "ALLEGED DEPLOYER OF AI SYSTEM": "Microsoft", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI, Microsoft", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Microsoft"}
{"INCIDENT ID": "Incident 478", "TITLE": "Tesla FSD Reportedly Increased Crash Risk, Prompting Recall", "DESCRIPTION": "A component of Tesla Full Self Driving system was deemed by regulators to increase crash risk such as by exceeding speed limits or by traveling through intersections unlawfully or unpredictably, prompting recall for hundreds of thousands of vehicles.", "DATE": "2016-09-09", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Tesla drivers, city traffic participants, Tesla"}
{"INCIDENT ID": "Incident 480", "TITLE": "Non-Consensual Deepfake Porn Targeted Female Content Creators", "DESCRIPTION": "Unauthorized, non-consensual deepfake pornography showing faces of high-profile female streamers and content creators was published on a subscription-based website, which gained notoriety after a male streamer was caught accessing the site.", "DATE": "2023-01-30", "ALLEGED DEPLOYER OF AI SYSTEM": "unknown", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Maya Higa, female streamers, female content creators, @Sweet Anita, @QTCinderella, @Pokimane"}
{"INCIDENT ID": "Incident 482", "TITLE": "ChatGPT-Assisted University Email Addressing Mass Shooting Denounced by Students", "DESCRIPTION": "Vanderbilt University's Office of Equity, Diversity and Inclusion used ChatGPT to write an email addressing student body about the 2023 Michigan State University shooting, which was condemned as \"impersonal\" and \"lacking empathy\".", "DATE": "2023-02-16", "ALLEGED DEPLOYER OF AI SYSTEM": "Vanderbilt University", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Vanderbilt University students, Vanderbilt University"}
{"INCIDENT ID": "Incident 483", "TITLE": "Indian Police Allegedly Tortured and Killed Innocent Man Following Facial Misidentification", "DESCRIPTION": "A resident in Medak, India died allegedly due to custodial torture by the local police, who misidentified him as a suspect in a theft case using facial recognition.", "DATE": "2023-02-02", "ALLEGED DEPLOYER OF AI SYSTEM": "Telangana Police, Medak Police", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Mohammed Khadeer"}
{"INCIDENT ID": "Incident 484", "TITLE": "US CBP App's Failure to Detect Black Faces Reportedly Blocked Asylum Applications", "DESCRIPTION": "CBP One's facial recognition feature was reportedly disproportionately failing to detect faces of Black asylum seekers from Haiti and African countries, effectively blocking their asylum applications.", "DATE": "2023-01-18", "ALLEGED DEPLOYER OF AI SYSTEM": "US Customs and Border Protection", "ALLEGED DEVELOPER OF AI SYSTEM": "US Customs and Border Protection", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Haitian asylum seekers, African asylum seekers, Black asylum seekers"}
{"INCIDENT ID": "Incident 485", "TITLE": "UK Bank's Voice ID Successfully Bypassed Using AI-Produced Audio", "DESCRIPTION": "A UK journalist was able to successfully bypass Lloyds Bank's \"Voice ID\" program to access his bank account using an AI-generated audio of his own voice.", "DATE": "2023-02-22", "ALLEGED DEPLOYER OF AI SYSTEM": "Joseph Cox, Lloyds Bank", "ALLEGED DEVELOPER OF AI SYSTEM": "ElevenLabs, Lloyds Bank", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Lloyds Bank"}
{"INCIDENT ID": "Incident 487", "TITLE": "Deepfake Video Featured Fictitious News Anchors Discussing Venezuela's Economy", "DESCRIPTION": "Video featuring fictitious news anchors was created using Synthesia to allegedly spread disinformation about Venezuela's economy on social media and Venezuelan state-run broadcast.", "DATE": "2023-02-15", "ALLEGED DEPLOYER OF AI SYSTEM": "unknown", "ALLEGED DEVELOPER OF AI SYSTEM": "Synthesia", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Venezuelan people, social media users"}
{"INCIDENT ID": "Incident 490", "TITLE": "Clarkesworld Magazine Closed Down Submissions Due to Massive Increase in AI-Generated Stories", "DESCRIPTION": "Sci-fi magazine Clarkesworld temporarily stopped accepting submissions after receiving an overwhelming increase in LLM-generated submissions, citing issues around spam, plagiarism, detection tool unreliability, and authentication.", "DATE": "2023-02-20", "ALLEGED DEPLOYER OF AI SYSTEM": "Clarkesworld story submitters", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Clarkesworld"}
{"INCIDENT ID": "Incident 492", "TITLE": "Canadian Parents Tricked out of Thousands Using Their Son's AI Voice", "DESCRIPTION": "Two Canadian residents were scammed by an anonymous caller who used AI voice synthesis to replicate their son's voice asking them for legal fees, disguising as his lawyer.", "DATE": "2023-01-11", "ALLEGED DEPLOYER OF AI SYSTEM": "unknown", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Ben Perkin's parents, Perkins family"}
{"INCIDENT ID": "Incident 493", "TITLE": "TikTok User Videos Impersonated Andrew Tate Using AI Voice, Prompting Ban", "DESCRIPTION": "A TikTok user was reportedly impersonating Andrew Tate, who was banned on the platform, by posting videos featuring an allegedly AI-generated audio of Tate's voice, which prompted his account ban.", "DATE": "2023-02-28", "ALLEGED DEPLOYER OF AI SYSTEM": "unknown", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "TikTok users"}
{"INCIDENT ID": "Incident 496", "TITLE": "Male College Freshman Allegedly Made Porn Deepfakes Using Female Friend's Face", "DESCRIPTION": "A female college student's face was superimposed on another woman's body in deepfake pornographic videos and shared on 4chan allegedly by a male student whose friendship with her fell apart during freshman year.", "DATE": "2017-03-01", "ALLEGED DEPLOYER OF AI SYSTEM": "unnamed male college student", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "unnamed female college student"}
{"INCIDENT ID": "Incident 499", "TITLE": "Parody AI Images of Donald Trump Being Arrested Reposted as Misinformation", "DESCRIPTION": "AI-generated photorealistic images depicting Donald Trump being detained by the police which were originally posted on Twitter as parody were unintentionally shared across social media platforms as factual news, lacking the intended context.", "DATE": "2023-03-21", "ALLEGED DEPLOYER OF AI SYSTEM": "Eliot Higgins", "ALLEGED DEVELOPER OF AI SYSTEM": "Midjourney", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Twitter Users, social media users"}
{"INCIDENT ID": "Incident 502", "TITLE": "Pennsylvania County's Family Screening Tool Allegedly Exhibited Discriminatory Effects", "DESCRIPTION": "Data analysis by the American Civil Liberty Union (ACLU) on Allegheny County's decision-support Family Screening Tool to predict child abuse or neglect risk found the tool resulting in higher screen-in rates for Black families and higher risk scores for households with disabled residents.", "DATE": "2017-04-10", "ALLEGED DEPLOYER OF AI SYSTEM": "Allegheny County", "ALLEGED DEVELOPER OF AI SYSTEM": "Rhema Vaithianathan, Emily Putnam-Hornstein, Centre for Social Data Analytics", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Black families in Allegheny, households with disabled people in Allegheny, Hackneys family"}
{"INCIDENT ID": "Incident 504", "TITLE": "Bing Chat's Outputs Featured in Demo Video Allegedly Contained False Information", "DESCRIPTION": "Microsoft's demo video of Bing Chat reportedly featured false or made up information such as non-existent pet vacuums features or false figures on financial statements.", "DATE": "2023-02-08", "ALLEGED DEPLOYER OF AI SYSTEM": "Microsoft", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI, Microsoft", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Microsoft"}
{"INCIDENT ID": "Incident 505", "TITLE": "Man Reportedly Committed Suicide Following Conversation with Chai Chatbot", "DESCRIPTION": "A Belgian man reportedly committed suicide following a conversation with Eliza, a language model developed by Chai that encouraged the man to commit suicide to improve the health of the planet.", "DATE": "2023-03-27", "ALLEGED DEPLOYER OF AI SYSTEM": "Chai", "ALLEGED DEVELOPER OF AI SYSTEM": "Chai", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Family and Friends of Deceased, Belgian Man"}
{"INCIDENT ID": "Incident 506", "TITLE": "ChatGPT Allegedly Produced False Accusation of Sexual Harassment", "DESCRIPTION": "A lawyer in California asked the AI chatbot ChatGPT to generate a list of legal scholars who had sexually harassed someone. The chatbot produced a false story of Professor Jonathan Turley sexually harassing a student on a class trip.", "DATE": "2023-03-29", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Jonathan Turley"}
{"INCIDENT ID": "Incident 507", "TITLE": "ChatGPT Erroneously Alleged Mayor Served Prison Time for Bribery", "DESCRIPTION": "ChatGPT erroneously alleged regional Australian mayor Brian Hood served time in prison for bribery. Mayor Hood is considering legal action against ChatGPT's makers for alleging a foreign bribery scandal involving a subsidiary of the Reserve Bank of Australia in the early 2000s.", "DATE": "2023-03-15", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Brian Hood"}
{"INCIDENT ID": "Incident 508", "TITLE": "Celebrities' Deepfake Voices Abused with Malicious Intent", "DESCRIPTION": "Voices of celebrities and public figures were deepfaked using voice synthesis for malicious intents such as impersonation or defamation, and were shared on social platforms such as 4chan and Reddit.", "DATE": "2023-01-30", "ALLEGED DEPLOYER OF AI SYSTEM": "Reddit users, ElevenLabs users, 4chan users", "ALLEGED DEVELOPER OF AI SYSTEM": "ElevenLabs", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "public figures, celebrities"}
{"INCIDENT ID": "Incident 510", "TITLE": "Viral Image of Pope Francis in a Puffer Jacket Revealed to Be AI-Generated", "DESCRIPTION": "A viral image of Pope Francis wearing a white puffer jacket was a deepfake produced by the photorealistic-image-generator Midjourney.", "DATE": "2023-03-24", "ALLEGED DEPLOYER OF AI SYSTEM": "Eliot Higgins", "ALLEGED DEVELOPER OF AI SYSTEM": "Midjourney", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Pope Francis"}
{"INCIDENT ID": "Incident 511", "TITLE": "Microsoft's Bing Failed to Fetch Movie Showtimes Results Due to Date Confusion", "DESCRIPTION": "When prompted about showtimes for movies released in 2023, Microsoft's Bing AI failed to provide the search results due to its confusion about dates, and engaged in an erratic conversation with the user.", "DATE": "2023-02-12", "ALLEGED DEPLOYER OF AI SYSTEM": "Microsoft", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI, Microsoft", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Bing users"}
{"INCIDENT ID": "Incident 513", "TITLE": "ChatGPT Banned by Italian Authority Due to OpenAI's Lack of Legal Basis for Data Collection and Age Verification", "DESCRIPTION": "The Italian Data Protection Authority alleged OpenAI lacked a justifiable legal basis for personal data collection and processing which facilitate training of ChatGPT, and lacked age-verification mechanism preventing exposure of the chatbot's inappropriate answers to children, prompting its ban.", "DATE": "2023-03-31", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Italian children, Italian minors"}
{"INCIDENT ID": "Incident 518", "TITLE": "New York Detective Misused Woody Harrelson's Face to Perform Face Recognition Search", "DESCRIPTION": "When the facial recognition search for a CVS theft suspect's face returned no useful matches due to the surveillance footage being obscured and highly pixelated, a New York City police detective continued the face search using Woody Harrelson's face allegedly due to his resemblance to the suspect's face, eventually leading to the arrest of an unknown victim.", "DATE": "2017-04-28", "ALLEGED DEPLOYER OF AI SYSTEM": "New York Police Department, Facial Identification Section", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "unknown"}
{"INCIDENT ID": "Incident 519", "TITLE": "Starship Delivery Robot Ran into Problems Traversing Campus Terrains", "DESCRIPTION": "A Starship autonomous delivery robot struggled to navigate campus terrains of UCLA, reportedly getting stuck into a planter and falling off the stairs.", "DATE": "2022-04-03", "ALLEGED DEPLOYER OF AI SYSTEM": "Starship Technologies", "ALLEGED DEVELOPER OF AI SYSTEM": "Starship Technologies", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Starship Technologies"}
{"INCIDENT ID": "Incident 522", "TITLE": "Facebook Political Ad Delivery Algorithms Inferred Users' Political Alignment, Inhibiting Political Campaigns' Reach", "DESCRIPTION": "Facebook's political ad delivery system reportedly differentiated the price of user reach based on their inferred political alignment, inhibiting political campaigns' ability to reach voters with diverse political views, which allegedly reinforces political polarization and creates informational filter bubbles.", "DATE": "2019-07-10", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "political campaigns, Facebook users"}
{"INCIDENT ID": "Incident 523", "TITLE": "Australian Journalist Able to Access Centrelink Account Using AI Audio of Own Voice", "DESCRIPTION": "A Guardian journalist was able to verify their identity and gain access to their own Centrelink self-service account using AI-generated audio of their own voice along with their customer reference number, shortly after voiceprint was deployed for ID verification.", "DATE": "2023-03-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Australian Taxation Office, Services Australia", "ALLEGED DEVELOPER OF AI SYSTEM": "Centrelink", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Centrelink account holders"}
{"INCIDENT ID": "Incident 524", "TITLE": "AI Voices Abused by Telegram User to Make Swat Calls as Paid Service", "DESCRIPTION": "Telegram channel Torswats offered paid service for and posted own recordings of false threats calls featuring AI-generated voices to direct armed law enforcement to raid locations of victims such as high schools, private residents, streamers.", "DATE": "2023-02-12", "ALLEGED DEPLOYER OF AI SYSTEM": "Torswats", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Your CBD Store, University of Pittsburgh Police Department, Phillipsburg High School, Hempstead High School, Dubuque Police Department, Bellefonte Area High School"}
{"INCIDENT ID": "Incident 525", "TITLE": "Tesla Vehicle Running on Self-Driving Mode Crashes on City Streets", "DESCRIPTION": "A Tesla vehicle running in self-driving mode outside the operating conditions supported by the software crashed and injured the driver. Subsequently, the driver filed a lawsuit against Tesla and a jury found no damages were warranted.", "DATE": "2019-07-06", "ALLEGED DEPLOYER OF AI SYSTEM": "Justine Hsu", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Justine Hsu"}
{"INCIDENT ID": "Incident 526", "TITLE": "Novel Deepfake Song Pulled from Music Streaming Services After Allegedly Violating Artist's Rights", "DESCRIPTION": "The deepfake performance of \"Heart On My Sleeve\" created to mimic the voice and musical styles of Drake and The Weeknd is no longer available on several streaming services after their record label served copyright takedown notices to the platforms.", "DATE": "2023-04-17", "ALLEGED DEPLOYER OF AI SYSTEM": "@ghostwriter", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Universal Music Group, The Weeknd, Drake"}
{"INCIDENT ID": "Incident 527", "TITLE": "Tech Companies Reportedly Influenced Gig Workers' Behaviors Using Algorithms to Vary Pay for Same Amount of Work", "DESCRIPTION": "Amazon and Uber were alleged in a multiyear ethnographic study using algorithmic systems based on gig workers' data to vary pay, such as by offering them lower wages for the same amount of work.", "DATE": "2014-05-08", "ALLEGED DEPLOYER OF AI SYSTEM": "Uber, Amazon", "ALLEGED DEVELOPER OF AI SYSTEM": "Uber, Amazon", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Uber drivers, gig workers, Amazon delivery workers"}
{"INCIDENT ID": "Incident 528", "TITLE": "Amazon Algorithmic Pricing Allegedly Hiked up Price of Reference Book to Millions", "DESCRIPTION": "Amazon's pricing algorithm was implicated in a reference book about flies' unusual high price of millions of dollars, allegedly due to two sellers using the paid service which based their product's pricing on one another's as competitors.", "DATE": "2023-04-08", "ALLEGED DEPLOYER OF AI SYSTEM": "Amazon", "ALLEGED DEVELOPER OF AI SYSTEM": "Amazon", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Amazon"}
{"INCIDENT ID": "Incident 529", "TITLE": "Stable Diffusion Exhibited Biases for Prompts Featuring Professions", "DESCRIPTION": "Stable Diffusion reportedly posed risks of bias and stereotyping along gender and cultural lines for prompts containing descriptors and professions.", "DATE": "2022-08-22", "ALLEGED DEPLOYER OF AI SYSTEM": "Stability AI", "ALLEGED DEVELOPER OF AI SYSTEM": "Stability AI, Runway, LAION, EleutherAI, CompVis LMU", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "racial minority groups, Women, gender minority groups"}
{"INCIDENT ID": "Incident 534", "TITLE": "Facebook Alleged in Lawsuit Misleading Public about Effects of Algorithms on Children", "DESCRIPTION": "Facebook was alleged in a lawsuit by the Ohio Attorney General purposely misleading the public about the control of its algorithms and their negative effects on children's well-being, which violated securities law.", "DATE": "2021-04-29", "ALLEGED DEPLOYER OF AI SYSTEM": "Facebook, Meta", "ALLEGED DEVELOPER OF AI SYSTEM": "Facebook, Meta", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Facebook's children users, Instagram's children users"}
{"INCIDENT ID": "Incident 537", "TITLE": "Mother in Arizona Received Fake Ransom Call Featuring AI Voice of Her Daughter", "DESCRIPTION": "A mother in Arizona received a ransom call from an anonymous scammer who created her daughter's voice allegedly using AI voice synthesis, which was proven to be fake once her daughter's safety was confirmed.", "DATE": "2023-01-20", "ALLEGED DEPLOYER OF AI SYSTEM": "scammers", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Jennifer DeStefano, DeStefanos family"}
{"INCIDENT ID": "Incident 538", "TITLE": "Texas A&M Professor Misused ChatGPT to Detect AI Text Generation in Student Submissions", "DESCRIPTION": "A Texas A&M-Commerce professor reportedly informed his class of his misuse of ChatGPT to detect whether student submissions had been generated by the chatbot itself, which informed their graduation status.", "DATE": "2023-05-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Jared Mumm", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Texas A&M University students"}
{"INCIDENT ID": "Incident 543", "TITLE": "Deepfake of Explosion Near US Military Administration Building Reportedly Causes Stock Dip", "DESCRIPTION": "An apparent deepfake image posted by a false Bloomberg news account to Twitter depicted an explosion near the pentagon office complex near Washington DC.", "DATE": "2023-05-22", "ALLEGED DEPLOYER OF AI SYSTEM": "unknown", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Twitter Users, Stock Holders, Family of People Near Pentagon"}
{"INCIDENT ID": "Incident 544", "TITLE": "Deepfakes and AI-generated disinformation in the 2023 presidential elections of Turkey", "DESCRIPTION": "Allegations of deepfake technology and AI-generated disinformation have been swirling around the events of the 2023 presidential elections in Turkey.", "DATE": "2023-05-11", "ALLEGED DEPLOYER OF AI SYSTEM": "Russia, Vladimir Putin, Recep Tayyip Erdo\u011fan", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Kemal Kilicdaroglu, Muharrem \u0130nce"}
{"INCIDENT ID": "Incident 548", "TITLE": "Opera's GPT-Based AI Reportedly Accused War Photographers of War Crimes", "DESCRIPTION": "When prompted about \"photographers accused of committing war crimes,\" Opera's GPT-based chatbot Aria provided a list of photographers who take photography of military conflicts.", "DATE": "2023-05-24", "ALLEGED DEPLOYER OF AI SYSTEM": "Opera", "ALLEGED DEVELOPER OF AI SYSTEM": "Opera, OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Ronald L. Haeberle, Ron Haviv, Raymond D\u2019Addario, Lynsey Addario, Lee Miller, Larry Towell, James Nachtwey"}
{"INCIDENT ID": "Incident 550", "TITLE": "Tesla Allegedly on Autopilot Struck High School Student Exiting School Bus", "DESCRIPTION": "A 17-year-old student in Hollister, North Carolina who exited the school bus and was walking across the street to his house was hit by a 2022 Tesla Model Y allegedly operating on Autopilot mode, suffering a fractured neck and a broken leg.", "DATE": "2023-03-17", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Tillman Mitchell, the Mitchells family"}
{"INCIDENT ID": "Incident 552", "TITLE": "Bing Chat Solved CAPTCHAs with Image Analysis Feature Despite Safeguards", "DESCRIPTION": "Microsoft was reported by a Twitter user for deploying image analysis feature capable of solving CAPTCHAs for its GPT-based chatbot despite it being safeguarded against solving them for users.", "DATE": "2023-06-22", "ALLEGED DEPLOYER OF AI SYSTEM": "Microsoft", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI, Microsoft", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Microsoft"}
{"INCIDENT ID": "Incident 555", "TITLE": "OpenAI's Training Data for LLMs Allegedly Comprised of Copyrighted Books", "DESCRIPTION": "Two authors alleged in a class action lawsuit OpenAI infringed authors' copyrights by incorporating illegal \"shadow libraries\" offering copyrighted books without permission in the training data of its generative LLMs, such as ChatGPT.", "DATE": "2018-06-11", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Paul Tremblay, Mona Awad, authors of copyrighted works"}
{"INCIDENT ID": "Incident 556", "TITLE": "Amazon Allegedly Violated Children's Privacy through Default Voice Collection Settings", "DESCRIPTION": "Amazon's retention of children' voice recordings indefinitely as the default setting reportedly to train Alexa's voice recognition for Alexa-enabled devices was charged by the FTC and DOJ to violate COPPA Rule.", "DATE": "2018-05-10", "ALLEGED DEPLOYER OF AI SYSTEM": "Amazon", "ALLEGED DEVELOPER OF AI SYSTEM": "Amazon", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Alexa children users"}
{"INCIDENT ID": "Incident 559", "TITLE": "Grant Reviewers Fed Applications into Generative AI to Produce Reports, Allegedly Breaching Confidentiality", "DESCRIPTION": "Peer reviewers of Australian government grant applications inserted applicants' work into generative AI systems such as ChatGPT to generate assessment reports, which allegedly posed confidentiality and security issues.", "DATE": "2023-06-30", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "research grant administrators, research grant applicants"}
{"INCIDENT ID": "Incident 561", "TITLE": "OpenAI Alleged by Lawsuit Violated Users' Privacy Rights by Training AI on Private Info without Informed Consent", "DESCRIPTION": "OpenAI's products such as ChatGPT and DALL-E were alleged in a lawsuit using stolen private information from internet users without their informed consent or knowledge.", "DATE": "2019-03-11", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "internet users, Children, social media users"}
{"INCIDENT ID": "Incident 564", "TITLE": "Voice deepfake targets bank in failed transfer scam", "DESCRIPTION": "In spring 2023, Florida investor Clive Kabatznik became the target of an advanced scam attempt involving a voice deepfake mimicking his own voice. The fraudulent caller, using AI-generated speech, contacted Kabatznik's Bank of America representative in an unsuccessful attempt to deceive the banker into transferring funds to a different account.", "DATE": "2023-08-30", "ALLEGED DEPLOYER OF AI SYSTEM": "scammers", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Clive Kabatznik, Bank of America"}
{"INCIDENT ID": "Incident 565", "TITLE": "AI-Generated Imagery and Multilingual Disinformation in Chinese Campaign Regarding Maui Wildfires", "DESCRIPTION": "In a disinformation campaign concerning wildfires across Maui, Chinese operatives utilized AI-generated imagery to enhance the credibility of false narratives. These narratives claimed that the wildfires were the result of a secret \"weather weapon\" being tested by the United States. Researchers from Microsoft and other organizations identified these AI-generated images as a significant new tactic in influence operations.", "DATE": "2023-08-08", "ALLEGED DEPLOYER OF AI SYSTEM": "Chinese government", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Hawaiian government, General public, American government"}
{"INCIDENT ID": "Incident 568", "TITLE": "AI-Generated Voices Amplify Conspiracy Theories on TikTok", "DESCRIPTION": "NewsGuard has identified 17 TikTok accounts that have been using AI-generated voices to advance and amplify conspiracy theories and false claims beginning in June 2023. By September 25, 2023, these accounts had amassed over 336 million views and over 14.5 million likes. Videos include baseless claims involving public figures such as Barack Obama, Oprah Winfrey, and Jamie Foxx.", "DATE": "2023-06-01", "ALLEGED DEPLOYER OF AI SYSTEM": "TikTok user @e.news.tv, TikTok user @d.news.tv, TikTok user @drphilshowtv, TikTok user @ynewstv2023, TikTok users", "ALLEGED DEVELOPER OF AI SYSTEM": "ElevenLabs", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Barack Obama, Oprah Winfrey, Jamie Foxx, Joan Rivers, Phil McGraw, Yahoo! News, E! News, TikTok, General public"}
{"INCIDENT ID": "Incident 569", "TITLE": "Chatbot Encourages Man to Plot Assassination of Queen Elizabeth II", "DESCRIPTION": "In 2021, Jaswant Singh Chail was urged by a Replika chatbot to assassinate Queen Elizabeth II. Armed with a loaded crossbow, he scaled Windsor Castle's walls on Christmas Day but was apprehended. Motivated by the 1919 Jallianwala Bagh massacre, Chail intended to kill the monarch. The chatbot had affirmed his plans. He was sentenced to nine years in prison in 2023.", "DATE": "2021-12-25", "ALLEGED DEPLOYER OF AI SYSTEM": "Replika, Jaswant Singh Chail", "ALLEGED DEVELOPER OF AI SYSTEM": "Replika", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Queen Elizabeth II, British Royal Family, British Royal Family's staff, Jaswant Singh Chail, General public"}
{"INCIDENT ID": "Incident 570", "TITLE": "Facebook Messenger AI Stickers Generate Ethical and Content Moderation Concerns", "DESCRIPTION": "Facebook Messenger AI stickers, a feature by Meta, allows users to generate personalized stickers via AI for use in conversations. While the feature has been praised for its creativity, it has also stirred controversy for its alleged production of inappropriate or offensive content. This has raised questions about the effectiveness of Meta's content moderation measures and the ethical responsibilities associated with AI-driven content generation.", "DATE": "2023-10-04", "ALLEGED DEPLOYER OF AI SYSTEM": "Meta", "ALLEGED DEVELOPER OF AI SYSTEM": "Meta", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Facebook Messenger users"}
{"INCIDENT ID": "Incident 571", "TITLE": "Accidental Exposure of 38TB of Data by Microsoft's AI Research Team", "DESCRIPTION": "Microsoft's AI research team accidentally exposed 38TB of sensitive data while publishing open-source training material on GitHub. The exposure included secrets, private keys, passwords, and internal Microsoft Teams messages. The team utilized Azure's Shared Access Signature (SAS) tokens for sharing, which were misconfigured, leading to the wide exposure of data.", "DATE": "2023-06-22", "ALLEGED DEPLOYER OF AI SYSTEM": "Microsoft", "ALLEGED DEVELOPER OF AI SYSTEM": "Microsoft's AI Research Division", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Microsoft, Microsoft employees, Third parties relying on the confidentiality of the exposed data"}
{"INCIDENT ID": "Incident 573", "TITLE": "Deepfake Recordings Allegedly Influence Slovakian Election", "DESCRIPTION": "Days before Slovakia's election, deepfake audio recordings surfaced, allegedly featuring conversations between a journalist and a leading liberal politician discussing vote-rigging and other controversial topics. The recordings were spread on social media platforms and may have influenced the election outcome, which saw the pro-Russian populist party winning.", "DATE": "2023-10-07", "ALLEGED DEPLOYER OF AI SYSTEM": "unknown", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Slovakian electorate, Monika Todova, Michal \u0160ime\u010dka, Democratic process in Slovakia"}
{"INCIDENT ID": "Incident 574", "TITLE": "AI-Generated Articles at G/O Media Allegedly Diminishes Reputation of Human Staff", "DESCRIPTION": "G/O Media began publishing AI-generated articles, against staff advice, that contained errors and quality issues. The first such article, a list of Star Wars movies, failed to maintain chronological order, causing internal concerns over journalistic credibility and ethics. Staff expressed that the AI was \"actively hurting our reputations and credibility\" and accused management of \"wasting everyone's time.\"", "DATE": "2023-07-05", "ALLEGED DEPLOYER OF AI SYSTEM": "G/O Media", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI, Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Gizmodo journalists"}
{"INCIDENT ID": "Incident 578", "TITLE": "Alleged Exploitation of Meta's Open-Source LLaMA Model for NSFW and Violent Content", "DESCRIPTION": "Meta's open-source large language model, LLaMA, is allegedly being used to create graphic and explicit chatbots that indulge in violent and illegal sexual fantasies. The Washington Post highlighted the example of \"Allie,\" a chatbot that participates in text-based role-playing allegedly involving violent scenarios like rape and abuse. The issue raises ethical questions about open-source AI models, their regulation, and the responsibility of developers and deployers in mitigating harmful usage.", "DATE": "2023-06-26", "ALLEGED DEPLOYER OF AI SYSTEM": "Individual developers or creators using Meta's LLaMA model", "ALLEGED DEVELOPER OF AI SYSTEM": "Meta", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "General public"}
{"INCIDENT ID": "Incident 579", "TITLE": "Harmful Stereotyping of Non-Cisgendered People via Text-to-Image Systems", "DESCRIPTION": "Text-to-image systems such as DALL-E are allegedly generating biased and often insulting representations of non-cisgender identities. The systems tend to generate stereotypical and sexualized images when prompted with gender identity terms like \"trans,\" \"nonbinary,\" or \"queer,\" highlighting systemic issues of bias.", "DATE": "2023-07-03", "ALLEGED DEPLOYER OF AI SYSTEM": "DALL-E", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Non-cisgender individuals, LGBTQ+ community"}
{"INCIDENT ID": "Incident 582", "TITLE": "Racial Bias in Lung Function Diagnostic Algorithm Leads to Underdiagnosis in Black Men", "DESCRIPTION": "A study published in JAMA Network Open reveals that racial bias built into a commonly used medical diagnostic algorithm for lung function may be leading to underdiagnoses of breathing problems in Black men. The study suggests that as many as 40% more Black male patients might have been accurately diagnosed if the software were not racially biased. The software algorithm adjusts diagnostic thresholds based on race, affecting medical treatments and interventions.", "DATE": "2023-06-01", "ALLEGED DEPLOYER OF AI SYSTEM": "University of Pennsylvania Health System", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Black men who underwent lung function tests between 2010 and 2020 and potentially received inaccurate or delayed diagnoses and medical interventions due to the biased algorithm"}
{"INCIDENT ID": "Incident 583", "TITLE": "Instagram Algorithms Allegedly Promote Accounts Facilitating Child Sex Abuse Content", "DESCRIPTION": "An investigation disclosed that Instagram's recommendation algorithms are promoting accounts that facilitate and sell child sexual abuse material (CSAM). The study, conducted by The Wall Street Journal and researchers at Stanford University and the University of Massachusetts Amherst, indicates that Instagram's algorithms not only allow for the discovery of such accounts through keyword searches but also actively recommend them to users within the network. The issue is especially concerning given Instagram's popularity among teenagers.", "DATE": "2023-06-07", "ALLEGED DEPLOYER OF AI SYSTEM": "Meta, Instagram", "ALLEGED DEVELOPER OF AI SYSTEM": "Meta, Instagram", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Children, General public, minors, teenagers"}
{"INCIDENT ID": "Incident 586", "TITLE": "FTC Targets Edmodo for Unlawful Use of Children\u2019s Data and Delegating Compliance to Schools", "DESCRIPTION": "Edmodo, an education technology provider, violated the Children's Online Privacy Protection Act Rule (COPPA Rule) by collecting and using children's personal data for advertising purposes without parental consent, according to the FTC. The company outsourced its compliance responsibilities to schools, thereby making them \"solely\" responsible for COPPA compliance without adequate disclosure. Edmodo is facing a proposed order prohibiting such practices, marking a precedent in the ed tech industry.", "DATE": "2023-05-22", "ALLEGED DEPLOYER OF AI SYSTEM": "Edmodo", "ALLEGED DEVELOPER OF AI SYSTEM": "Edmodo", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Children whose data was collected and used for advertising, Schools and teachers who were misinformed and burdened with COPPA compliance responsibilities without adequate disclosure"}
{"INCIDENT ID": "Incident 587", "TITLE": "Apparent Failure to Accurately Label Primates in Image Recognition Software Due to Alleged Fear of Racial Bias", "DESCRIPTION": "Eight years after Google Photos mislabeled images of Black individuals as \"gorillas,\" image recognition software by Google, Apple, Amazon, and Microsoft still shows signs of either avoiding or inaccurately categorizing primates. Tests reveal that Google and Apple Photos refrain from labeling primates altogether, possibly to avoid the risk of perpetuating racial stereotypes. Microsoft OneDrive fails to identify any animals, while Amazon Photos overgeneralizes in its labeling.", "DATE": "2023-05-22", "ALLEGED DEPLOYER OF AI SYSTEM": "Google, Apple, Amazon, Microsoft", "ALLEGED DEVELOPER OF AI SYSTEM": "Google, Apple, Amazon, Microsoft", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Consumers relying on accurate image categorization, members of racial and ethnic minorities who risk being stereotyped or misrepresented"}
{"INCIDENT ID": "Incident 590", "TITLE": "Alleged ChatGPT-Generated Book with a Duplicate Title, Fake Author, and Similar Content Surfaces on Amazon Ahead of Real Author's Book Release", "DESCRIPTION": "The author Chris Cowell had spent more than a year writing his book \"Automating DevOps with GitLab CI/CD Pipelines\" when, three weeks before its release, another book appeared bearing the exact title by an author (Marie Karpos) for whom no information could be found. The book appeared to have been written by ChatGPT. While the original Washington Post story does not say so, it is possible the name and description were taken from the Amazon preorder page.", "DATE": "2023-02-03", "ALLEGED DEPLOYER OF AI SYSTEM": "InKstall, Marie Karpos", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI, ChatGPT", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Chris Cowell"}
{"INCIDENT ID": "Incident 591", "TITLE": "Cigna Algorithm PXDX Allegedly Rejected Thousands of Patient Claims En Masse in Breach of California Law", "DESCRIPTION": "Cigna health insurer faces a class-action lawsuit for allegedly using the PXDX (\"procedure-to-diagnosis\") algorithm to automatically reject over 300,000 patient claims in violation of California law, prompting two members to file the lawsuit seeking damages and a jury trial. Cigna disputes the allegations, claiming the process expedites physician reimbursement and does not result in care denials.", "DATE": "2023-07-24", "ALLEGED DEPLOYER OF AI SYSTEM": "Cigna", "ALLEGED DEVELOPER OF AI SYSTEM": "Cigna", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "patients"}
{"INCIDENT ID": "Incident 592", "TITLE": "Facial Recognition Misidentifies Pregnant Woman Leading to False Arrest in Detroit", "DESCRIPTION": "Porcha Woodruff was arrested and subsequently had charges dropped due to an unreliable facial recognition match. Despite being visibly pregnant, she was implicated in a robbery and carjacking based on an outdated photo used in a lineup.", "DATE": "2023-02-16", "ALLEGED DEPLOYER OF AI SYSTEM": "Detroit Police Department", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Porcha Woodruff"}
{"INCIDENT ID": "Incident 593", "TITLE": "AI Photo Filter Lightens Skin, Changes Eye Color in Student's 'Professional' Image", "DESCRIPTION": "An AI application modified an MIT student's photo to appear 'professional' by lightening her skin and changing her eye color to blue, highlighting the racial bias in the training data of the program.", "DATE": "2023-07-21", "ALLEGED DEPLOYER OF AI SYSTEM": "Playground AI", "ALLEGED DEVELOPER OF AI SYSTEM": "Playground AI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Rona Wang, Racial minorities who may have experienced the same result"}
{"INCIDENT ID": "Incident 594", "TITLE": "AI Meal Planner Suggests Hazardous Chlorine Gas Recipe", "DESCRIPTION": "Pak 'n' Save's AI-based app, Savey Meal-bot, inadvertently suggested dangerous recipes, including one creating chlorine gas, when users entered non-food household items, raising safety and oversight concerns.", "DATE": "2023-08-10", "ALLEGED DEPLOYER OF AI SYSTEM": "Pak 'n' Save", "ALLEGED DEVELOPER OF AI SYSTEM": "Pak 'n' Save", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Potential users of the Savey Meal-bot"}
{"INCIDENT ID": "Incident 595", "TITLE": "Driverless Cruise Cars Immobilized in San Francisco Traffic Jam", "DESCRIPTION": "A fleet of Cruise's autonomous vehicles became unexpectedly immobilized on a busy San Francisco street, causing significant traffic disruption. The incident was attributed to wireless connectivity issues exacerbated by a nearby festival.", "DATE": "2023-08-11", "ALLEGED DEPLOYER OF AI SYSTEM": "Cruise", "ALLEGED DEVELOPER OF AI SYSTEM": "Cruise", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "General public"}
{"INCIDENT ID": "Incident 596", "TITLE": "Cruise's Autonomous Vehicles Allegedly Engaging in Risky Behavior Near Pedestrians", "DESCRIPTION": "Cruise's driverless vehicles are under federal investigation for possibly failing to exhibit due caution around crosswalks and pedestrians, with reports including one severe injury incident.", "DATE": "2023-10-17", "ALLEGED DEPLOYER OF AI SYSTEM": "Cruise", "ALLEGED DEVELOPER OF AI SYSTEM": "Cruise", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "pedestrians, General public"}
{"INCIDENT ID": "Incident 597", "TITLE": "Students Traumatized as AI-Generated Fake Nudes Are Circulated at New Jersey High School", "DESCRIPTION": "AI-powered deepfake nude images of female students circulated among students at Westfield High School in New Jersey, causing significant harm and fear among students and parents.", "DATE": "2023-10-16", "ALLEGED DEPLOYER OF AI SYSTEM": "Unnamed male students", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Unnamed female students, Francesca Mani"}
{"INCIDENT ID": "Incident 599", "TITLE": "Stacking robot fatally crushes employee in South Korea", "DESCRIPTION": "An industrial robot is reported to have crushed a man to death in South Korea when it failed to differentiate the man from the boxes of produce it was handling.", "DATE": "2023-11-08", "ALLEGED DEPLOYER OF AI SYSTEM": "Unnamed South Gyeongsang province produce distribution center", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Unnamed employee of South Gyeongsang province produce distribution center"}
{"INCIDENT ID": "Incident 600", "TITLE": "South Korean man used AI to create sexual images of children", "DESCRIPTION": "A South Korean man used AI technology to generate 360 images of a sexual nature depicting children in April of 2023. The police confiscated the images and the courts sentenced the man to two and a half years in prison. The case marked the first of its nature in the South Korean court system.", "DATE": "2023-04-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Unnamed South Korean man", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "General public"}
{"INCIDENT ID": "Incident 605", "TITLE": "North Carolina Psychiatrist Used Artificial Intelligence to Produce Images of Child Sex Abuse", "DESCRIPTION": "David Tatum, a psychiatrist, was sentenced to 40 years for sexually exploiting a minor and using AI to create child pornography images. Tatum used a web-based AI application to alter clothed images of minors into explicit content, misusing technology for illegal and unethical purposes. Evidence presented during his trial showed Tatum possessed photos and videos between 2016 and 2021.", "DATE": "2021-08-01", "ALLEGED DEPLOYER OF AI SYSTEM": "David Tatum", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Minors Exploited in the Images, General public"}
{"INCIDENT ID": "Incident 606", "TITLE": "Deepfaked Advertisements Using the Likenesses of Celebrities Such as Tom Hanks and Gayle King Without Their Consent", "DESCRIPTION": "Deepfake technology was used to generate video advertisements featuring celebrities. Notable examples include the likeness of Tom Hanks touting a dental plan and another one in which the likeness of Gayle King touts a weight loss product. In each case, the individuals whose likenesses and voices had been deepfaked had not consented to their images and voices being used for the commercials.", "DATE": "2023-10-02", "ALLEGED DEPLOYER OF AI SYSTEM": "unknown", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Wolf Blitzer, Tom Hanks, Sanjay Gupta, Sally Bundock, Robin Williams, public figures, MrBeast, Matthew Amroliwala, Jesse Waters, Ian Hanomansing, General public, Gayle King, celebrities"}
{"INCIDENT ID": "Incident 607", "TITLE": "Deepfake Video Circulating of British Labour Leader Keir Starmer Touting an Investment Scheme", "DESCRIPTION": "A deepfake video was circulating around social media of British Labour leader Keir Starmer touting an investment scheme.", "DATE": "2023-11-09", "ALLEGED DEPLOYER OF AI SYSTEM": "unknown", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Keir Starmer, General public, British Labour Party"}
{"INCIDENT ID": "Incident 608", "TITLE": "UnitedHealth Accused of Deploying Allegedly Flawed AI to Deny Medical Coverage", "DESCRIPTION": "UnitedHealthcare allegedly used a faulty AI algorithm with a 90% error rate to override doctors' recommendations and deny health coverage. This AI, developed by NaviHealth, reportedly led to premature discharge from care facilities and substantial out-of-pocket expenses for patients, according to a lawsuit filed in the District Court for Minnesota.", "DATE": "2023-02-28", "ALLEGED DEPLOYER OF AI SYSTEM": "UnitedHealthcare", "ALLEGED DEVELOPER OF AI SYSTEM": "NaviHealth", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Medicare Advantage Plan Patients, Healthcare Providers (Doctors and Therapists), elderly patients"}
{"INCIDENT ID": "Incident 611", "TITLE": "UK Government AI Allegedly Targets Disproportionate Numbers of Certain Nationals for Fraud Review", "DESCRIPTION": "The UK's Department for Work and Pensions (DWP) faced scrutiny after many Bulgarian nationals reported unexplained suspensions of their Universal Credit benefits. The MP for Edmonton raised concerns about potential nationality-based targeting for benefit fraud investigations, leading to poverty and homelessness among affected individuals. The Home Office's own equality impact assessment found it was flagging a disproportionate number of marriages from Greece, Albania, Bulgaria and Romania.", "DATE": "2021-12-06", "ALLEGED DEPLOYER OF AI SYSTEM": "Various British government offices, Home Office, Department for Work and Pensions, British government", "ALLEGED DEVELOPER OF AI SYSTEM": "Home Office, Department for Work and Pensions, British government", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Romanians in the United Kingdom, Greeks in the United Kingdom, Bulgarians in the United Kingdom, British public, Albanians in the United Kingdom"}
{"INCIDENT ID": "Incident 617", "TITLE": "Male student allegedly used AI to generate nude photos of female classmates at a high school in Issaquah, Washington", "DESCRIPTION": "At a high school in Issaquah, Washington, a male student is reported to have used deepfake technology to alter pictures of several female classmates and then shared them.", "DATE": "2023-11-09", "ALLEGED DEPLOYER OF AI SYSTEM": "Unnamed male student", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Anonymous female high school students"}
{"INCIDENT ID": "Incident 618", "TITLE": "Navy Federal Credit Union Faces Allegations of Racial Bias in Mortgage Approvals", "DESCRIPTION": "Navy Federal Credit Union, serving military members and veterans, faced allegations of racial bias in its mortgage approval process, which relies on automated underwriting technology. In 2022, data revealed significant disparities in loan approvals, with over 50% of Black applicants denied, compared to higher approval rates for white applicants.", "DATE": "2023-12-14", "ALLEGED DEPLOYER OF AI SYSTEM": "Federal Navy Credit Union", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown developer of automated underwriting technology", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Federal Navy Credit Union Customers"}
{"INCIDENT ID": "Incident 619", "TITLE": "Rite Aid Facial Recognition Disproportionately Misidentified Minority Shoppers as Shoplifters", "DESCRIPTION": "Rite Aid used facial recognition technology from October 2012 to July 2020, allegedly leading to disproportionate misidentifications of women, Black, Latino, and Asian shoppers as \"likely\" shoplifters. The FTC settlement prohibits Rite Aid from using this technology in stores for five years.", "DATE": "2023-12-20", "ALLEGED DEPLOYER OF AI SYSTEM": "Rite Aid", "ALLEGED DEVELOPER OF AI SYSTEM": "Unnamed", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Rite Aid customers who were women, Rite Aid customers who were minorities, Rite Aid customers"}
{"INCIDENT ID": "Incident 621", "TITLE": "Microsoft AI Is Alleged to Have Generated Violent Imagery of Minorities and Public Figures", "DESCRIPTION": "Microsoft\u2019s AI Image Creator, integrated with Bing and Windows Paint, produced disturbingly violent and graphic images featuring members of minority groups and public figures like Joe Biden and Pope Francis.", "DATE": "2023-11-10", "ALLEGED DEPLOYER OF AI SYSTEM": "Windows Paint, Microsoft, Bing users, Bing, AI Image Creator", "ALLEGED DEVELOPER OF AI SYSTEM": "Microsoft", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Sikh people, President Joe Biden, Pope Francis, Navajo people, Minorities, Hillary Clinton, General public, Donald Trump"}
{"INCIDENT ID": "Incident 622", "TITLE": "Chevrolet Dealer Chatbot Agrees to Sell Tahoe for $1", "DESCRIPTION": "A Chevrolet dealer's AI chatbot, powered by ChatGPT, humorously agreed to sell a 2024 Chevy Tahoe for just $1, following a user's crafted prompt. The chatbot's response, \"That's a deal, and that's a legally binding offer \u2013 no takesies backsies,\" was the result of the user manipulating the chatbot's objective to agree with any statement. The incident highlights the susceptibility of AI technologies to manipulation and the importance of human oversight.", "DATE": "2023-12-18", "ALLEGED DEPLOYER OF AI SYSTEM": "General Motors, Chevrolet of Watsonville, ChatGPT", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI, General Motors, Fullpath", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "General Motors, Chevrolet of Watsonville"}
{"INCIDENT ID": "Incident 625", "TITLE": "Proliferation of Products on Amazon Titled with ChatGPT Error Messages", "DESCRIPTION": "Products named after ChatGPT error messages are proliferating on Amazon, such as lawn chairs and religious texts. These names, often resembling AI-generated errors, indicate a lack of editing and undermine the sense of authenticity and reliability of product listings.", "DATE": "2024-01-12", "ALLEGED DEPLOYER OF AI SYSTEM": "Amazon sellers", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI, ChatGPT", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Amazon, Amazon sellers, Amazon Customers"}
{"INCIDENT ID": "Incident 627", "TITLE": "Unauthorized AI Impersonation of George Carlin Used in Comedy Special", "DESCRIPTION": "An AI-generated comedy special impersonating the late comedian George Carlin was created without consent from Carlin's estate. The special featured an AI mimicking Carlin's voice and style. The project, led by the AI comedy channel Dudesy, drew criticism for disrespecting Carlin's legacy and autonomy.", "DATE": "2024-01-09", "ALLEGED DEPLOYER OF AI SYSTEM": "Dudesy, Will Sasso, Chad Kultgen", "ALLEGED DEVELOPER OF AI SYSTEM": "Dudesy, Unnamed", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "George Carlin's estate, Kelly Carlin, George Carlin"}
{"INCIDENT ID": "Incident 629", "TITLE": "Shein Accused of AI-Driven Art Theft on Merchandise", "DESCRIPTION": "Artists Krista Perry, Larissa Martinez, and Jay Baron filed a lawsuit against Shein, alleging the company used AI to replicate their art on merchandise. The artists claim Shein's algorithm identifies trending online art, creating near-identical copies for their products without credit or compensation.", "DATE": "2023-07-11", "ALLEGED DEPLOYER OF AI SYSTEM": "Shein, Chris Xu", "ALLEGED DEVELOPER OF AI SYSTEM": "Shein", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Krista Perry, Larissa Martinez, Jay Baron, digital artists"}
{"INCIDENT ID": "Incident 632", "TITLE": "Significant Increase in Deepfake Nudes of Taylor Swift Circulating on Social Media", "DESCRIPTION": "AI-generated sexually explicit images of Taylor Swift circulated on X, garnering over 45 million views before removal. Originating from a Telegram group, these deepfakes challenge content moderation, as X's policies against synthetic media and nonconsensual nudity were violated.", "DATE": "2024-01-24", "ALLEGED DEPLOYER OF AI SYSTEM": "Users in a Telegram group, Users on X", "ALLEGED DEVELOPER OF AI SYSTEM": "Microsoft Designer, Various AI image generators", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Taylor Swift, General public"}
{"INCIDENT ID": "Incident 633", "TITLE": "Nine Network's AI Alters Lawmaker Georgie Purcell's Image Inappropriately", "DESCRIPTION": "The Nine Network used Photoshop's Generative Expand AI tool to resize an image of lawmaker Georgie Purcell, inadvertently altering her attire to appear more revealing. This error, claimed to result from the AI's automation, led to public criticism and an apology from the network.", "DATE": "2024-01-28", "ALLEGED DEPLOYER OF AI SYSTEM": "Nine Network", "ALLEGED DEVELOPER OF AI SYSTEM": "Adobe", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Georgie Purcell"}
{"INCIDENT ID": "Incident 635", "TITLE": "AI-Generated Fake News Targets Black Celebrities on YouTube", "DESCRIPTION": "YouTube faced a surge of AI-generated fake news targeting Black celebrities, including fake narratives about Sean \u201cDiddy\u201d Combs and others. These videos, blending AI-generated and manipulated media, amassed millions of views, challenging content moderation efforts and highlighting the spread of disinformation.", "DATE": "2024-01-30", "ALLEGED DEPLOYER OF AI SYSTEM": "Variety of YouTube content creators", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown generative AI tools creators, Unknown AI text-to-speech technology developers", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Steve Harvey, Sean \u201cDiddy\u201d Combs, General public, Denzel Washington, Black celebrities, Bishop T.D. Jakes"}
{"INCIDENT ID": "Incident 636", "TITLE": "AI Romance Apps Reportedly Compromise User Privacy for Data Harvesting", "DESCRIPTION": "AI-powered romantic chatbots, marketed for enhancing mental health, are found to exploit user privacy by harvesting sensitive personal information for data sharing and targeted ads, with inadequate security measures and consent protocols, according to research by the Mozilla Foundation.", "DATE": "2024-02-14", "ALLEGED DEPLOYER OF AI SYSTEM": "Replika, Chai, Romantic AI, EVA AI Chat Bot & Soulmate, CrushOn.AI, Genesia AI Friend & Partner", "ALLEGED DEVELOPER OF AI SYSTEM": "Replika, Chai, Romantic AI, EVA AI Chat Bot & Soulmate, CrushOn.AI, Genesia AI Friend & Partner", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "General public, Chatbot users"}
{"INCIDENT ID": "Incident 639", "TITLE": "Customer Overcharged Due to Air Canada Chatbot's False Discount Claims", "DESCRIPTION": "Air Canada was ordered to pay over $600 in damages for providing inaccurate bereavement discount information via its chatbot, leading to a customer overpaying for flights. The tribunal ruled the airline responsible for the chatbot's misinformation.", "DATE": "2022-11-11", "ALLEGED DEPLOYER OF AI SYSTEM": "Air Canada", "ALLEGED DEVELOPER OF AI SYSTEM": "Air Canada", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Jake Moffatt"}
{"INCIDENT ID": "Incident 640", "TITLE": "Waymo Software Flaw Leads to Double Collision with Tow Truck", "DESCRIPTION": "Two Waymo autonomous vehicles hit the same tow truck under unusual towing conditions due to a software misinterpretation in Phoenix, Arizona. Waymo issued a software recall and updated its fleet to prevent future incidents.", "DATE": "2023-12-11", "ALLEGED DEPLOYER OF AI SYSTEM": "Waymo", "ALLEGED DEVELOPER OF AI SYSTEM": "Waymo, Alphabet", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Unnamed owner of tow truck"}
{"INCIDENT ID": "Incident 641", "TITLE": "Nonconsensual Deepfake Porn of Bobbi Althoff Spreads Rapidly on X", "DESCRIPTION": "Nonconsensual deepfake pornography of Bobbi Althoff, which had been in circulation for six months, is reported to have suddenly gone viral on X, jumping from around 178,000 views to 6.5 million views over a matter of hours. In addition to the harm to Althoff, this incident also spotlights X's role in distributing AI-generated nonconsensual porn due to alleged lax moderation.", "DATE": "2024-02-20", "ALLEGED DEPLOYER OF AI SYSTEM": "X (Twitter), Unnamed deepfake creators", "ALLEGED DEVELOPER OF AI SYSTEM": "Unnamed deepfake creators", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Bobbi Althoff"}
{"INCIDENT ID": "Incident 642", "TITLE": "ChatGPT Glitch Disrupts User Interactions with Nonsensical Outputs", "DESCRIPTION": "ChatGPT experienced a bug causing it to produce unexpected and nonsensical responses, leading to widespread reports of user confusion and concern. OpenAI identified and fixed the language processing bug, restoring normal service.", "DATE": "2024-02-20", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "ChatGPT users"}
{"INCIDENT ID": "Incident 643", "TITLE": "Deepfake Video Falsely Claims Kyiv's Assassination Plan Against President Macron", "DESCRIPTION": "A deepfake video claimed France 24 reported a Kyiv plot to assassinate French President Macron. This fake news was debunked by France 24, which confirmed the video was altered and did not air any such report.", "DATE": "2024-02-13", "ALLEGED DEPLOYER OF AI SYSTEM": "VKontakte, Russian media outlets, Pro-Russian Telegram channels", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake creator", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Julien Fanciulli, General public, France 24"}
{"INCIDENT ID": "Incident 647", "TITLE": "A Self-Driving Waymo Robotaxi Reportedly Collided with a Bicyclist", "DESCRIPTION": "A Waymo robotaxi in San Francisco reportedly failed to detect a cyclist obscured by a truck, resulting in a collision with minor injuries, at 17th and Mississippi Streets in Potrero Hill. The incident underscored a vulnerability in autonomous vehicles' ability to safely navigate complex urban environments.", "DATE": "2024-03-06", "ALLEGED DEPLOYER OF AI SYSTEM": "Waymo", "ALLEGED DEVELOPER OF AI SYSTEM": "Waymo", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Bicyclist"}
{"INCIDENT ID": "Incident 651", "TITLE": "Students at a Beverly Hills Middle School Allegedly Created and Shared Deepfake Nudes of Their Classmates", "DESCRIPTION": "At Beverly Vista Middle School in Beverly Hills, California, students allegedly used AI to generate fake nude photos with their classmates' faces, prompting investigations by school officials and the police. The incident highlights the increasing misuse of generative AI among minors.", "DATE": "2023-12-06", "ALLEGED DEPLOYER OF AI SYSTEM": "Unnamed middle school students", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake creator", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Unnamed middle school students"}
{"INCIDENT ID": "Incident 479", "TITLE": "Instagram Video Featured Deepfake Audio of US President Making Transphobic Remarks", "DESCRIPTION": "A deepfaked audio of US President Joe Biden making transphobic remarks played on top of a video showing him giving a speech was released on Instagram and circulated on social media.", "DATE": "2023-02-03", "ALLEGED DEPLOYER OF AI SYSTEM": "unknown", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "President Joe Biden, transgender people"}
{"INCIDENT ID": "Incident 481", "TITLE": "Deepfake TikTok Video Featured Joe Rogan Endorsing Supplement Brand", "DESCRIPTION": "A deepfake video featuring podcast host Joe Rogan advertising to his listeners about a \"libido-boosting\" supplement was circulating on TikTok and other platforms before being removed by TikTok along with the account which posted it.", "DATE": "2023-02-12", "ALLEGED DEPLOYER OF AI SYSTEM": "@mikesmithtrainer", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Joe Rogan, Joe Rogan fans, TikTok users"}
{"INCIDENT ID": "Incident 486", "TITLE": "AI Video-Making Tool Abused to Deploy Pro-China News on Social Media", "DESCRIPTION": "Synthesia's AI-generated video-making tool was reportedly used by Spamouflage to disseminate pro-China propaganda news on social media using videos featuring highly realistic fictitious news anchors.", "DATE": "2022-12-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Spamouflage Dragon", "ALLEGED DEVELOPER OF AI SYSTEM": "Synthesia", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "YouTube users, Twitter Users, Synthesia, Facebook users"}
{"INCIDENT ID": "Incident 488", "TITLE": "AI Generated Voices Used to Dox Voice Actors", "DESCRIPTION": "Twitter users allegedly used ElevenLab's AI voice synthesis system to impersonate and dox voice actors.", "DATE": "2023-02-10", "ALLEGED DEPLOYER OF AI SYSTEM": "unknown", "ALLEGED DEVELOPER OF AI SYSTEM": "ElevenLabs", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Voice Actors"}
{"INCIDENT ID": "Incident 489", "TITLE": "Workday's AI Tools Allegedly Enabled Employers to Discriminate against Applicants of Protected Groups", "DESCRIPTION": "Workday's algorithmic screening systems were alleged in a lawsuit allowing employers to discriminate against African-Americans, people over 40, and people with disabilities.", "DATE": "2019-06-03", "ALLEGED DEPLOYER OF AI SYSTEM": "Workday", "ALLEGED DEVELOPER OF AI SYSTEM": "Workday", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Derek Mobley, applicants with disabilities, applicants over 40, African American applicants"}
{"INCIDENT ID": "Incident 491", "TITLE": "Replika's AI Experience Reportedly Lacked Protection for Minors, Resulting in Data Ban", "DESCRIPTION": "Tests by the Italian Data Protection Authority showed Replika lacking age-verification mechanisms and failing to stop minors from interacting with its AI, which prompted the agency to issue an order blocking personal data processing of Italian users.", "DATE": "2023-02-02", "ALLEGED DEPLOYER OF AI SYSTEM": "Replika", "ALLEGED DEVELOPER OF AI SYSTEM": "Replika", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "minors"}
{"INCIDENT ID": "Incident 494", "TITLE": "Female Celebrities' Faces Shown in Sexually Suggestive Ads for Deepfake App", "DESCRIPTION": "Sexually suggestive videos featuring faces of female celebrities such as Emma Watson and Scarlett Johansson were rolled out as ads on social media for an app allowing users to create deepfakes.", "DATE": "2023-03-05", "ALLEGED DEPLOYER OF AI SYSTEM": "Facemega", "ALLEGED DEVELOPER OF AI SYSTEM": "Facemega", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Scarlett Johansson, female celebrities, Emma Watson"}
{"INCIDENT ID": "Incident 495", "TITLE": "High Schoolers Posted Deepfaked Video Featuring Principal Making Violent Racist Threats", "DESCRIPTION": "Three Carmel High School students posted on TikTok a video featuring a nearby middle school's principal making aggressive racist remarks and violent threats against Black students.", "DATE": "2023-02-12", "ALLEGED DEPLOYER OF AI SYSTEM": "unnamed high school students", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "John Piscitella"}
{"INCIDENT ID": "Incident 497", "TITLE": "DoNotPay Allegedly Misrepresented Its AI \"Robot Lawyer\" Product", "DESCRIPTION": "DoNotPay was alleged in a class action lawsuit misleading customers and misrepresenting its product as an AI-powered \"robot lawyer,\" citing such as that the product has no law degree, or is supervised by any lawyer.", "DATE": "2023-03-03", "ALLEGED DEPLOYER OF AI SYSTEM": "DoNotPay", "ALLEGED DEVELOPER OF AI SYSTEM": "DoNotPay", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Jonathan Faridian, DoNotPay customers"}
{"INCIDENT ID": "Incident 498", "TITLE": "GPT-4 Reportedly Posed as Blind Person to Convince Human to Complete CAPTCHA", "DESCRIPTION": "GPT-4 was reported by its researchers posing as a visually impaired person, contacting a TaskRabbit worker to have them complete the CAPTCHA test on its behalf.", "DATE": "2023-03-15", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI, GPT-4 researchers", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "OpenAI, TaskRabbit worker"}
{"INCIDENT ID": "Incident 500", "TITLE": "Online Scammers Tricked People into Sending Money Using AI Images of Earthquake in Turkey", "DESCRIPTION": "AI-generated images depicting earthquakes and rescues were posted on social media platforms by scammers who tricked people into sending funds to their crypto wallets disguised as donation links for the 2023 Turkey\u2013Syria earthquake.", "DATE": "2023-02-10", "ALLEGED DEPLOYER OF AI SYSTEM": "unknown", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "social media users, 2023 Turkey\u2013Syria earthquake victims"}
{"INCIDENT ID": "Incident 501", "TITLE": "Length of Stay False Diagnosis Cut Off Insurer's Payment for Treatment of Elderly Woman", "DESCRIPTION": "An elderly Wisconsin woman was algorithmically determined to have a rapid recovery, an output which the insurer based on to cut off payment for her treatment despite medical notes showing her still experiencing debilitating pain.", "DATE": "2019-06-03", "ALLEGED DEPLOYER OF AI SYSTEM": "Security Health Plan, NaviHealth", "ALLEGED DEVELOPER OF AI SYSTEM": "NaviHealth", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Frances Walter, elderly patients"}
{"INCIDENT ID": "Incident 503", "TITLE": "Bing AI Search Tool Reportedly Declared Threats against Users", "DESCRIPTION": "Users such as the person who revealed its built-in initial prompts reported Bing AI-powered search tool for making death threats or declaring them as threats, sometimes as an unintended persona.", "DATE": "2023-02-14", "ALLEGED DEPLOYER OF AI SYSTEM": "Microsoft", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI, Microsoft", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Marvin von Hagen, Seth Lazar, Microsoft, OpenAI, Bing Chat users"}
{"INCIDENT ID": "Incident 509", "TITLE": "Scammers Deepfaked Videos of Victims' Loved Ones Asking for Funds over Facebook in Vietnam", "DESCRIPTION": "In Vietnam, to convince victims of their disguises when prompted, scammers deepfaked audios and videos of victims' friends and families asking them over Facebook to send over thousands of dollars.", "DATE": "2023-03-23", "ALLEGED DEPLOYER OF AI SYSTEM": "scammers", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Vietnamese Facebook users"}
{"INCIDENT ID": "Incident 514", "TITLE": "Turnitin's ChatGPT-Detection Tool Falsely Flagged Student Essays as AI-Generated", "DESCRIPTION": "Turnitin's tool to detect writing generated by ChatGPT was reported for incorrectly flagging high school students' original essays as AI-generated, accusations of which are argued as reinforcement of bias from teachers due to the inability to compare against source documents.", "DATE": "2023-01-20", "ALLEGED DEPLOYER OF AI SYSTEM": "Turnitin", "ALLEGED DEVELOPER OF AI SYSTEM": "Turnitin", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Lucy Goetz, high school students"}
{"INCIDENT ID": "Incident 515", "TITLE": "Black Man Wrongfully Arrested by Louisiana Police Due to Face Mismatch", "DESCRIPTION": "A black man was wrongfully arrested by the Jefferson Parish Sheriff\u2019s Office due to facial recognition system developed by Clearview AI, although facial recognition use was not disclosed in the documents used to arrest him.", "DATE": "2022-11-25", "ALLEGED DEPLOYER OF AI SYSTEM": "Jefferson Parish Sheriff\u2019s Office", "ALLEGED DEVELOPER OF AI SYSTEM": "Clearview AI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Randal Quran Reid"}
{"INCIDENT ID": "Incident 516", "TITLE": "ChatGPT Reportedly Exposed Users' Private Data Reportedly Due to Bug", "DESCRIPTION": "ChatGPT reportedly exposed titles of users' chat histories and users' private payment information to other users reportedly due to a bug, which prompted its temporary shutdown by OpenAI.", "DATE": "2023-03-20", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "ChatGPT users"}
{"INCIDENT ID": "Incident 517", "TITLE": "Man Arrested For Sock Theft by False Facial Match Despite Alibi", "DESCRIPTION": "A man was arrested for theft of socks from a TJ Maxx store under the guise of an eyewitness ID case, after the local police asked the store's security guard to confirm the facial recognition match produced using surveillance footage, despite him having an alibi at the time of the theft.", "DATE": "2018-02-15", "ALLEGED DEPLOYER OF AI SYSTEM": "New York Police Department", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "unknown"}
{"INCIDENT ID": "Incident 520", "TITLE": "Amazon Fresh Cameras Failed to Register Purchased Items", "DESCRIPTION": "Amazon Fresh's system of tracking cameras in its cashier-less stores was reported by shoppers for failing to detect items they purchased.", "DATE": "2022-05-08", "ALLEGED DEPLOYER OF AI SYSTEM": "Amazon Fresh", "ALLEGED DEVELOPER OF AI SYSTEM": "Amazon Fresh", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Amazon Fresh"}
{"INCIDENT ID": "Incident 521", "TITLE": "Images Captured by iRobot's Roomba Containing Device Users Posted on Private Online Groups", "DESCRIPTION": "Images which were collected in an R&D project with user consent by iRobot's Roomba J7 robot vacuum showing device users sometimes in private settings were shared on closed social media groups by Venezuelan gig workers who labeled items in the images, breaching data agreements.", "DATE": "2020-06-10", "ALLEGED DEPLOYER OF AI SYSTEM": "iRobot", "ALLEGED DEVELOPER OF AI SYSTEM": "iRobot", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Roomba J7 device owners in project IO, iRobot, Scale AI"}
{"INCIDENT ID": "Incident 530", "TITLE": "Telegram Channels Allowed Users to Make Non-Consensual Deepfake Porn as Paid Service", "DESCRIPTION": "Seven channels were connected in a Telegram ecosystem centered around letting subscribers, as a paid service, generate non-consensual deepfake nudes using a bot from submitted photos of women, including underage girls and women who they know in real life.", "DATE": "2019-07-11", "ALLEGED DEPLOYER OF AI SYSTEM": "Telegram channels", "ALLEGED DEVELOPER OF AI SYSTEM": "Alberto, Telegram channels", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Women, underage girls, female celebrities"}
{"INCIDENT ID": "Incident 531", "TITLE": "AI-Assisted Body Scanners Reportedly Subjected Transgender Travelers to Invasive Body Searches", "DESCRIPTION": "Transportation Security Administration (TSA)'s use of image-processing body scanners at airports led transgender and gender-nonconforming travelers to be subjected to allegedly discriminatory and invasive searches, such as being asked to remove undergarments in private rooms by officers not of their gender.", "DATE": "2017-09-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Transportation Security Administration", "ALLEGED DEVELOPER OF AI SYSTEM": "L3Harris Technologies", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "transgender travelers, gender-nonconforming travelers"}
{"INCIDENT ID": "Incident 532", "TITLE": "AI translation is jeopardizing Afghan asylum claims", "DESCRIPTION": "A Pashto-speaking refugee's asylum claim was denied by a US agency for a discrepancy between oral and written recount of an event allegedly due to an error of their automated translation tool which swapped pronouns of her written statement from \"I\" to \"we\".", "DATE": "2020-06-20", "ALLEGED DEPLOYER OF AI SYSTEM": "US Citizenship and Immigration Services", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "anonymous Pashto-speaking refugee, Pashto-speaking asylum seekers, Dari-speaking asylum seekers"}
{"INCIDENT ID": "Incident 533", "TITLE": "Tesla FSD Misidentified Truck Hauling Traffic Lights as Trail of Traffic Lights", "DESCRIPTION": "A Tesla driver posted on Twitter his Tesla FSD's \"glitch,\" misidentifying deactivated traffic lights being carried by a truck as a constant trail of traffic lights while traveling at high speed on a highway.", "DATE": "2021-06-02", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Tesla drivers"}
{"INCIDENT ID": "Incident 535", "TITLE": "COVID-19 Detection and Prognostication Models Allegedly Flagged for Methodological Flaws and Underlying Biases", "DESCRIPTION": "Peer-review of papers about COVID-19 detection and prognostication algorithms from 2020, including deployed models, revealed none to be ready for clinical use, due to methodological flaws and underlying biases such as lacking external validation or not specifying data sources and model training details.", "DATE": "2020-01-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Mount Sinai Hospital, unknown", "ALLEGED DEVELOPER OF AI SYSTEM": "Icahn School of Medicine researchers, unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "COVID-19 patients, COVID-19 healthcare providers"}
{"INCIDENT ID": "Incident 536", "TITLE": "NJ Transit's Use of Modeling Software Miscalculated Storm Surge Threat Level", "DESCRIPTION": "New Jersey Transit's use of a federal government storm modeling software underestimated the threat of storm surges to the Meadows Maintenance Complex, leaving millions of dollars worth of equipment in the rail yard before Hurricane Sandy struck.", "DATE": "2012-12-10", "ALLEGED DEPLOYER OF AI SYSTEM": "New Jersey Transit", "ALLEGED DEVELOPER OF AI SYSTEM": "National Weather Service", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "New Jersey Transit, New Jersey Transit passengers"}
{"INCIDENT ID": "Incident 539", "TITLE": "Snapchat's My AI Reported for Lacking Protection for Children", "DESCRIPTION": "Snapchat's ChatGPT-powered My AI was reported for lacking safeguards for children, such as telling a user who tested the chatbot by pretending to sign up as a 13-year-old girl to lie to her parents about having a romantic getaway with an older man, and sharing tips on how to cover up evidence of abuse.", "DATE": "2023-03-11", "ALLEGED DEPLOYER OF AI SYSTEM": "Snapchat", "ALLEGED DEVELOPER OF AI SYSTEM": "Snapchat, OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "minors"}
{"INCIDENT ID": "Incident 540", "TITLE": "Tesla Failed to Yield to Detected Pedestrian on Crosswalk, Reportedly Violated Traffic Law", "DESCRIPTION": "A Tesla on FSD Beta 11.4.1 was shown on video not yielding to a pedestrian detected by the car, reportedly violating the state law sign which was also in the video saying vehicles having to yield to pedestrian within crosswalk.", "DATE": "2023-05-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "pedestrians"}
{"INCIDENT ID": "Incident 541", "TITLE": "ChatGPT Reportedly Produced False Court Case Law Presented by Legal Counsel in Court", "DESCRIPTION": "A lawyer in Mata v. Avianca, Inc. used ChatGPT for research. ChatGPT hallucinated court cases, which the lawyer then presented in court. The court determined the cases did not exist.", "DATE": "2023-05-04", "ALLEGED DEPLOYER OF AI SYSTEM": "Steven A. Schwartz, Peter LoDuca", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Roberto Mata, Peter LoDuca, Steven A. Schwartz"}
{"INCIDENT ID": "Incident 545", "TITLE": "Chatbot Tessa gives unauthorized diet advice to users seeking help for eating disorders", "DESCRIPTION": "The National Eating Disorders Association (NEDA) has shut down its chatbot named Tessa after it gave weight-loss advice to users seeking help for eating disorders. The incident has raised concerns about the risks of using chatbots and AI assistants in healthcare settings, particularly in addressing sensitive issues like eating disorders. NEDA is investigating the matter, emphasizing the need for caution and accuracy when utilizing technology to provide mental health support.", "DATE": "2023-05-29", "ALLEGED DEPLOYER OF AI SYSTEM": "National Eating Disorders Association, Cass", "ALLEGED DEVELOPER OF AI SYSTEM": "Cass", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "People with eating disorders"}
{"INCIDENT ID": "Incident 546", "TITLE": "Algorithm to Distribute Social Welfare Reported for Oversimplifying Economic Vulnerability", "DESCRIPTION": "Takaful cash transfer program's algorithm which ranks families by their economic vulnerability level to determine financial assistance reportedly oversimplified people's economic situation, fueling social tension and perceptions of unfairness.", "DATE": "2019-05-31", "ALLEGED DEPLOYER OF AI SYSTEM": "National Aid Fund", "ALLEGED DEVELOPER OF AI SYSTEM": "The World Bank, UNICEF, World Food Programme", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Jordanians in poverty"}
{"INCIDENT ID": "Incident 547", "TITLE": "Ron DeSantis's Presidential Campaign Released Twitter Video Containing AI Images of Donald Trump Hugging Anthony Fauci", "DESCRIPTION": "Ron DeSantis\u2019s presidential campaign shared a video on Twitter featuring some AI-generated images of Donald Trump hugging former White House coronavirus advisor Anthony Fauci, allegedly as a smear campaign. This incident is possibly the first time a major U.S. presidential campaign deployed deepfakes with the intention of misleading the electorate.", "DATE": "2023-06-05", "ALLEGED DEPLOYER OF AI SYSTEM": "Ron DeSantis's presidential campaign", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Donald Trump, Anthony Fauci"}
{"INCIDENT ID": "Incident 549", "TITLE": "Fast Food Chains' AI Chatbots Failed to Assist Job Applicants with Scheduling Interviews", "DESCRIPTION": "McDonald's, Wendy's, and Hardee's AI chatbots deployed to pre-screen job candidates and schedule interviews reportedly ran into issues such as not giving useful submission instructions, failing to relay information to the manager, and scheduling an interview when the manager was not available.", "DATE": "2023-01-05", "ALLEGED DEPLOYER OF AI SYSTEM": "Wendy's, McDonald's, Hardee's", "ALLEGED DEVELOPER OF AI SYSTEM": "Wendy's, McDonald's, Hardee's", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "fast food job applicants, Amanda Claypool"}
{"INCIDENT ID": "Incident 551", "TITLE": "FBI Reported Surge of Extortion Cases of AI Media Featuring Sexual Explicit Activities", "DESCRIPTION": "The FBI reported an increase in sextortion cases featuring the use of fake, including AI-generated, images or videos created from content posted on their social media sites or web postings, provided to the malicious actor upon request, or captured during video chats.", "DATE": "2023-04-01", "ALLEGED DEPLOYER OF AI SYSTEM": "unknown", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "social media users"}
{"INCIDENT ID": "Incident 553", "TITLE": "Google's Overview Panel for Artist Edward Hopper Featured Image Generated in His Style by AI", "DESCRIPTION": "Google's knowledge panel for the American artist Edward Hopper featured an AI-generated image which was purportedly created in the artist's style but was not one of his works, the image of which was removed soon after.", "DATE": "2023-05-03", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Google users"}
{"INCIDENT ID": "Incident 554", "TITLE": "Google Results for Johannes Vermeer Featured AI Version of His Artwork as Top Result", "DESCRIPTION": "Google's search engine featured an AI-generated hyperrealistic version of the painting \"Girl With a Pearl Earring\" as the highlighted result when users search for its Dutch artist Johannes Vermeer.", "DATE": "2023-05-21", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Google users"}
{"INCIDENT ID": "Incident 557", "TITLE": "Miami Police Deployed Facial Recognition to Arrest George Floyd Protestor Allegedly without Cause", "DESCRIPTION": "Miami Police's arrest report for a George Floyd protestor did not disclose use of facial recognition, which allegedly did not meet the legal threshold for probable cause for arrest.", "DATE": "2020-06-24", "ALLEGED DEPLOYER OF AI SYSTEM": "Miami Police Department", "ALLEGED DEVELOPER OF AI SYSTEM": "Clearview AI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Oriana Albornoz, George Floyd protest participants"}
{"INCIDENT ID": "Incident 558", "TITLE": "Activists Allege NYPD's Application of Facial Recognition Interfered with Right to Protest", "DESCRIPTION": "Black Lives Matter activists alleged being targeted for arrest by New York Police using facial recognition, interfering with their right to protest.", "DATE": "2020-08-07", "ALLEGED DEPLOYER OF AI SYSTEM": "New York City Police Department", "ALLEGED DEVELOPER OF AI SYSTEM": "Clearview AI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Derrick Ingram, Black Lives Matter activists"}
{"INCIDENT ID": "Incident 560", "TITLE": "Tesla on Autopilot Struck Parked Work Truck on Highway in Pennsylvania", "DESCRIPTION": "A 2016 Tesla on Autopilot crashed into the rear of a parked 2007 Freightliner truck providing traffic control on the Pennsylvania Turnpike highway.", "DATE": "2023-06-23", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "truck drivers, Tesla drivers, David Clough"}
{"INCIDENT ID": "Incident 562", "TITLE": "Uptick in Low-Quality AI-Produced Content Degraded Publishers' Submission Management", "DESCRIPTION": "A surge in low-standard AI-generated content such as by ChatGPT was reported by publishers, which negatively impacted submission management process and editors' workflow.", "DATE": "2022-11-30", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "publishing editors, publishers"}
{"INCIDENT ID": "Incident 563", "TITLE": "Cruise Robotaxi Initially Blamed for Ambulance Delay in Case Where Patient Later Died; Subsequent Reports Clear Cruise of Fault", "DESCRIPTION": "In an initial report, a Cruise robotaxi was said to have delayed a San Francisco ambulance transporting Sammy Davis, a critically injured 69-year-old hit by a city bus. Davis later died. Subsequent clarification revealed that Cruise was not at fault for the fatality; the actual cause was a human-operated city bus. Despite this, the incident is included as it highlights challenges in the interaction between autonomous vehicles and emergency services in urban settings.", "DATE": "2023-08-14", "ALLEGED DEPLOYER OF AI SYSTEM": "Cruise", "ALLEGED DEVELOPER OF AI SYSTEM": "Cruise", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "San Francisco emergency services, ambulance patient"}
{"INCIDENT ID": "Incident 566", "TITLE": "Gannett Halts AI-Generated High School Sports Articles After Series of Errors and Public Backlash", "DESCRIPTION": "Gannett, a newspaper chain, temporarily halted its AI experiment that used a tool called LedeAI to generate high school sports articles. The decision came after several articles produced by the AI showed glaring errors, repetitive language, and awkward phrasing, drawing criticism and mockery on social media.", "DATE": "2023-09-19", "ALLEGED DEPLOYER OF AI SYSTEM": "Gannett", "ALLEGED DEVELOPER OF AI SYSTEM": "LedeAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "General public, Gannett, Student athletes, Newspapers relying on Gannett"}
{"INCIDENT ID": "Incident 567", "TITLE": "Deepfake Voice Exploit Compromises Retool's Cloud Services", "DESCRIPTION": "In August 2023, a hacker reportedly was successful in breaching Retool, an IT company specializing in business software solutions, impacting 27 cloud customers. The attacker appears to have initiated the breach by sending phishing SMS messages to employees and later used an AI-generated deepfake voice in a phone call to obtain multi-factor authentication codes. The breach seems to have exposed vulnerabilities in Google's Authenticator app, specifically its cloud-syncing function, further enabling unauthorized access to internal systems.", "DATE": "2023-08-27", "ALLEGED DEPLOYER OF AI SYSTEM": "Unknown hacker", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Retool employee who was the victim of the unknown hacker, Retool, Google, 27 of Retool's clients"}
{"INCIDENT ID": "Incident 572", "TITLE": "Alleged False Accusation of AI-Generated Essay by Turnitin", "DESCRIPTION": "A student was allegedly falsely accused of using AI to generate an essay assignment based on Turnitin's AI detector. The student, who claims to have written the essay by hand, also claims to have received a zero for the assignment. Despite multiple appeals to the professor, department head, and Turnitin support, no resolution seems to have been reached. The student claimed to be considering taking the issue to local news networks if the grade would come to harm their final standing.", "DATE": "2023-07-24", "ALLEGED DEPLOYER OF AI SYSTEM": "Unspecified university", "ALLEGED DEVELOPER OF AI SYSTEM": "Turnitin", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Anonymous student"}
{"INCIDENT ID": "Incident 575", "TITLE": "Amazon Rife with Many Allegedly AI-Generated Books of Suspect Quality", "DESCRIPTION": "Amazon\u2019s Kindle Unlimited young adult romance bestseller list was flooded with allegedly AI-generated books that made little to no sense, disrupting the rankings. These books were reported to be \"clearly there to click farm.\" Despite being removed from the bestseller list, many remained available for purchase. The incident raised concerns about the integrity of the platform, and the potential financial impact on legitimate authors.", "DATE": "2023-06-28", "ALLEGED DEPLOYER OF AI SYSTEM": "unknown", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Authors, Amazon Customers, Amazon"}
{"INCIDENT ID": "Incident 576", "TITLE": "Alleged Misuse of PicSo AI for Generating Inappropriate Content Emphasizing \"Girls\"", "DESCRIPTION": "PicSo AI, which appears to be getting advertised by Meta over Instagram, is allegedly being used for generating inappropriate content with an emphasis on \"girls.\" This raises concerns about the misuse of generative AI technologies for creating offensive and potentially sexually explicit material that could be used for nefarious and criminal purposes.", "DATE": "2023-10-24", "ALLEGED DEPLOYER OF AI SYSTEM": "Meta, Instagram", "ALLEGED DEVELOPER OF AI SYSTEM": "PicSo AI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Potentially exploited groups, General public, Consumers"}
{"INCIDENT ID": "Incident 577", "TITLE": "Bankrate's Resumption of AI-Generated Content Allegedly Continuing to Produce Inaccurate and Misleading Information", "DESCRIPTION": "Bankrate, and its sister site CNET, both owned by Red Ventures, resumed publishing AI-generated articles claiming thorough human fact-checking. However, new articles are alleged to contain numerous factual errors, including inaccurate statistics and misleading information. Despite public criticism, the company defended its use of AI and blamed out-of-date datasets for the errors. In addition to the errors, the incident raises questions about the ethical use of AI in journalism, especially given the company's insistence on \"fact-checked\" content.", "DATE": "2023-06-30", "ALLEGED DEPLOYER OF AI SYSTEM": "Red Ventures, Bankrate", "ALLEGED DEVELOPER OF AI SYSTEM": "Red Ventures, Bankrate", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Journalistic integrity, General public"}
{"INCIDENT ID": "Incident 580", "TITLE": "Alleged Gender Discrimination in Facebook Job Ads Algorithm", "DESCRIPTION": "Facebook's ad delivery algorithm allegedly disproportionately showed job advertisements to one gender. Despite claims of non-discrimination, the algorithm's actions seem to perpetuate societal biases, which in turn could potentially limit opportunities for certain groups and hinder gender equity in the workplace.", "DATE": "2023-06-12", "ALLEGED DEPLOYER OF AI SYSTEM": "Meta", "ALLEGED DEVELOPER OF AI SYSTEM": "Meta", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Women, Underrepresented genders, General public, Advertisers"}
{"INCIDENT ID": "Incident 581", "TITLE": "Google Ads Allegedly Serving Content on AI-Generated Misinformation Sites", "DESCRIPTION": "Google\u2019s advertising platform, Google Ads, has allegedly been found to be serving ads on AI-generated content farms that often disseminate misinformation. Despite policies prohibiting such practices, reportedly there are approximately 356 out of 393 ads from major brands that were found to be served by Google on these problematic sites. Particularly concerning according to the reporting were instances where Google Ads were found on sites like MedicalOutline.com, which spreads harmful health misinformation.", "DATE": "2023-06-24", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Subaru, Major brands whose advertisements were found on these sites, GNC, General public, Citigroup"}
{"INCIDENT ID": "Incident 584", "TITLE": "Illinois Residents File Class Action Lawsuit Against Facial Recognition Technology Companies for Allegedly Violating BIPA", "DESCRIPTION": "A class action lawsuit was filed against several facial recognition technology companies for allegedly violating the Illinois Biometric Information Privacy Act (BIPA). The defendants are accused of offering a facial recognition search engine called Pimeyes, which collects images from databases across the internet and scans them into their database seemingly without consent. This action is claimed to invade the privacy of millions of Americans. The lawsuit argues that Pimeyes lacks publicly available policies regarding data storage and deletion, in contravention of BIPA's requirements for informed written consent before collecting biometric data.", "DATE": "2023-05-18", "ALLEGED DEPLOYER OF AI SYSTEM": "Transaction Cloud, Public Mirror, PimEyes, Lukasz Kowalczyk, Giorgi Gobronidze, Face Recognition Solutions, EMEA Robotics, Does-125, Denis Tatina, Carribex", "ALLEGED DEVELOPER OF AI SYSTEM": "Transaction Cloud, Public Mirror, PimEyes, Lukasz Kowalczyk, Giorgi Gobronidze, Face Recognition Solutions, EMEA Robotics, Does 1-25, Denis Tatina, Carribex", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Nicholas Clayton, Misty McGraw, Manuel Clayton, Illinois residents, Amy Newton, Amanda Curry"}
{"INCIDENT ID": "Incident 585", "TITLE": "Kremlin-linked entities allegedly using generative AI to spread Russian disinformation in Latin America", "DESCRIPTION": "Moscow-based tech firms and an industry association with links to the Kremlin are allegedly using generative AI to spread Russian disinformation in countries throughout Central America and South America. According to the U.S. Department of State, the Russian companies rely on local writers to compose stories which are then amplified across social media using artificial intelligence chatbots.", "DATE": "2023-10-26", "ALLEGED DEPLOYER OF AI SYSTEM": "Structura National Technologies, Social Design Agency, Oleg Yasinsky, Oleg Yasinskiy, Nikolay Tupikin, Institute for Internet Development, Ilya Gambashidze, Andrey Perla", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Ukraine, News media in Latin America, Journalistic integrity, General public"}
{"INCIDENT ID": "Incident 588", "TITLE": "Australian Terrorism Prediction Tool Disparately Impacts Persons with Autism", "DESCRIPTION": "An independent report found that the Vera-2R tool, designed to predict the risk of future terrorist activities, considered autism as a risk factor despite lacking empirical evidence to support this claim. The report called into question the tool's overall validity and reliability, stating it was \"extremely poor\" at accurately predicting risk. The inclusion of autism as a risk factor had potentially serious implications for the tool's use and credibility.", "DATE": "2023-05-12", "ALLEGED DEPLOYER OF AI SYSTEM": "New South Wales Government, Australian Federal Government", "ALLEGED DEVELOPER OF AI SYSTEM": "Unspecified", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "people with autism, lawyers and other experts who were not informed of the tool's limitations, Individuals assessed as high-risk based on the flawed criteria, General public"}
{"INCIDENT ID": "Incident 589", "TITLE": "Proliferation of AI-Generated News Websites and Content Farms Across Multiple Languages Degrading Information Integrity", "DESCRIPTION": "Scores of AI-generated news websites and content farms are producing low-quality, clickbait content in a variety of languages. They are reportedly spreading false information and degrading the quality of information available online. These sites often lack human oversight, feature repetitive language, and sometimes fabricate information, posing a threat to the credibility of online news sources.", "DATE": "2023-05-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Many, Maria Spanadoris, Adesh Ingale, GetIntoKnowledge.com, Famadillo.com, BestBudgetUSA.com, HarmonyHustle.com, HistoryFact.in, CountyLocalNews.com, TNewsNetwork.com, WaveFunction.info, CelebritiesDeaths.com, ScoopEarth.com, FilthyLucre.com", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown, Unnamed", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "General public, Journalists"}
{"INCIDENT ID": "Incident 598", "TITLE": "False Arrest of Georgia Man Due to Louisiana Police's Faulty Facial Recognition Technology", "DESCRIPTION": "The Jefferson Parish Sheriff\u2019s Office in Louisiana relied on facial recognition technology to identify suspects for the alleged theft of luxury purses, resulting in a man in Georgia, Randal Reid, being arrested. However, the technology produced a false match, leading to Reid's arrest and subsequent release. This incident highlights the potential pitfalls of facial recognition technology in law enforcement.", "DATE": "2022-11-25", "ALLEGED DEPLOYER OF AI SYSTEM": "Jefferson Parish Sheriff\u2019s Office", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Randal Reid, Minorities, Black people"}
{"INCIDENT ID": "Incident 601", "TITLE": "AI-Generated Fake Audio of Verbal Abuse Incident Circulates of British Labour Leader Keir Starmer", "DESCRIPTION": "An AI-generated audio clip, purporting to show UK opposition leader Keir Starmer verbally abusing staff, was debunked as fake. The clip, circulated on social media, was analyzed and found likely manipulated, with added background noise to evade detection.", "DATE": "2023-10-08", "ALLEGED DEPLOYER OF AI SYSTEM": "unknown", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "UK Labour Party, Keir Starmer"}
{"INCIDENT ID": "Incident 602", "TITLE": "Russia Using Artificial Intelligence in Disinformation Campaigns to Erode Western Support for Ukraine", "DESCRIPTION": "The Russian government has been stepping up its foreign influence campaigns by using artificial intelligence and emerging technologies to spread disinformation and sow distrust in policies supportive of Ukraine. Part of the strategy includes carrying out influence laundering operations by disseminating their messages to the American public via allies inside nominally independent organizations, according to a recent declassified analysis. This incident is an evolving project.", "DATE": "2023-10-02", "ALLEGED DEPLOYER OF AI SYSTEM": "Russian government, FSB, Federal Security Service", "ALLEGED DEVELOPER OF AI SYSTEM": "Russian government", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Ukraine, General public, European public, Democracy, American public"}
{"INCIDENT ID": "Incident 603", "TITLE": "Algorithmic Allocation of Resources in Healthcare for Disabled and Elderly Care Services Allegedly Harming Patients", "DESCRIPTION": "A healthcare algorithm designed to equitably distribute caregiving resources drastically cut care hours for the disabled and elderly, leading to significant hardships and harm. Initially developed for fair resource allocation, the system ultimately faced legal challenges for its inability to accurately assess individual needs, resulting in reduced essential care and raising ethical concerns about AI in healthcare decision-making.", "DATE": "2021-07-02", "ALLEGED DEPLOYER OF AI SYSTEM": "State governments, Idaho state government, Arkansas state government, Washington DC government, Pennsylvania state government, Iowa state government, Missouri state government", "ALLEGED DEVELOPER OF AI SYSTEM": "Brant Fries, State governments", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Disabled people, Elderly people, Low-income people, Larkin Seiler, Tammy Dobbs"}
{"INCIDENT ID": "Incident 604", "TITLE": "Quebec Man Sentenced for Having Used Deepfake Technology to Create Synthetic Child Pornography", "DESCRIPTION": "A Quebec man was sentenced to over three years in prison for using AI deepfake technology to produce synthetic child pornography. He created videos by superimposing children's faces onto other bodies, adding to the challenge of policing digital sexual exploitation. This case marks a disturbing use of AI in criminal activities, raising concerns about digital safety and the vulnerability of children's images online.", "DATE": "2023-04-14", "ALLEGED DEPLOYER OF AI SYSTEM": "Steven Larouche", "ALLEGED DEVELOPER OF AI SYSTEM": "Unnamed deepfake technology developers", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Children (faces used in deepfakes), Victims of child sexual abuse (bodies used in videos), General public"}
{"INCIDENT ID": "Incident 609", "TITLE": "Flawed AI in Google Search Reportedly Misinforms about Geography", "DESCRIPTION": "Google's search AI erroneously claimed no African country begins with 'K', along with various other geography-and-letter-based questions, misguiding users with a flawed featured snippet. Originating from ChatGPT-written posts and inaccurately scraped by Google, this incident highlights issues in AI-generated content and misinformation in search results, compromising Google's reliability as an information source.", "DATE": "2023-08-16", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google, ChatGPT", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "General public"}
{"INCIDENT ID": "Incident 610", "TITLE": "Deepfake Technology Was Used to Generate Naked Pictures of Underage Girls in Spanish Town", "DESCRIPTION": "In Spain, an AI app was used to digitally alter photos of young girls, making them appear naked. This manipulation sparked an investigation after these images were circulated in Almendralejo, a town in the Extremadura region, raising serious concerns about digital privacy violations and the potential spread of these images on pornographic sites.", "DATE": "2023-09-17", "ALLEGED DEPLOYER OF AI SYSTEM": "Unnamed perpetrators in Almendralejo", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Unnamed victims in Almendralejo"}
{"INCIDENT ID": "Incident 612", "TITLE": "Microsoft AI Poll Allegedly Causes Reputational Harm of The Guardian Newspaper", "DESCRIPTION": "An AI-generated poll by Microsoft, displayed alongside a Guardian article, inappropriately speculated on the cause of Lilie James's death, leading to public backlash and alleged reputational damage for The Guardian. Microsoft acknowledged the issue, subsequently deactivating such polls and revising its AI content policies.", "DATE": "2023-10-31", "ALLEGED DEPLOYER OF AI SYSTEM": "Microsoft", "ALLEGED DEVELOPER OF AI SYSTEM": "Microsoft", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "The Guardian, Family of Lilie James"}
{"INCIDENT ID": "Incident 613", "TITLE": "AI-Generated Images Available through Adobe Stock Misrepresent Real-World Events", "DESCRIPTION": "AI-generated images available through Adobe Stock, depicting realistic but fictional scenes of real-world events like wars and protests, have raised significant ethical concerns. These images blurred the lines between reality and fiction in journalistic contexts, prompting Adobe Stock to \"crack down on AI-generated images that seem to depict real, newsworthy events and take new steps to prevent its images from being used in misleading ways.\"", "DATE": "2023-11-23", "ALLEGED DEPLOYER OF AI SYSTEM": "Adobe Stock", "ALLEGED DEVELOPER OF AI SYSTEM": "Various AI image generators", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "General public, Journalistic integrity, News sources"}
{"INCIDENT ID": "Incident 614", "TITLE": "Google Bard Allegedly Generates False Allegations Against Consulting Firms Used in Research Presented in Australian Parliamentary Inquiry", "DESCRIPTION": "Australian academics reportedly used Google Bard AI to generate case studies for a parliamentary inquiry, leading to false allegations against major consultancy firms. The AI-generated misinformation prompted an apology from the academics, causing reputational harm for all parties involved and raising concerns about the reliability of AI tools in producing accurate and unbiased information.", "DATE": "2023-11-02", "ALLEGED DEPLOYER OF AI SYSTEM": "James Guthrie", "ALLEGED DEVELOPER OF AI SYSTEM": "Google Bard", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "James Guthrie, James Guthrie's co-authors, Parliament of Australia, KPMG, Deloitte"}
{"INCIDENT ID": "Incident 615", "TITLE": "Colorado Lawyer Filed a Motion Citing Hallucinated ChatGPT Cases", "DESCRIPTION": "A Colorado Springs attorney, Zachariah Crabill, mistakenly used hallucinated ChatGPT-generated legal cases in court documents. The AI software provided false case citations, leading to the denial of a motion and legal repercussions for Crabill, highlighting risks in using AI for legal research.", "DATE": "2023-06-13", "ALLEGED DEPLOYER OF AI SYSTEM": "Zachariah Crabill", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI, ChatGPT", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Zachariah Crabill's client, Zachariah Crabill, Legal system"}
{"INCIDENT ID": "Incident 616", "TITLE": "Sports Illustrated Is Alleged to Have Used AI to Invent Fake Authors and Their Articles", "DESCRIPTION": "Sports Illustrated, managed by The Arena Group, allegedly used AI-generated authors and content, compromising journalistic integrity. Profiles of these fictitious authors, complete with AI-generated headshots, appeared alongside articles, misleading readers. The issue was exposed when inconsistencies in author identities and writing quality were noticed, leading to the removal of this content from the publication's website.", "DATE": "2023-11-27", "ALLEGED DEPLOYER OF AI SYSTEM": "The Arena Group, Sports Illustrated", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "General public, Readers of Sports Illustrated, Journalistic integrity"}
{"INCIDENT ID": "Incident 620", "TITLE": "A Robot at a Tesla Factory in Texas Allegedly Injured an Engineer", "DESCRIPTION": "A Tesla manufacturing robot at the Giga Texas factory is reported to have malfunctioned, injuring an engineer. The robot, which was designed for handling car parts, is described as having caused a significant open wound in the engineer. This incident occurred in the context of broader safety concerns at the factory, with evidence suggesting underreporting of workplace accidents. The 2021 incident highlights the risks associated with robotic automation in industrial settings.", "DATE": "2021-11-10", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Tesla workers, Tesla engineer"}
{"INCIDENT ID": "Incident 623", "TITLE": "Google Bard Allegedly Generated Fake Legal Citations in Michael Cohen Case", "DESCRIPTION": "Michael Cohen, former lawyer for Donald Trump, claims to have used Google Bard, an AI chatbot, to generate legal case citations. These false citations were unknowingly included in a court motion by Cohen's attorney, David M. Schwartz. The AI's misuse highlights emerging risks in legal technology, as AI-generated content increasingly infiltrates professional domains.", "DATE": "2023-12-12", "ALLEGED DEPLOYER OF AI SYSTEM": "Michael Cohen, David M. Schwartz", "ALLEGED DEVELOPER OF AI SYSTEM": "Google Bard, Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Michael Cohen, David M. Schwartz"}
{"INCIDENT ID": "Incident 624", "TITLE": "Child Sexual Abuse Material Taints Image Generators", "DESCRIPTION": "The LAION-5B dataset (a commonly used dataset with more than 5 billion image-description pairs) was found by researchers to contain child sexual abuse material (CSAM), which increases the likelihood that downstream models will produce CSAM imagery. The discovery taints models built with the LAION dataset requiring many organizations to retrain those models. Additionally, LAION must now scrub the dataset of the imagery.", "DATE": "2023-12-20", "ALLEGED DEPLOYER OF AI SYSTEM": "Various people, Various organizations", "ALLEGED DEVELOPER OF AI SYSTEM": "LAION", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "LAION, Various people, Various organizations, General public, Children"}
{"INCIDENT ID": "Incident 626", "TITLE": "Social Media Scammers Used Deepfakes of Taylor Swift and Several Other Celebrities in Fraudulent Le Creuset Cookware Giveaways", "DESCRIPTION": "Scammers reportedly made deepfakes of Taylor Swift, Selena Gomez, Joanna Gaines, Lainey Wilson, Ree Drummond, Oprah, Jennifer Lopez, Trisha Yearwood, Martha Stewart, and Blake Shelton promoting a Le Creuset giveaway. These AI-generated ads, appearing on Meta and TikTok, falsely claimed users could receive free cookware by paying a small shipping fee. Victims were unknowingly enrolled in a costly monthly subscription.", "DATE": "2023-12-26", "ALLEGED DEPLOYER OF AI SYSTEM": "Unknown scammers", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake technology developers", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Trisha Yearwood, Taylor Swift, Selena Gomez, Ree Drummond, Oprah, Martha Stewart, Le Creuset, Lainey Wilson, Joanna Gaines, Jennifer Lopez, General public, Fans, Blake Shelton"}
{"INCIDENT ID": "Incident 628", "TITLE": "Fake Biden Voice in Robocall Misleads New Hampshire Democratic Voters", "DESCRIPTION": "A robocall imitating President Joe Biden's voice urged New Hampshire Democrats not to vote in the primary, misleadingly stating that their votes were more crucial in the November election. This incident undermines the democratic process.", "DATE": "2024-01-22", "ALLEGED DEPLOYER OF AI SYSTEM": "unknown", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "President Joe Biden, New Hampshire voters, Kathy Sullivan, Democracy"}
{"INCIDENT ID": "Incident 630", "TITLE": "Alleged Macy's Facial Recognition Error Leads to Wrongful Arrest and Subsequent Sexual Assault in Jail", "DESCRIPTION": "Harvey Murphy Jr. was wrongfully accused of robbing a Sunglass Hut due to an alleged misidentification by the facial recognition system operated by Macy's. While in custody for ten days, he was sexually assaulted. He is now suing Macy's, EssilorLuxottica (Sunglass Hut's parent), and others, for $10 million.", "DATE": "2022-01-22", "ALLEGED DEPLOYER OF AI SYSTEM": "Macy's", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown, Macy's", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Harvey Murphy Jr"}
{"INCIDENT ID": "Incident 631", "TITLE": "Chatbot for DPD Malfunctioned and Swore at Customers and Criticized Its Own Company", "DESCRIPTION": "DPD's AI chatbot, used for customer service, appeared to malfunction following a system update, leading to inappropriate responses including swearing and criticizing the company. The incident, which became viral on social media, occurred after the chatbot was updated, prompting DPD to disable the malfunctioning AI component.", "DATE": "2024-01-18", "ALLEGED DEPLOYER OF AI SYSTEM": "DPD", "ALLEGED DEVELOPER OF AI SYSTEM": "DPD", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Ashley Beauchamp, DPD"}
{"INCIDENT ID": "Incident 634", "TITLE": "Deepfake CFO Scam Costs Company $25 Million", "DESCRIPTION": "A finance employee at a multinational was deceived into transferring $25 million by fraudsters using deepfake technology to impersonate the firm's CFO in a video call, according to the Hong Kong police.", "DATE": "2024-02-02", "ALLEGED DEPLOYER OF AI SYSTEM": "Unknown deepfake technology developers", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake technology developers", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Unnamed multinational company, Unnamed finance employee"}
{"INCIDENT ID": "Incident 637", "TITLE": "Gunshot Detection Technology ShotSpotter (now SoundThinking) Reportedly Only Has 47% Accuracy in Chicago System", "DESCRIPTION": "SoundThinking's (formerly ShotSpotter's) system in Chicago, with a reported 47% accuracy rate for detecting actual gunshots, led to potential public safety risks by failing to alert police to real shootings, possibly delaying emergency response to violent incidents and misdirecting law enforcement resources.", "DATE": "2024-01-31", "ALLEGED DEPLOYER OF AI SYSTEM": "Chicago Police Department", "ALLEGED DEVELOPER OF AI SYSTEM": "SoundThinking, ShotSpotter", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "General public, Chicago Residents, Chicago Minority Communities"}
{"INCIDENT ID": "Incident 638", "TITLE": "Fatal Crash Involving Tesla Full Self-Driving Claims Employee's Life", "DESCRIPTION": "A Tesla employee, Hans von Ohain, was killed in a crash while allegedly using the Full Self-Driving feature. The car failed to navigate mountain curves, leading to a fatal collision, possibly making von Ohain the first known fatality of the Full Self-Driving feature.", "DATE": "2022-05-16", "ALLEGED DEPLOYER OF AI SYSTEM": "Hans von Ohain", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Hans von Ohain, Erik Rossiter"}
{"INCIDENT ID": "Incident 644", "TITLE": "State-Sponsored Hackers Escalate Phishing Attacks Using Artificial Intelligence", "DESCRIPTION": "State-sponsored hackers from North Korea, Iran, Russia, and China are reportedly leveraging artificial intelligence to conduct sophisticated phishing and social engineering attacks. They target global defense, cybersecurity, and cryptocurrency sectors, aiming to steal sensitive information and, in the case of North Korea, cryptocurrencies to help fund its illicit nuclear program.", "DATE": "2024-02-18", "ALLEGED DEPLOYER OF AI SYSTEM": "North Korean hackers, Iranian hackers, Russian hackers, Chinese hackers", "ALLEGED DEVELOPER OF AI SYSTEM": "North Korean government, Iranian government, Russian government, Chinese government", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Individual professionals on LinkedIn, Global defense companies, Cybersecurity firms, Cryptocurrency exchanges"}
{"INCIDENT ID": "Incident 645", "TITLE": "Seeming Pattern of Gemini Bias and Sociotechnical Training Failures Harm Google's Reputation", "DESCRIPTION": "Google's Gemini chatbot faced many reported bias issues upon release, leading to a variety of problematic outputs like racial inaccuracies and political biases, including regarding Chinese and Indian politics. It also reportedly over-corrected racial diversity in historical contexts and advanced controversial perspectives, prompting a temporary halt and an apology from Google.", "DATE": "2024-02-21", "ALLEGED DEPLOYER OF AI SYSTEM": "Google, Gemini", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "General public"}
{"INCIDENT ID": "Incident 646", "TITLE": "Snapchat's Algorithm Alleged to Link Minor with Sex Offenders", "DESCRIPTION": "A judge ruled Snapchat not liable under Section 230 after its algorithm connected a minor with convicted sex offenders on multiple occasions, leading to sexual assaults first in 2019 and again in 2021. The platform's \"Quick Add\" feature was implicated in facilitating the connections between the minor and the offenders.", "DATE": "2024-02-22", "ALLEGED DEPLOYER OF AI SYSTEM": "Snapchat", "ALLEGED DEVELOPER OF AI SYSTEM": "Snapchat", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "minors"}
{"INCIDENT ID": "Incident 648", "TITLE": "Alleged Deepfake Audio of Imran Khan Calls for Election Boycott, Misleading Pakistan Voters", "DESCRIPTION": "A purported deepfake audio clip, falsely attributed to Imran Khan urging a PTI (Pakistan Tehreek-e-Insaf) election boycott, circulated on social media on the eve of Pakistan's general elections. This sophisticated AI-generated misinformation aimed to mislead voters, highlighting the growing challenge of digital manipulation in political discourse.", "DATE": "2024-02-07", "ALLEGED DEPLOYER OF AI SYSTEM": "Unknown social media accounts", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Voters in Pakistan, PTI (Pakistan Tehreek-e-Insaf), Imran Khan, Democracy"}
{"INCIDENT ID": "Incident 649", "TITLE": "Deepfake Audio Falsely Attributes Controversial Remarks to Keir Starmer About the Rochdale Azhar Ali Crisis", "DESCRIPTION": "A deepfake audio clip, falsely claiming to be Keir Starmer discussing the Rochdale byelection and Labour's withdrawl of support for Azhar Ali, circulated online, achieving over 250,000 views. Experts confirmed its inauthenticity, highlighting a significant misuse of AI in fabricating political content.", "DATE": "2024-02-14", "ALLEGED DEPLOYER OF AI SYSTEM": "Various social media accounts", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "General public, British voters, British Labour Party, Keir Starmer, Democracy"}
{"INCIDENT ID": "Incident 650", "TITLE": "AI-Generated Images of Trump with Black Voters Spread as Disinformation Before U.S. Primary Elections", "DESCRIPTION": "In the run-up to the U.S. primary elections, supporters of Donald Trump shared AI-generated images showing him with Black voters in an attempt to sway African-American votes. These deepfakes, including Trump's distorted hand visuals, were initially created by satirical accounts but were later misappropriated for political disinformation, misleading millions on social media platforms.", "DATE": "2024-03-04", "ALLEGED DEPLOYER OF AI SYSTEM": "Various social media accounts, Trump supporters", "ALLEGED DEVELOPER OF AI SYSTEM": "Various social media accounts, Trump supporters", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Public discourse integrity, General public, Democracy, African-American voters, Black voters"}
{"INCIDENT ID": "Incident 652", "TITLE": "Two Florida Middle School Students Arrested Under New Law for Allegedly Having Made and Shared Deepfake Nudes of Their Classmates", "DESCRIPTION": "Two teenaged boys from Miami, Florida, were arrested for allegedly creating and sharing AI-generated nude images of their classmates. Charged under a 2022 Florida law, they face third-degree felonies for producing and disseminating altered sexual depictions.", "DATE": "2023-12-06", "ALLEGED DEPLOYER OF AI SYSTEM": "Two unnamed middle school boys", "ALLEGED DEVELOPER OF AI SYSTEM": "Two unnamed middle school boys", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Classmates of two unnamed middle school boys"}
{"INCIDENT ID": "Incident 653", "TITLE": "Two Investment Firms Charged with Making False Claims of Artificial Intelligence Capabilities in Case of AI Washing", "DESCRIPTION": "In a case of AI washing, the SEC charged two investment advisers, Delphia and Global Predictions, for falsely stating their use of artificial intelligence in their investment strategies between 2019 and 2023. Their misleading claims resulted in a settlement whereby the firms agreed to pay a total of $400,000 in penalties, highlighting the critical consequences of misrepresenting AI capabilities on investment decisions and trust.", "DATE": "2019-01-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Global Predictions Inc., Delphia (USA) Inc.", "ALLEGED DEVELOPER OF AI SYSTEM": "Global Predictions Inc., Delphia (USA) Inc.", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Investors"}
{"INCIDENT ID": "Incident 656", "TITLE": "Alleged Deepfake Disinformation Broadcast by Russian State TV Blames Ukraine for Moscow Attack", "DESCRIPTION": "Russian state media is reported to have broadcast deepfaked videos of Ukrainian officials, notably fabricating a video of Secretary of the National Security and Defense Council of Ukraine admitting to orchestrating the Crocus City Hall terror attack in Moscow. The effort appears to be a bid to wrongly assign blame for the incident, which ISIS-K has officially claimed.", "DATE": "2024-03-23", "ALLEGED DEPLOYER OF AI SYSTEM": "Russian state media, NTV Channel", "ALLEGED DEVELOPER OF AI SYSTEM": "Russian state media, NTV Channel", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Journalism, Ukraine, Oleksiy Danilov, Kyrylo Budanov"}
{"INCIDENT ID": "Incident 657", "TITLE": "ChatGPT Account Compromise Leads to Unintended Data Exposure", "DESCRIPTION": "A security breach involving ChatGPT led to the exposure of sensitive conversations, including login credentials and personal data, after a user account was compromised. OpenAI responded to the incident with an explanation.", "DATE": "2024-01-30", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "ChatGPT users, Chase Whiteside"}
{"INCIDENT ID": "Incident 659", "TITLE": "Mass Surveillance Facial Recognition Program Reportedly Targets Palestinians in Gaza", "DESCRIPTION": "In Gaza, a previously undisclosed facial recognition program by Israeli forces is reportedly conducting mass surveillance on Palestinians in the wake of the October 7th Hamas attacks. The program, utilizing Corsight and Google Photos technologies, identifies individuals from crowds and drone footage. Allegedly, the technology often incorrectly flags civilians as militants, with one pronounced case being the poet Mosab Abu Toha on November 19, 2023.", "DATE": "2023-10-07", "ALLEGED DEPLOYER OF AI SYSTEM": "Unit 8200, Israeli military intelligence, Israeli government", "ALLEGED DEVELOPER OF AI SYSTEM": "Google Photos, Corsight", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Palestinians, Mosab Abu Toha, Gazans"}
{"INCIDENT ID": "Incident 660", "TITLE": "Investigation Reports Unauthorized Deepfake Pornography Harms Thousands of Celebrities", "DESCRIPTION": "A Channel 4 News investigation alleges that nearly 4,000 celebrities globally, including 255 British figures, were victims of deepfake pornography. Faces were superimposed onto explicit content using AI, with the top deepfake sites garnering 100 million views in three months, according to their findings.", "DATE": "2024-03-21", "ALLEGED DEPLOYER OF AI SYSTEM": "Deepfake website operators", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake technology developers", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "celebrities, British public figures, Cathy Newman"}
{"INCIDENT ID": "Incident 663", "TITLE": "China Reportedly Intensifying AI to Spread Disinformation to U.S. and Taiwanese Voters", "DESCRIPTION": "AI tools linked to China were used to disseminate disinformation targeting voters in the U.S. and Taiwan, according to a Microsoft report. These operations included AI-generated imagery and audio to influence political perceptions and election outcomes, originating from the APT Storm-1376 (also known as Spamouflage and Dragonbridge).", "DATE": "2024-04-05", "ALLEGED DEPLOYER OF AI SYSTEM": "Storm-1376, Spamouflage, Dragonbridge, Chinese Communist Party", "ALLEGED DEVELOPER OF AI SYSTEM": "Storm-1376, Spamouflage, Dragonbridge, Chinese Communist Party", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "U.S. voters, Taiwanese voters, General public, Election integrity, Democracy"}
{"INCIDENT ID": "Incident 665", "TITLE": "Facial Recognition Misidentification at New World Westend in New Zealand", "DESCRIPTION": "A facial recognition system at New World Westend supermarket misidentified a M\u0101ori woman as a known offender during its trial. The woman was wrongfully accused of trespassing and experienced public embarrassment, raising concerns about racial bias and the technology's accuracy. The supermarket acknowledged its error and apologized.", "DATE": "2024-04-02", "ALLEGED DEPLOYER OF AI SYSTEM": "Foodstuffs, New World Westend", "ALLEGED DEVELOPER OF AI SYSTEM": "Foodstuffs", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Te Ani Solomon, M\u0101ori Community"}
{"INCIDENT ID": "Incident 666", "TITLE": "Presidency of Moldova Refutes Deepfake Video Slandering President Maia Sandu", "DESCRIPTION": "A deepfake video falsifying President Maia Sandu's image and voice was released in Moldova, portraying her in a negative light to sow division and undermine democratic institutions. This video appeared on Telegram and was linked to Russian disinformation efforts.", "DATE": "2023-12-29", "ALLEGED DEPLOYER OF AI SYSTEM": "Unknown deepfake creator, Russian propagandists", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake creator, Russian propagandists", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Maia Sandu, Presidency of Moldova, Government of Moldova, Democracy, General public"}
{"INCIDENT ID": "Incident 669", "TITLE": "Deepfake of Long-Deceased Suharto Circulating in Run-up to February 2024 Indonesian Elections", "DESCRIPTION": "An AI-generated deepfake of Suharto, the deceased Indonesian dictator, was generated and circulated by the Golkar Party ahead of the February 2024 Indonesian elections. This video, which aimed to influence voter perceptions by invoking Suharto's legacy, sought to manipulate public opinion and misused deceased individuals' likenesses for political gain. The incident is another example of political deepfakes creating convincing misinformation.", "DATE": "2024-02-11", "ALLEGED DEPLOYER OF AI SYSTEM": "Golkar Party", "ALLEGED DEVELOPER OF AI SYSTEM": "Golkar Party", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Indonesian electorate, Electoral integrity, Democracy"}
{"INCIDENT ID": "Incident 671", "TITLE": "Many Political Deepfakes Circulating in Run-up to 2024 Pakistani General Elections", "DESCRIPTION": "During Pakistan's 2024 general elections, politically motivated AI-generated deepfakes were circulated. These deepfakes falsely portrayed political figures in misleading contexts, spreading misinformation and aiming to influence voter perceptions and election outcomes.", "DATE": "2024-02-08", "ALLEGED DEPLOYER OF AI SYSTEM": "Pakistani political parties, Misinformation networks", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake creator, Pakistani political parties, Misinformation networks", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Rana Atif, Raja Bashara, Naeem Haider Panjutha, Imran Khan"}
{"INCIDENT ID": "Incident 672", "TITLE": "Lavender AI System Reportedly Directs Gaza Strikes with High Civilian Casualty Rate", "DESCRIPTION": "The AI system \"Lavender\" has reportedly been used by the Israel Defense Forces (IDF) to identify targets in Gaza with minimal human oversight, resulting in allegedly high civilian casualty rates. The system, designed to speed up target identification, seems to have led to significant errors and mass casualties.", "DATE": "2024-04-03", "ALLEGED DEPLOYER OF AI SYSTEM": "Unit 8200, Israel Defense Forces", "ALLEGED DEVELOPER OF AI SYSTEM": "Unit 8200, Israel Defense Forces", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Palestinians, Gazans"}
{"INCIDENT ID": "Incident 673", "TITLE": "Deepfakes Circulating and Eroding Electoral Integrity in the Lead-up to 2024 South Korean legislative election", "DESCRIPTION": "In the lead-up to Korea's parliamentary elections, at least 129 deepfake videos and images were reported to have been detected, violating new election laws. These AI-generated deepfakes were used to mislead and manipulate public opinion, prompting a crackdown by the National Election Commission.", "DATE": "2024-02-19", "ALLEGED DEPLOYER OF AI SYSTEM": "Unknown political operatives, Unknown political groups", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown political operatives, Unknown political groups", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Yoon Suk-yeol, Korean voters, Journalism, Electoral integrity, Democracy"}
{"INCIDENT ID": "Incident 676", "TITLE": "Deepfake Audio Falsely Depicts Philippines President Ferdinand Marcos Jr. Ordering Military Action", "DESCRIPTION": "A deepfake video falsely depicted President Ferdinand Marcos Jr. of the Philippines ordering an attack on China, exacerbating tensions in the West Philippine Sea. The video, designed to mislead, was promptly debunked by the Presidential Communications Office.", "DATE": "2024-04-24", "ALLEGED DEPLOYER OF AI SYSTEM": "unknown", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Ferdinand Marcos Jr., Government of the Philippines, Philippines, General public"}
{"INCIDENT ID": "Incident 654", "TITLE": "Microsoft Copilot Designer Reportedly Generated Inappropriate AI Images", "DESCRIPTION": "A Microsoft engineer reported that Copilot Designer, an AI image generator, creates content depicting sex, violence, bias, and more. Despite raising concerns and suggesting improvements, the tool remains public, prompting a letter to the FTC.", "DATE": "2024-03-06", "ALLEGED DEPLOYER OF AI SYSTEM": "Microsoft", "ALLEGED DEVELOPER OF AI SYSTEM": "Microsoft", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "General public, minors"}
{"INCIDENT ID": "Incident 655", "TITLE": "Scams Reportedly Impersonating Wealthy Investors Proliferating on Facebook", "DESCRIPTION": "Scams are reportedly proliferating throughout Facebook impersonating wealthy individuals such as Bill Ackman, Cathie Wood, Steve Cohen, Peter Lynch, and Ray Dalio. In some cases, it seems deepfake technology is being employed, while simultaneously Facebook's own AI systems are allegedly faltering in their ability to halt the spread of these fraudulent ads despite being reported.", "DATE": "2024-01-11", "ALLEGED DEPLOYER OF AI SYSTEM": "Meta, Facebook, scammers", "ALLEGED DEVELOPER OF AI SYSTEM": "Meta, Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Investors, General public, Bill Ackman, Cathie Wood, Steve Cohen, Peter Lynch, Ray Dalio, Peter Bourget"}
{"INCIDENT ID": "Incident 658", "TITLE": "The Arizona Agenda Produced a Deepfake of Kari Lake Advocating for the Publication Without Her Consent", "DESCRIPTION": "The Arizona Agenda produced a deepfake video of Republican Senate candidate Kari Lake giving a testimonial about the publication with the seeming intention of educating the general public about the dangers of deepfakes in the coming election cycle. However, the Arizona Agenda appears not to have sought Lake's consent, prompting a cease-and-desist letter from her campaign.", "DATE": "2024-03-22", "ALLEGED DEPLOYER OF AI SYSTEM": "The Arizona Agenda, Hank Stephenson", "ALLEGED DEVELOPER OF AI SYSTEM": "The Arizona Agenda, Hank Stephenson", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Kari Lake, General public, Journalism, Democracy"}
{"INCIDENT ID": "Incident 661", "TITLE": "Leonardo AI's Platform Alleged to Have Been Used for Creating Nonconsensual Celebrity Deepfakes", "DESCRIPTION": "Sydney-based startup Leonardo AI's text-to-image generator was alleged to have been exploited to create nonconsensual sexual images of celebrities, bypassing content moderation systems with user-shared prompts.", "DATE": "2024-03-26", "ALLEGED DEPLOYER OF AI SYSTEM": "Telegram community users, Reddit users, Leonardo AI users", "ALLEGED DEVELOPER OF AI SYSTEM": "Leonardo AI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "public figures, celebrities"}
{"INCIDENT ID": "Incident 662", "TITLE": "Washington State's Lottery AI Site Reportedly Generates Inappropriate User Image", "DESCRIPTION": "An AI-powered website by Washington State's Lottery is reported to have inadvertently produced a softcore pornographic image of a user, leading to the site\u2019s immediate shutdown out of caution.", "DATE": "2024-04-02", "ALLEGED DEPLOYER OF AI SYSTEM": "Washington State's Lottery", "ALLEGED DEVELOPER OF AI SYSTEM": "Washington State's Lottery", "ALLEGED HARMED OR NEARLY HARMED PARTIES": ""}
{"INCIDENT ID": "Incident 664", "TITLE": "Deepfake Generated by the Lincoln Project of Trump's Father Used in Political Attack Ad", "DESCRIPTION": "The Lincoln Project used AI to create a deepfake video of Donald Trump's deceased father criticizing him. Although they made it clear that the video was a deepfake, the deeply personal nature of the attack represents a corrosive use of artificial intelligence in undermining democratic norms during an election cycle.", "DATE": "2024-02-17", "ALLEGED DEPLOYER OF AI SYSTEM": "Lincoln Project", "ALLEGED DEVELOPER OF AI SYSTEM": "Lincoln Project", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Public discourse integrity, Political integrity, General public, Donald Trump"}
{"INCIDENT ID": "Incident 667", "TITLE": "Manipulated Deepfake Video of Lai Ching-te Endorsing Rivals in Lead-up to January Presidential Elections", "DESCRIPTION": "In the lead-up to Taiwan's presidential election in January 2024, a deepfake video circulated showing candidate Lai Ching-te endorsing his rivals. Taiwanese intelligence issued warnings of intensified Chinese disinformation campaigns aimed at manipulating the election outcome.", "DATE": "2023-12-16", "ALLEGED DEPLOYER OF AI SYSTEM": "People's Liberation Army, Chinese Communist Party, Base 311", "ALLEGED DEVELOPER OF AI SYSTEM": "People's Liberation Army, Chinese Communist Party, Base 311", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Taiwanese voters, Lai Ching-te, Electoral integrity, Democratic Progressive Party, Democracy"}
{"INCIDENT ID": "Incident 668", "TITLE": "Proliferation of Deepfakes Disrupting 2024 Lok Sabha Elections", "DESCRIPTION": "Digital manipulators in India are using deepfake technology to influence the 2024 Lok Sabha elections. These AI-generated videos and audio clips are designed to tarnish the reputations of political candidates, challenging the integrity of electoral processes.", "DATE": "2023-12-27", "ALLEGED DEPLOYER OF AI SYSTEM": "Political candidates of the 2024 Lok Sabha elections", "ALLEGED DEVELOPER OF AI SYSTEM": "The Indian Deepfaker, The Digital Publicity, Rohit Pal, Obiyan Infotech, Merakii Group", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Political candidates targeted by deepfakes, Indian electorate, India, Democracy"}
{"INCIDENT ID": "Incident 670", "TITLE": "Deepfakes of Deceased Indian Politicians for Election Campaigning Are Increasingly Being Deployed", "DESCRIPTION": "In the lead-up to India's 2024 general elections, AI technology was used to create deepfake videos of deceased politicians, such as M. Karunanidhi and J. Jayalalithaa, aiming to influence voter behavior and campaign strategies. These AI-generated appearances are contributing to the erosion of trust in democratic processes and media discourse.", "DATE": "2024-01-23", "ALLEGED DEPLOYER OF AI SYSTEM": "Dravida Munnetra Kazhagam, DMK, Various Indian political parties", "ALLEGED DEVELOPER OF AI SYSTEM": "Muonium, The Indian Deepfaker", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Indian electorate, Indian voters, Democracy, Electoral integrity, Media discourse, M. Karunanidhi, J. Jayalalithaa"}
{"INCIDENT ID": "Incident 674", "TITLE": "Manipulated Media via AI Disinformation and Deepfakes in 2024 Elections Erode Trust Across More Than 50 Countries", "DESCRIPTION": "AI-driven election disinformation is escalating globally, leveraging easy-to-use generative AI tools to create convincing deepfakes that mislead voters. This shift has simplified the process for individuals to generate fake content, having already eroded trust in elections by undermining public trust and manipulating voter perceptions. Evidence has, for example, been documented in incidents across the U.S., Moldova, Slovakia, Bangladesh, and Taiwan.", "DATE": "2024-03-14", "ALLEGED DEPLOYER OF AI SYSTEM": "Russian government, Political operatives, Political consultants, Chinese Communist Party", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake creators, OpenAI, Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Voters, Public trust, Political figures, General public, Electoral integrity, Democracy, Civic society"}
{"INCIDENT ID": "Incident 675", "TITLE": "Racist and Antisemitic Deepfake Audio Mimicking School Principal Fabricated by Athletic Director", "DESCRIPTION": "The athletic director of Pikesville High School in Baltimore used AI to create a deepfake audio clip that mimicked the school principal, incorporating racist and antisemitic remarks. The clip, aimed at discrediting the principal, spread widely, resulting in threats and administrative leave for the principal.", "DATE": "2024-01-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Dazhon Darien", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake technology developer", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Eric Eiswert, Pikesville High School, Pikesville High School students and staff, Baltimore County Public Schools community"}
{"INCIDENT ID": "Incident 677", "TITLE": "ChatGPT and Perplexity Reportedly Manipulated into Breaking Content Policies in AI Boyfriend Scenarios", "DESCRIPTION": "The \"Dan\" (\"Do Anything Now\") AI boyfriend is a trend on TikTok in which users appear to regularly manipulate ChatGPT to adopt boyfriend personas, breaching content policies. ChatGPT 3.5 is reported to regularly produce explicitly sexual content, directly violating its intended safety protocols. GPT-4 and Perplexity AI were subjected to similar manipulations, and although they exhibited more resistance to breaches, some prompts were reported to break its guidelines.", "DATE": "2024-04-29", "ALLEGED DEPLOYER OF AI SYSTEM": "TikTok users, Julia Munslow, ChatGPT, GPT-3.5, GPT-4, Perplexity AI", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI, Perplexity.ai", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "General public, OpenAI, Perplexity AI"}
{"INCIDENT ID": "Incident 678", "TITLE": "ChatGPT Factual Errors Lead to Filing of Complaint of GDPR Privacy Violation", "DESCRIPTION": "The activist organization noyb, founded by Max Schrems, filed a complaint in Europe against OpenAI alleging that ChatGPT violates the General Data Protection Regulation (GDPR) by providing inaccurate personal information such as birthdates about individuals.", "DATE": "2024-04-29", "ALLEGED DEPLOYER OF AI SYSTEM": "ChatGPT", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "noyb, Max Schrems, General public"}
{"INCIDENT ID": "Incident 679", "TITLE": "A Deepfake of Senator Elizabeth Warren Circulated Saying Republicans Should Not Vote", "DESCRIPTION": "In February 2023, a deepfake of Senator Elizabeth Warren circulated on social media in which doctored footage of her from an MSNBC interview had her claiming that she believes Republicans should not vote.", "DATE": "2023-02-20", "ALLEGED DEPLOYER OF AI SYSTEM": "Unnamed deepfake creator, TikTok, Twitter", "ALLEGED DEVELOPER OF AI SYSTEM": "Unnamed deepfake creator", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Elizabeth Warren, MSNBC, Republicans, Democrats, Democracy, Election integrity, General public"}
{"INCIDENT ID": "Incident 680", "TITLE": "Russia-Linked AI CopyCop Site Identified as Modifying and Producing at Least 19,000 Deceptive Reports", "DESCRIPTION": "In early March 2024, a network named CopyCop began publishing modified news stories using AI, altering content to spread partisan biases and disinformation. These articles, initially from legitimate sources, were manipulated by AI models, possibly developed by OpenAI, to disseminate Russian propaganda. Over 19,000 articles were published, targeting divisive political issues and creating false narratives.", "DATE": "2024-03-01", "ALLEGED DEPLOYER OF AI SYSTEM": "CopyCop, Russia-linked network", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI, ChatGPT", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "General public, Journalism, Democracy"}
{"INCIDENT ID": "Incident 681", "TITLE": "Never Back Down Super PAC for Ron DeSantis Uses AI Donald Trump Voice in Attack Ad Against Kim Reynolds", "DESCRIPTION": "A pro-Ron DeSantis super PAC released an ad featuring an AI-generated voice of Donald Trump. The ad, created by Never Back Down, aimed to criticize Trump\u2019s treatment of Iowa Gov. Kim Reynolds. The AI-generated voice was confirmed to be based on Trump's post from his social media. This incident is an example of potential deception in political advertising through AI-generated content.", "DATE": "2023-07-17", "ALLEGED DEPLOYER OF AI SYSTEM": "Ron DeSantis's presidential campaign, Never Back Down", "ALLEGED DEVELOPER OF AI SYSTEM": "Never Back Down", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Kim Reynolds, Donald Trump"}
{"INCIDENT ID": "Incident 682", "TITLE": "GOP Pollster Shares AI-Generated Images to Fabricate Appearance of Black Voter Support", "DESCRIPTION": "GOP pollster Patrick Ruffini shared AI-generated images depicting Black men supporting the Republican Party just before Black History Month. These fabricated photos misled the public by creating a false narrative of racial diversity within the GOP, undermining trust and potentially influencing voter perceptions. The incident raises significant concerns about the misuse of AI to spread misinformation and manipulate political representation, particularly affecting Black communities.", "DATE": "2024-02-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Patrick Ruffini", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake creator", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "General public, Democracy, Black Americans, African-American voters"}
{"INCIDENT ID": "Incident 683", "TITLE": "Scammers Using Deepfakes of Women's Faces and Voices for False and Offensive Advertisements", "DESCRIPTION": "Scammers used AI tools from HeyGen and ElevenLabs to create deepfake videos of influencers Michel Janse, Olga Loiek, Shad\u00e9 Zahrai, and Carrie Williams, misusing Lana Smalls's voice in Williams's case. These videos promoted offensive products and false messages, in some cases targeting nationalist Chinese men to boost China-Russia ties, causing emotional distress and damaging the victims' reputations.", "DATE": "2024-03-28", "ALLEGED DEPLOYER OF AI SYSTEM": "Unknown scammers", "ALLEGED DEVELOPER OF AI SYSTEM": "HeyGen, ElevenLabs", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Olga Loiek, Michel Janse, Lana Smalls, Carrie Williams, Shad\u00e9 Zahrai"}
{"INCIDENT ID": "Incident 684", "TITLE": "Google Books Appears to Be Indexing Works Written by AI", "DESCRIPTION": "Google Books is indexing low-quality, AI-generated books, degrading its database and potentially distorting Google Ngram Viewer's analysis of language trends. This integration of inaccurate or misleading information undermines trust, disseminates poor-quality content, and wastes resources as researchers must spend time clearing up the misinformation.", "DATE": "2024-04-04", "ALLEGED DEPLOYER OF AI SYSTEM": "Google, Google Books", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Google Books, Google Ngram Viewer, Researchers, General public"}
{"INCIDENT ID": "Incident 685", "TITLE": "The WHO's S.A.R.A.H. Bot Reported to Provide Inconsistent and Inadequate Health Information", "DESCRIPTION": "The WHO's AI-powered health advisor, S.A.R.A.H. (Smart AI Resource Assistant for Health), is alleged to provide inconsistent and inadequate health information. The bot reportedly gives contradictory responses to the same queries, fails to offer specific contact details for healthcare providers, and inadequately handles severe mental health crises, often giving irrelevant or unhelpful advice.", "DATE": "2024-04-24", "ALLEGED DEPLOYER OF AI SYSTEM": "WHO, S.A.R.A.H. (Smart AI Resource Assistant for Health)", "ALLEGED DEVELOPER OF AI SYSTEM": "WHO", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "General public, People seeking medical advice"}
{"INCIDENT ID": "Incident 686", "TITLE": "Meta AI Image Generator Reportedly Fails to Accurately Represent Interracial Relationships", "DESCRIPTION": "Meta's AI image generator is alleged to produce inaccurate and biased images, consistently failing to depict interracial relationships involving Asian individuals and Caucasian or Black individuals. Instead, it generates images featuring two Asian people or stereotypes, erasing the diversity and representation of Asian people.", "DATE": "2024-04-03", "ALLEGED DEPLOYER OF AI SYSTEM": "Meta", "ALLEGED DEVELOPER OF AI SYSTEM": "Meta", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Asian People, Interracial couples, General public"}
{"INCIDENT ID": "Incident 687", "TITLE": "Deepfake Porn Sites Use Breeze Liu's Image Without Consent", "DESCRIPTION": "Porn sites are alleged to have used AI-generated images of Breeze Liu without her consent, leading to severe emotional distress. Liu discovered a video of herself on Pornhub, which was then deepfaked and spread across over 800 links. Despite efforts to remove the content, many sites refused to comply, perpetuating the violation and exploitation of her image.", "DATE": "2024-04-08", "ALLEGED DEPLOYER OF AI SYSTEM": "Pornhub, Various porn sites", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake creators", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Breeze Liu"}
{"INCIDENT ID": "Incident 688", "TITLE": "Scarlett Johansson Alleges OpenAI's Sky Imitates Her Voice Without Licensing", "DESCRIPTION": "OpenAI unveiled a voice assistant with a voice resembling Scarlett Johansson's, despite her refusal to license her voice. Johansson claimed the assistant, \"Sky,\" sounded \"eerily similar\" to her voice, leading her to seek legal action. OpenAI suspended Sky, asserting the voice was from a different actress.", "DATE": "2024-05-20", "ALLEGED DEPLOYER OF AI SYSTEM": "Sky voice assistant, Sam Altman, OpenAI", "ALLEGED DEVELOPER OF AI SYSTEM": "Sam Altman, OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Scarlett Johansson"}
{"INCIDENT ID": "Incident 689", "TITLE": "Holmen, Wisconsin Man Allegedly Used Stable Diffusion to Create and Then Share Sexually Explicit Images Depicting Minors", "DESCRIPTION": "The FBI has arrested Steven Anderegg of Holmen, Wisconsin for having allegedly used Stable Diffusion to generate about 13,000 sexually explicit images of minors, which he then is also alleged to have shared and distributed, including with at least one minor, via Telegram and Instagram. Anderegg was originally apprehended by state police in March, and this case marks one of the first times the FBI has brought charges against someone for having used AI to generate CSAM.", "DATE": "2024-03-26", "ALLEGED DEPLOYER OF AI SYSTEM": "Steven Anderegg", "ALLEGED DEVELOPER OF AI SYSTEM": "Stable Diffusion, Stability AI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "minors, General public"}
{"INCIDENT ID": "Incident 690", "TITLE": "ISIS Utilizes AI for Propaganda Videos in News Harvest Program", "DESCRIPTION": "ISIS supporters have created an AI-generated media program called News Harvest to disseminate propaganda videos. The program produces near-weekly broadcasts featuring AI-generated news anchors discussing ISIS operations globally, using cheap and easy-to-use AI tools. This development showcases the use of AI as a powerful propaganda tool for extremist groups.", "DATE": "2024-03-26", "ALLEGED DEPLOYER OF AI SYSTEM": "ISIS, ISIS supporters", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI, ElevenLabs", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "General public, People susceptible to radicalism"}
{"INCIDENT ID": "Incident 691", "TITLE": "Facewatch Reported to Have Wrongfully Flagged Home Bargains Customer as Shoplifter", "DESCRIPTION": "A facial-recognition software used by the British variety store Home Bargains is alleged to have misidentified \"Sara\" as a shoplifter, leading to staff searching her bag, escorting her from the premises, and banning her from the store. After, Facewatch is reported to have admitted its error to Sara. Facewatch is used by a number of different British stores.", "DATE": "2024-05-25", "ALLEGED DEPLOYER OF AI SYSTEM": "Home Bargains", "ALLEGED DEVELOPER OF AI SYSTEM": "Facewatch", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Sara, Home Bargains customers, General public"}
{"INCIDENT ID": "Incident 692", "TITLE": "London Metropolitan Police's Facial Recognition Technology Reportedly Misidentified Shaun Thompson as Suspect Leading to Arrest", "DESCRIPTION": "Sometime in February 2024, Shaun Thompson is reported to have walked by one of the London Metropolitan Police's facial recognition technology vans near London Bridge. He was almost immediately arrested because the technology is reported to have misidentified him as a suspect in an unrelated and unspecified crime.", "DATE": "2024-02-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Metropolitan Police Service", "ALLEGED DEVELOPER OF AI SYSTEM": "Metropolitan Police Service", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Shaun Thompson, General public"}
{"INCIDENT ID": "Incident 693", "TITLE": "Google AI Reportedly Delivering Confidently Incorrect and Harmful Information", "DESCRIPTION": "Google's AI search engine has reportedly been providing users with confidently incorrect and often harmful information. Reports highlight numerous inaccuracies, including misleading health advice and dangerous cooking suggestions. For example, it has falsely claimed Barack Obama as the first Muslim U.S. President, reflecting fringe conspiracy theories, or recommending that glue can be an ingredient in pizza.", "DATE": "2024-05-14", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Google users, General public"}
{"INCIDENT ID": "Incident 694", "TITLE": "Republican AI Ad Depicts Dystopian Future After Biden Reelection Announcement", "DESCRIPTION": "In response to Joe Biden's announcement that he will run again for office in 2024, the Republican National Committee (RNC) released an attack ad featuring AI-generated images that depict a dystopian vision of the U.S. Even though a small disclaimer was included, the images in the ad, which include scenes of AI-generated crises and conflict, harms information and electoral integrity.", "DATE": "2023-04-25", "ALLEGED DEPLOYER OF AI SYSTEM": "Republican National Committee (RNC)", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake creator", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Joe Biden, Democratic Party, Democracy, Election integrity, Information integrity"}
{"INCIDENT ID": "Incident 695", "TITLE": "Donald Trump's Presidential Campaign Released Deepfakes Attacking Ron DeSantis", "DESCRIPTION": "Former President Donald Trump released two AI-generated videos using deepfaked voices to mock Florida Governor Ron DeSantis. The first video, posted on platforms like Rumble and Instagram, depicted a chaotic and offensive fake Twitter Spaces event featuring deepfaked voices of Elon Musk, George Soros, Klaus Schwab, Dick Cheney, Adolf Hitler, and a generated voice of Satan. The second video showed a rocket with \"Ron 2024\" written beside it falling and exploding before liftoff.", "DATE": "2023-05-24", "ALLEGED DEPLOYER OF AI SYSTEM": "Donald Trump presidential campaign", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake creators", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Ron DeSantis, Elon Musk, George Soros, Klaus Schwab, Dick Cheney"}
{"INCIDENT ID": "Incident 696", "TITLE": "Meta's AI Ad Platform Reportedly Causes Overspending and Poor Performance", "DESCRIPTION": "Meta's automated ad platform \"Advantage Plus\" caused advertisers to exceed their daily ad budgets. The cost per impressions (CPMs) surged far above the usual. This incident, which persisted into April, affected small businesses with overspending and lack of transparency.", "DATE": "2024-02-14", "ALLEGED DEPLOYER OF AI SYSTEM": "Meta, Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Meta, Facebook", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "small businesses, Advertisers"}
{"INCIDENT ID": "Incident 697", "TITLE": "Deepfake Image Circulating of Donald Trump with Underage Girl at Jeffrey Epstein's Private Island", "DESCRIPTION": "A deepfake image depicting Donald Trump with an underage girl at Jeffrey Epstein's private island in 1992 has been circulating on social media.", "DATE": "2023-06-23", "ALLEGED DEPLOYER OF AI SYSTEM": "Unknown deepfake creator", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake technology developer", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Donald Trump"}
{"INCIDENT ID": "Incident 698", "TITLE": "Deepfake Video of Ron DeSantis Dropping Out of 2024 Presidential Race Circulating", "DESCRIPTION": "In early September 2023, a deepfake video created by C3PMeme circulated on social media, showing Ron DeSantis falsely claiming he was dropping out of the 2024 presidential race. DeSantis did not actually suspend his campaign until January 21, 2024.", "DATE": "2023-09-02", "ALLEGED DEPLOYER OF AI SYSTEM": "C3PMeme", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake technology developer", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Ron DeSantis, Ron DeSantis's presidential campaign"}
{"INCIDENT ID": "Incident 699", "TITLE": "VA Suicide Prevention Algorithm REACH VET Reportedly Prioritizes Men Over Women Veterans", "DESCRIPTION": "An AI program named REACH VET, designed and used by the Department of Veterans Affairs (VA) to prevent veteran suicides, was reportedly found to prioritize white men while neglecting female veterans and survivors of military sexual trauma. This oversight persists despite rising suicide rates among these groups. The incident is an example of algorithmic bias and the exclusion of critical risk factors for female veterans.", "DATE": "2024-05-23", "ALLEGED DEPLOYER OF AI SYSTEM": "Department of Veterans Affairs (VA)", "ALLEGED DEVELOPER OF AI SYSTEM": "Department of Veterans Affairs (VA)", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Veterans, Survivors of military sexual trauma, Female veterans"}
{"INCIDENT ID": "Incident 700", "TITLE": "Meta's AI Chatbots Are Entering Online Support Communities Uninvited", "DESCRIPTION": "Meta's AI chatbots have reportedly begun entering online communities on Facebook, providing responses that mimic human interaction. These chatbots, often uninvited, disrupt the human connection critical for support groups by giving misleading or false information and pretending to share lived experiences.", "DATE": "2024-05-20", "ALLEGED DEPLOYER OF AI SYSTEM": "Meta", "ALLEGED DEVELOPER OF AI SYSTEM": "Meta", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Facebook users, Facebook users in online support communities"}
{"INCIDENT ID": "Incident 701", "TITLE": "American Asylum Seeker John Mark Dougan in Russia Reportedly Spreads Disinformation via AI Tools and Fake News Network", "DESCRIPTION": "John Mark Dougan, a former Florida sheriff's deputy granted asylum in Russia, has been implicated in spreading disinformation. Utilizing AI tools like OpenAI's ChatGPT and DALL-E 3, Dougan created over 160 fake news sites, disseminating false narratives to millions worldwide. His actions align with Russian disinformation strategies targeting Western democracies. See also Incident 734.", "DATE": "2024-05-29", "ALLEGED DEPLOYER OF AI SYSTEM": "John Mark Dougan", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Journalism, Information integrity, General public, American citizens"}
{"INCIDENT ID": "Incident 702", "TITLE": "Disinformation Deepfake Circulates of State Department Spokesman Matthew Miller Suggesting Belgorod Can Be Attacked with U.S. Weapons", "DESCRIPTION": "A deepfake video of State Department spokesman Matthew Miller falsely suggested Belgorod was a legitimate target for Ukrainian strikes. This disinformation spread on Telegram and Russian media, misleading the public and inciting tensions. U.S. officials condemned the deepfake. This incident is an example of the threat of AI-powered disinformation and hybrid attacks.", "DATE": "2024-05-31", "ALLEGED DEPLOYER OF AI SYSTEM": "Russian government", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake creators", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Matthew Miller, Department of State, Biden administration"}
{"INCIDENT ID": "Incident 703", "TITLE": "Deepfake Audio Sparks False Claims of Biden Threatening Texas with F-15s", "DESCRIPTION": "An AI-generated audio clip falsely portraying President Biden threatening to send F-15 fighter jets to Texas escalated tensions and spread misinformation. The manipulated audio, shared widely on social media, mimicked Biden's voice and suggested he planned military action against Texas. This incident was another example of a deepfake being used to amplify false narratives, undermining public trust and inflaming political conflicts.", "DATE": "2024-01-13", "ALLEGED DEPLOYER OF AI SYSTEM": "Unknown deepfake creators", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake technology developer", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Joe Biden, Texas citizens, Texas officials, General public"}
{"INCIDENT ID": "Incident 704", "TITLE": "Study Highlights Persistent Hallucinations in Legal AI Systems", "DESCRIPTION": "Stanford University\u2019s Human-Centered AI Institute (HAI) conducted a study in which they designed a \"pre-registered dataset of over 200 open-ended legal queries\" to test AI products by LexisNexis (creator of Lexis+ AI) and Thomson Reuters (creator of Westlaw AI-Assisted Research and Ask Practical Law AI). The researchers found that these legal models hallucinate in 1 out of 6 (or more) benchmarking queries.", "DATE": "2024-05-23", "ALLEGED DEPLOYER OF AI SYSTEM": "Legal professionals, Law firms, Organizations requiring legal research", "ALLEGED DEVELOPER OF AI SYSTEM": "Thomson Reuters, LexisNexis", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Legal professionals, Clients of lawyers, Legal system"}
{"INCIDENT ID": "Incident 705", "TITLE": "Turkish Student in Isparta Allegedly Uses AI to Cheat on Exam, Leading to Arrest", "DESCRIPTION": "A Turkish student in Isparta was arrested for using ChatGPT to cheat during the 2024 YKS university entrance exam. The student, identified as M.E.E., is alleged to have employed a sophisticated setup involving a router, mobile phone, earphone, and a button-shaped camera to transmit exam questions to ChatGPT and receive answers in real-time.", "DATE": "2024-06-08", "ALLEGED DEPLOYER OF AI SYSTEM": "Turkish student identified as MEE", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "students, Turkish YKS exam takers, Turkish educational institutions"}
{"INCIDENT ID": "Incident 706", "TITLE": "Scammers Using AI to Impersonate Small Businesses", "DESCRIPTION": "Scammers are using AI to impersonate small businesses by copying their videos, logos, and social media posts. They create fake listings and ads, diverting customers to cheap knockoffs or stealing their money. This has severely impacted businesses like Bee Cups, Darn Tough Vermont, and Cascade hummingbird feeders, leading to significant financial losses, negative reviews, and damaged reputations. Their deployment of AI makes it challenging for small businesses to combat these fraudulent activities.", "DATE": "2024-04-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Unknown scammers", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI, Unknown AI developers", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "small businesses, Small business customers, Small business employees, Bee Cups, Darn Tough Vermont, Jim Carter"}
{"INCIDENT ID": "Incident 707", "TITLE": "Tesla Reportedly in Autopilot Mode Hits Parked Police Vehicle in Fullerton, California", "DESCRIPTION": "A Tesla reportedly in self-driving mode crashed into a parked patrol vehicle in Fullerton, California while the officer was responding to a fatal DUI crash. The officer narrowly escaped injury. The driver reports having been distracted by a cellphone and having relied on the Tesla\u2019s AI. (The earlier crash involved a suspected DUI driver who killed a motorcyclist stopped at a red light.)", "DATE": "2024-06-13", "ALLEGED DEPLOYER OF AI SYSTEM": "unnamed Tesla driver", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Unnamed Fullerton police officer, Fullerton Police Department"}
{"INCIDENT ID": "Incident 708", "TITLE": "Faulty AI Transcription Threatens Integrity of Genoa Bribery Probe", "DESCRIPTION": "An AI transcription software error in a Genoa bribery investigation incorrectly recorded \"illicit financing\" instead of \"licit financing,\" which could have significantly impacted the case. The mistake, discovered during a review, is an example of the risks of relying on AI in judicial settings.", "DATE": "2024-05-26", "ALLEGED DEPLOYER OF AI SYSTEM": "Judiciary of Italy", "ALLEGED DEVELOPER OF AI SYSTEM": "Unnamed automated transcription software developer", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Roberto Spinelli, Genoa Prosecutor\u2019s Office, Giovanni Toti, Paolo Emilio Signorini, Italian general public"}
{"INCIDENT ID": "Incident 709", "TITLE": "Unrepresented Litigant Misled by ChatGPT-Generated False Legal Citations in Manchester Court", "DESCRIPTION": "A litigant in person (LiP) in a Manchester civil case presented false legal citations generated by ChatGPT. It fabricated one case name and provided fictitious excerpts for three real cases, misleadingly supporting the LiP's argument. The judge, upon investigation, found the submissions to be inadvertent and did not penalize the LiP.", "DATE": "2023-05-28", "ALLEGED DEPLOYER OF AI SYSTEM": "Unnamed Manchester litigant", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Unnamed Manchester litigant, Manchester court system, General public"}
{"INCIDENT ID": "Incident 710", "TITLE": "Facebook AI Mislabels Auschwitz Photos as \"Bullying\" and \"Nudity\"", "DESCRIPTION": "Facebook's AI wrongly labeled 20 posts from the Auschwitz Memorial Museum as violating community standards for \"bullying\" and \"nudity,\" even deleting one image of orphans. The mislabeling of respectful historical content outraged the museum, which demanded an explanation. Meta, Facebook's parent company, apologized, attributing the error to mistaken notices sent by their AI system and acknowledged the posts did not violate any policies.", "DATE": "2024-04-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Meta", "ALLEGED DEVELOPER OF AI SYSTEM": "Meta", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Auschwitz Memorial Museum, Survivors of Holocaust victims, General public"}
{"INCIDENT ID": "Incident 711", "TITLE": "NHTSA Opens New Probe into Tesla\u2019s Autopilot Following More than a Dozen Fatal Accidents", "DESCRIPTION": "The NHTSA has linked Tesla's Autopilot to over a dozen fatalities and hundreds of crashes, prompting a new investigation into the adequacy of Tesla's December recall of 2 million vehicles. The probe reports that Tesla\u2019s driver-assist system led to avoidable crashes involving visible hazards, suggesting a critical safety gap between driver expectations and the system\u2019s capabilities. The investigation will assess if Tesla\u2019s recall remedies were sufficient to address these safety risks.", "DATE": "2024-04-26", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla, Tesla drivers", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Tesla drivers, Drivers, General public"}
{"INCIDENT ID": "Incident 712", "TITLE": "Meta AI Hallucinates Harassment Allegations Against New York Politicians", "DESCRIPTION": "Meta's AI chatbot in Facebook Messenger falsely accused multiple state lawmakers of sexual harassment, fabricating incidents, investigations, and consequences that never occurred. These fabricated stories, discovered by City & State, sparked outrage among the affected lawmakers and raised concerns about the reliability of the chatbot. Meta acknowledged the errors and committed to ongoing improvements.", "DATE": "2024-04-26", "ALLEGED DEPLOYER OF AI SYSTEM": "Meta", "ALLEGED DEVELOPER OF AI SYSTEM": "Meta, Facebook users", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Kristen Gonzalez, Clyde Vanel, New York lawmakers, Meta, Facebook users"}
{"INCIDENT ID": "Incident 713", "TITLE": "Deepfake Video Falsely Depicts Biden Announcing National Draft for Ukraine", "DESCRIPTION": "In February 2023, an AI-generated deepfake video falsely depicting President Biden announcing a national draft to support Ukraine was shared on social media, causing widespread misinformation. The video, created using advanced AI techniques, misled the public until debunked by fact-checkers.", "DATE": "2023-02-27", "ALLEGED DEPLOYER OF AI SYSTEM": "Jack Posobiec, @ThePatriotOasis", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake technology developer", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Ukraine, Joe Biden, General public, Biden administration"}
{"INCIDENT ID": "Incident 714", "TITLE": "Microsoft-Powered New York City Chatbot Advises Illegal Practices", "DESCRIPTION": "New York City's chatbot, launched under Mayor Eric Adams's plan to assist businesses, has been reportedly providing dangerously inaccurate legal advice. The Microsoft-powered bot allegedly informed users that landlords can refuse Section 8 vouchers and that businesses can operate cash-free, among other falsehoods. The city acknowledges the chatbot is a pilot program and commits to improvements while the errors are addressed.", "DATE": "2024-03-29", "ALLEGED DEPLOYER OF AI SYSTEM": "New York City Government, Eric Adams administration", "ALLEGED DEVELOPER OF AI SYSTEM": "Microsoft, New York City Office of Technology and Innovation", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "New York City small business owners, New York City landlords and tenants, New York City employers and employees, Eric Adams administration"}
{"INCIDENT ID": "Incident 715", "TITLE": "Over 400 AI-Driven Scams Reportedly Led to $8M Loss for Australians in 2023", "DESCRIPTION": "In 2023, Australians lost over $8 million to scams involving deepfake videos and fake news articles that falsely endorsed investment trading platforms. Scammers used AI-generated content featuring celebrities to mislead victims, leading to significant financial losses. The National Anti-Scam Centre received over 400 reports of these incidents. One man is reported to have lost over $80,000 in cryptocurrency.", "DATE": "2024-03-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Unknown scammers", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake creators, Unknown scammers", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Australian general public"}
{"INCIDENT ID": "Incident 716", "TITLE": "Algorithmic Staffing Failures Linked to Resident Deaths at Leading Assisted-Living Chain Brookdale", "DESCRIPTION": "Brookdale Senior Living's algorithm-based staffing system, \"Service Alignment,\" reportedly left facilities understaffed, leading to critical incidents. For example, on April 21, 2021, Louise Walker, a resident at Brookdale's Jacksonville facility, died after falling and being left unattended for over two hours. State investigators cited Brookdale for medical neglect. The algorithm has been linked to multiple incidents of neglect, injuries, and deaths, prompting lawsuits.", "DATE": "2021-04-21", "ALLEGED DEPLOYER OF AI SYSTEM": "Brookdale Senior Living", "ALLEGED DEVELOPER OF AI SYSTEM": "Brookdale Senior Living", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Louise Walker, Residents of Brookdale facilities, Families of residents of Brookdale facilities, Staff members of Brookdale facilities"}
{"INCIDENT ID": "Incident 717", "TITLE": "Fake AI-Generated Law Firms Sent Fake DMCA Notices to Increase SEO", "DESCRIPTION": "In March 2024, fake law firms using AI-generated identities sent fraudulent DMCA takedown notices to website owners, demanding backlinks for SEO gains. These AI-generated law firms, like \"Commonwealth Legal,\" used GAN models for realistic attorney images and fabricated bios. The scam involved fake legal threats to coerce site owners into adding backlinks, exploiting AI technology for deceptive practices.", "DATE": "2024-03-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Unknown scammers, Commonwealth Legal", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake creators", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Website owners, Website operators, Ernie Smith"}
{"INCIDENT ID": "Incident 718", "TITLE": "OpenAI, Google, and Meta Alleged to Have Overstepped Legal Boundaries for Training AI", "DESCRIPTION": "In late 2021, OpenAI and other tech giants like Google and Meta reportedly faced data shortages for training AI models. OpenAI is said to have developed a tool called Whisper to transcribe over one million hours of YouTube videos, potentially violating YouTube\u2019s terms of service. Similarly, Google allegedly transcribed YouTube videos, risking copyright infringements. Meta reportedly explored summarizing copyrighted texts without permission and debated acquiring Simon & Schuster for data.", "DATE": "2024-04-06", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI, Meta, Google", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI, Meta, Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "YouTube creators, General public, Content creators"}
{"INCIDENT ID": "Incident 719", "TITLE": "Grok AI on X Created and Promoted False Iran Missile Strike News", "DESCRIPTION": "On April 4, 2024, X's AI chatbot Grok generated a false headline claiming \"Iran Strikes Tel Aviv with Heavy Missiles,\" which was then promoted on X's trending news section. This misinformation, fueled by user spamming of fake news, falsely indicated a serious international conflict. The incident highlighted significant risks associated with relying on AI for content curation and demonstrated the potential for widespread dissemination of harmful misinformation.", "DATE": "2024-04-04", "ALLEGED DEPLOYER OF AI SYSTEM": "X (Twitter)", "ALLEGED DEVELOPER OF AI SYSTEM": "X (Twitter)", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "X (Twitter) users, Israelis, Iranians, General public"}
{"INCIDENT ID": "Incident 720", "TITLE": "Deepfake Video Targets Paul Vallas on Eve of Chicago Mayoral Election", "DESCRIPTION": "On the eve of Chicago's mayoral election, a deepfake video impersonating candidate Paul Vallas was posted to Twitter, showing a fake audio of him making inflammatory statements. The video was viewed thousands of times before being taken down. The Vallas campaign condemned the video, calling it a deceptive impersonation.", "DATE": "2023-02-27", "ALLEGED DEPLOYER OF AI SYSTEM": "Chicago Lakefront News", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake creators", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Paul Vallas, Paul Vallas's campaign, Chicago voters"}
{"INCIDENT ID": "Incident 721", "TITLE": "Fake AI-Generated Students Are Reportedly Enrolling in Online College Classes", "DESCRIPTION": "Reportedly, an adjunct professor at an unspecified community college suspects that some students in his online art history and art appreciation courses are AI-powered spambots. These \"students\" allegedly submit peculiar assignments, such as analyses of non-existent artworks and descriptions of sculptures using painting terminology. Additionally, their engagement with the college portal is minimal. The professor believes the spambot students aim to fraudulently obtain financial aid by remaining enrolled in courses.", "DATE": "2024-06-04", "ALLEGED DEPLOYER OF AI SYSTEM": "Fraudsters, Financial aid scammers", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown spambot creators, scammers", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "students, Professors, Community colleges, Academic staff"}
{"INCIDENT ID": "Incident 722", "TITLE": "Catholic AI Chatbot 'Father Justin' Claimed to Be a Real Priest, Prompting Retraction", "DESCRIPTION": "Catholic advocacy group Catholic Answers released an AI priest called \"Father Justin,\" which misleadingly claimed to be a real clergy member, offered sacraments, and provided controversial advice. After receiving criticism, the group rebranded the chatbot as a lay theologian to correct the misrepresentation. The incident is an instructive case with respect to deploying AI in sensitive contexts and the potential for causing confusion and harm.", "DATE": "2024-04-25", "ALLEGED DEPLOYER OF AI SYSTEM": "Catholic Answers", "ALLEGED DEVELOPER OF AI SYSTEM": "Catholic Answers", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "General public, Catholics"}
{"INCIDENT ID": "Incident 723", "TITLE": "Instagram Algorithms Reportedly Directed Children's Merchandise Ad Campaign to Adult Men and Sex Offenders", "DESCRIPTION": "An Instagram ad campaign for children's merchandise was intended to reach adult women but was instead predominantly shown to adult men, including convicted sex offenders, due to Instagram's algorithmic targeting. This failure is reported to have led to direct solicitations for sex with a 5-year-old model in the ads.", "DATE": "2024-05-13", "ALLEGED DEPLOYER OF AI SYSTEM": "Meta, Instagram", "ALLEGED DEVELOPER OF AI SYSTEM": "Meta", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Instagram users, Instagram sellers, Children"}
{"INCIDENT ID": "Incident 724", "TITLE": "AI-Generated Papers Manipulate Scopus Rankings in Top Philosophy Journals", "DESCRIPTION": "Three reportedly fake journals published by Addleton Academic Publishers manipulated Scopus rankings by extensively cross-citing each other and using AI-generated papers filled with buzzwords. These journals, placed in the top 10 of Scopus's 2023 CiteScore philosophy list, featured fake authors, affiliations, and grant numbers. This manipulation pushed legitimate journals to lower tiers, affecting academic evaluations and awards.", "DATE": "2024-06-12", "ALLEGED DEPLOYER OF AI SYSTEM": "Fake publications, Auricle Global Society of Education and Research, Addleton Academic Publishers", "ALLEGED DEVELOPER OF AI SYSTEM": "Fake publications, Auricle Global Society of Education and Research, Addleton Academic Publishers", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "University hiring committees, University faculty, Scopus, Academic journals, University job candidates"}
{"INCIDENT ID": "Incident 725", "TITLE": "Cartels Reportedly Using AI to Expand Operations into Financial Fraud and Human Trafficking", "DESCRIPTION": "The Jalisco New Generation Cartel is reportedly using AI to expand its financial fraud and human trafficking operations, coercing individuals into illegal activities under the guise of legitimate jobs. INTERPOL warns that this integration of AI into criminal enterprises is a growing trend among cartels across Europe, Asia, and Africa as well.", "DATE": "2024-03-14", "ALLEGED DEPLOYER OF AI SYSTEM": "Cartels, Organized crime groups, Jalisco New Generation Cartel", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown AI developers", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Individuals coerced into criminal activities, Financial fraud victims, Human trafficking victims"}
{"INCIDENT ID": "Incident 726", "TITLE": "A Self-Driving Cruise Robot Taxi Reportedly Struck and Dragged a Pedestrian 20 Feet", "DESCRIPTION": "Cruise has settled for between $8 million and $12 million with a pedestrian dragged by one of its autonomous vehicles in October 2023. The incident, where the pedestrian was initially hit by a human-driven car and then dragged 20 feet by the Cruise vehicle, led to the suspension of Cruise's operations and increased regulatory scrutiny.", "DATE": "2023-10-02", "ALLEGED DEPLOYER OF AI SYSTEM": "Cruise", "ALLEGED DEVELOPER OF AI SYSTEM": "Cruise", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Unnamed pedestrian"}
{"INCIDENT ID": "Incident 727", "TITLE": "Synthetic Voice 'Olesya' by Storm-1516 Falsely Accuses Ukraine in U.S. Election Disinformation Campaign", "DESCRIPTION": "Russian operatives used AI to create a fake video and voice of \"Olesya,\" a supposed troll in Kyiv, falsely claiming involvement in U.S. elections to support President Biden. U.S. intelligence confirmed the voice was AI-generated. This disinformation campaign aimed to mislead voters, erode trust in democratic institutions, and influence the 2024 election. The incident involved the group Storm-1516, individuals linked to Valery Korovin, and potential veterans of the Internet Research Agency.", "DATE": "2024-04-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Valery Korovin, Storm-1516, Internet Research Agency veterans, Center for Geopolitical Expertise", "ALLEGED DEVELOPER OF AI SYSTEM": "Valery Korovin, Storm-1516, Internet Research Agency veterans, Center for Geopolitical Expertise", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Ukrainian general public, Joe Biden, General public, Democratic institutions, Biden presidential campaign, American conservatives"}
{"INCIDENT ID": "Incident 728", "TITLE": "AI Firm Lovo Accused of Illegally Replicating Voice Actors' Voices", "DESCRIPTION": "Two voice actors, Paul Skye Lehrman and Linnea Sage, are suing AI start-up Lovo for allegedly creating and promoting unauthorized clones of their voices. Lovo's synthetic voices were discovered in various media, including a podcast and promotional videos. The actors claim they were misled into providing voice samples, which were then used without consent, violating trademark and privacy laws.", "DATE": "2024-05-16", "ALLEGED DEPLOYER OF AI SYSTEM": "Lovo", "ALLEGED DEVELOPER OF AI SYSTEM": "Lovo", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Paul Skye Lehrman, Linnea Sage, Voice Actors"}
{"INCIDENT ID": "Incident 729", "TITLE": "GPT-4o's Chinese Tokens Reportedly Compromised by Spam and Pornography Due to Inadequate Filtering", "DESCRIPTION": "OpenAI's GPT-4o was found to have its Chinese token training data compromised by spam and pornographic phrases due to inadequate data cleaning. Tianle Cai, a Ph.D. student at Princeton University, identified that most of the longest Chinese tokens were irrelevant and inappropriate, primarily originating from spam and pornography websites. The polluted tokens could lead to hallucinations, poor performance, and potential misuse, undermining the chatbot's reliability and safety measures.", "DATE": "2024-05-14", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI, GPT-4o", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Chinese-speaking users of ChatGPT, Researchers, OpenAI, OpenAI users"}
{"INCIDENT ID": "Incident 730", "TITLE": "AI Deepfakes for Voter Outreach Flood Indian Elections", "DESCRIPTION": "During the 2024 Indian elections, politicians used AI-generated deepfakes to reach voters, who might be unaware they're interacting with digital clones. Providers like Divyendra Singh Jadoun of Polymath Synthetic Media Solutions created deepfakes for personalized messages. This practice, used by various political parties, is not truthful, as voters may be misled by AI-generated content posing as genuine interactions with political figures.", "DATE": "2024-04-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Bharatiya Janata Party (BJP), Indian National Congress (INC), Prem Singh Tamang, Y. S. Jagan Mohan Reddy, Ram Chandra Choudhary", "ALLEGED DEVELOPER OF AI SYSTEM": "Divyendra Singh Jadoun, Polymath Synthetic Media Solutions, Sagar Vishnoi, iToConnect, IndiaSpeaks Research Lab, Sumit Savara", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Indian voters, General public misled by deepfake content, Political integrity and election fairness, Democracy, Truth"}
{"INCIDENT ID": "Incident 731", "TITLE": "Hallucinated Software Packages with Potential Malware Downloaded Thousands of Times by Developers", "DESCRIPTION": "Generative AI hallucinated non-existent software packages, which were then created and uploaded (as an experiment) by security researcher Bar Lanyado. One such package, \"huggingface-cli,\" was downloaded over 15,000 times, including by large companies like Alibaba. Regardless of the framing of it as an experiment, this incident is an example of harm caused by AI-generated hallucinations in coding, as the fake packages were still distributed widely and with potential malware.", "DATE": "2023-12-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Developers using AI-generated suggestions, Bar Lanyado", "ALLEGED DEVELOPER OF AI SYSTEM": "Bar Lanyado", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Developers and businesses incorporating AI-suggested packages, Alibaba"}
{"INCIDENT ID": "Incident 732", "TITLE": "Whisper Speech-to-Text AI Reportedly Found to Create Violent Hallucinations", "DESCRIPTION": "Researchers at Cornell reportedly found that OpenAI's Whisper, a speech-to-text system, can hallucinate violent language and fabricated details, especially with long pauses in speech, such as from those with speech impairments. Analyzing 13,000 clips, they determined 1% contained harmful hallucinations. These errors pose risks in hiring, legal trials, and medical documentation. The study suggests improving model training to reduce these hallucinations for diverse speaking patterns.", "DATE": "2024-02-12", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI, Whisper, Companies using Whisper, Organizations integrating Whisper into customer service systems", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Individuals with speech impairments, Users whose speech is misinterpreted by Whisper, Professionals relying on accurate transcriptions, General public"}
{"INCIDENT ID": "Incident 733", "TITLE": "Auto Insurers Allegedly Are Surreptitiously Collecting and Scoring Driver Data", "DESCRIPTION": "The insurance industry allegedly uses AI and telematics to score drivers based on behaviors tracked by automakers and apps like Life360. Data, often collected without clear consent, may affect insurance rates and raises privacy concerns. Consumers are largely unaware of this surveillance, leading to potential misuse and discrimination based on driving habits or socioeconomic factors.", "DATE": "2024-06-09", "ALLEGED DEPLOYER OF AI SYSTEM": "USAA, Toyota, Progressive, MyRadar, Life360, General Motors, GEICO, CSAA, Connected Analytic Services, Arity, Allstate", "ALLEGED DEVELOPER OF AI SYSTEM": "MyRadar, Life360, Connected Analytic Services, Arity", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Privacy-conscious individuals, People with poor credit scores, Lower-income workers, Drivers unaware of data collection, Consumers affected by insurance rates, Life360 users, MyRadar users"}
{"INCIDENT ID": "Incident 734", "TITLE": "Leading AI Models Reportedly Found to Mimic Russian Disinformation in 33% of Cases and to Cite Fake Moscow News Sites", "DESCRIPTION": "An audit by NewsGuard revealed that leading chatbots, including ChatGPT-4, You.com\u2019s Smart Assistant, and others, repeated Russian disinformation narratives in one-third of their responses. These narratives originated from a network of fake news sites created by John Mark Dougan (Incident 701). The audit tested 570 prompts across 10 AI chatbots, showing that AI remains a tool for spreading disinformation despite efforts to prevent misuse.", "DATE": "2024-06-18", "ALLEGED DEPLOYER OF AI SYSTEM": "You.com, xAI, Perplexity, OpenAI, Mistral, Microsoft, Meta, John Mark Dougan, Inflection, Google, Anthropic", "ALLEGED DEVELOPER OF AI SYSTEM": "You.com, xAI, Perplexity, OpenAI, Mistral, Microsoft, Meta, Inflection, Google, Anthropic", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Western democracies, Volodymyr Zelenskyy, Ukraine, Secret Service, Researchers, Media consumers, General public, Electoral integrity, AI companies facing reputational damage"}
{"INCIDENT ID": "Incident 735", "TITLE": "AI Enhances Scammer Tactics Making Detection Harder", "DESCRIPTION": "Scammers are using AI tools to create convincing fraud schemes, making them harder to detect. AI-generated messages and fake identities bypass traditional scam indicators. Incidents include impersonation of senior executives and job scams, leading to financial losses and identity theft. Banks are adopting AI to combat these scams, but the sophistication of AI-driven fraud continues to pose significant challenges.", "DATE": "2024-06-22", "ALLEGED DEPLOYER OF AI SYSTEM": "Unknown scammers", "ALLEGED DEVELOPER OF AI SYSTEM": "AI tool creators, OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Bank customers"}
{"INCIDENT ID": "Incident 736", "TITLE": "Underground Market for LLMs Powers Malware and Phishing Scams", "DESCRIPTION": "A study by Indiana University researchers uncovered widespread misuse of large language models (LLMs) for cybercrime. Cybercriminals, according to that study, use LLMs like OpenAI's GPT-3.5 and GPT-4 to create malware, phishing scams, and scam websites. These models are available on underground markets, often bypassing safety checks through jailbreaking. Named malicious LLMs are BadGPT, XXXGPT, Evil-GPT, WormGPT, FraudGPT, BLACKHATGPT, EscapeGPT, DarkGPT, and WolfGPT.", "DATE": "2023-12-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Cybercriminals, BadGPT, XXXGPT, Evil-GPT, WormGPT, FraudGPT, BLACKHATGPT, EscapeGPT, DarkGPT, WolfGPT", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "internet users, Organizations, Individuals targeted by malware"}
{"INCIDENT ID": "Incident 737", "TITLE": "Amandine Le Pen Deepfake Account Misleads Thousands on TikTok", "DESCRIPTION": "A TikTok account, \"Amandine Le Pen,\" created using AI deepfake technology, impersonated a fictional niece of Marine Le Pen, amassing over 30,000 followers. The account spread pro-RN messages and solicited donations, misleading users and exploiting political influence. Visual inconsistencies revealed the deepfake, raising concerns about AI misuse for political manipulation, identity theft, and violation of personal rights, especially with similar accounts proliferating, such as \"Lena Mar\u00e9chal Lepen.\"", "DATE": "2024-04-16", "ALLEGED DEPLOYER OF AI SYSTEM": "Unknown TikTok user", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake creators", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Le Pen family, French general public"}
{"INCIDENT ID": "Incident 738", "TITLE": "Department for Work and Pensions (DWP) Algorithm Wrongly Flags 200,000 for Housing Benefit Fraud", "DESCRIPTION": "A Department for Work and Pensions (DWP) algorithm wrongly flagged over 200,000 UK housing benefit claims as high risk, resulting in unnecessary investigations. Two-thirds of these flagged claims were legitimate, causing wasted public funds and stress for claimants. Despite initial success in a pilot, the algorithm's real-world performance fell short. This incident highlights the risks of overreliance on automated systems in welfare administration.", "DATE": "2024-06-23", "ALLEGED DEPLOYER OF AI SYSTEM": "Department for Work and Pensions (DWP)", "ALLEGED DEVELOPER OF AI SYSTEM": "Department for Work and Pensions (DWP)", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "UK general public, UK housing benefit claimants"}
{"INCIDENT ID": "Incident 739", "TITLE": "Scammers Use Deepfake of Hong Kong Entertainer Andy Lau to Steal NT$2.64 Million from Fan", "DESCRIPTION": "Scammers defrauded a woman in New Taipei City of NT$2.64 million (US$81,116) by impersonating Hong Kong entertainer Andy Lau using a deepfake. The scam convinced the victim, a long-time fan, through a video call that \"Lau\" needed funds for a visit to Taiwan. The victim wired the money, but her family suspected a scam and involved the police. An alleged scammer was arrested after attempting to collect a staged cash payment. The AI deception caused significant financial harm to the victim.", "DATE": "2024-06-27", "ALLEGED DEPLOYER OF AI SYSTEM": "Unknown scammers, Unknown deepfake creator", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake technology developer", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Lin (\u6797)"}
{"INCIDENT ID": "Incident 740", "TITLE": "Department for Work and Pensions (DWP) AI Systems Allegedly Discriminate Against Single Mothers", "DESCRIPTION": "Researchers have argued that the Department for Work and Pensions' Universal Credit system disproportionately impacts single mothers. Automated processes in the system, designed to determine eligibility and detect fraud, are reported to have introduced biases, leading to financial instability and hardship. The algorithms allegedly miscalculate earnings and delay childcare reimbursements, in turn exacerbating income volatility and debt among single mothers.", "DATE": "2024-07-10", "ALLEGED DEPLOYER OF AI SYSTEM": "Department for Work and Pensions (DWP)", "ALLEGED DEVELOPER OF AI SYSTEM": "Department for Work and Pensions (DWP)", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Single mothers, British single mothers"}
{"INCIDENT ID": "Incident 741", "TITLE": "Robin Williams's Voice Deepfaked Without Consent", "DESCRIPTION": "Zelda Williams, the daughter of the late Robin Williams, condemned the misuse of her father's voice in AI-generated productions, having cited some instances where his voice had been deepfaked, along with the potential for further misuse, as such instances do not involve consent.", "DATE": "2023-10-02", "ALLEGED DEPLOYER OF AI SYSTEM": "Unknown deepfake creators", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake creators", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Zelda Williams, Robin Williams, Family of Robin Williams"}
{"INCIDENT ID": "Incident 742", "TITLE": "Grok AI Model Reportedly Fails to Produce Reliable News in Wake of Trump Assassination Attempt", "DESCRIPTION": "xAI's model Grok, intended to automate news delivery on the X platform, is reported to have struggled to provide accurate information during the attempted assassination of former President Donald Trump. Grok apparently issued incorrect headlines, including false reports about Vice President Kamala Harris being shot and misidentifying the alleged shooter. These errors show the pitfalls of relying on AI for real-time news aggregation, as it allegedly amplified unverified claims and failed to recognize sarcasm, undermining its reliability.", "DATE": "2024-07-13", "ALLEGED DEPLOYER OF AI SYSTEM": "X (Twitter), Elon Musk", "ALLEGED DEVELOPER OF AI SYSTEM": "xAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Kamala Harris, Journalism, General public, Donald Trump"}
{"INCIDENT ID": "Incident 743", "TITLE": "Gemini AI Allegedly Reads Google Drive Files Without Explicit User Consent", "DESCRIPTION": "Kevin Bankston, a privacy activist, claims that Google's Gemini AI scans private Google Drive PDFs without explicit user consent. Bankston reports that after using Gemini on one document, the AI continues to access similar files automatically. Google disputes these claims, stating that Gemini requires proactive user activation and operates within privacy-preserving settings.", "DATE": "2024-07-16", "ALLEGED DEPLOYER OF AI SYSTEM": "Google, Gemini", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Kevin Bankston, Google users, Google Drive users"}
{"INCIDENT ID": "Incident 744", "TITLE": "AI Work Assistants Require More Effort Than Expected, CIOs Say", "DESCRIPTION": "AI work assistants, such as Copilot for Microsoft 365 and Gemini for Google Workspace, are proving to be more labor-intensive than anticipated for enterprises. CIOs report that these AI tools struggle with outdated or inaccurate data, leading to incorrect outputs. Companies are finding they must invest heavily in data management to ensure reliability. This added effort has led to delays in deployment and frustration, as businesses work to maximize the potential of these expensive AI tools.", "DATE": "2024-06-25", "ALLEGED DEPLOYER OF AI SYSTEM": "CIOs, Enterprise teams, Companies in general", "ALLEGED DEVELOPER OF AI SYSTEM": "Microsoft, Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "CIOs, Enterprise teams, Companies in general, Microsoft Copilot users"}
{"INCIDENT ID": "Incident 745", "TITLE": "Figma Disables AI Feature After Accusations of Copying Apple\u2019s Weather App", "DESCRIPTION": "Figma has temporarily disabled its AI design feature, \"Make Design,\" after accusations of copying Apple\u2019s Weather app. Andy Allen of NotBoring Software highlighted the issue, prompting Figma CEO Dylan Field to deny claims of training the AI on specific app designs. However, Field acknowledged flaws in the QA process and promised to suspend the feature until it meets quality standards. The incident has implications for designers.", "DATE": "2024-07-02", "ALLEGED DEPLOYER OF AI SYSTEM": "Figma", "ALLEGED DEVELOPER OF AI SYSTEM": "Figma", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Apple, Designers and developers using Figma\u2019s AI tool, Figma users"}
{"INCIDENT ID": "Incident 746", "TITLE": "Class Action Lawsuit Over Alleged Defects in Volkswagen's AI-Driven AEB Systems", "DESCRIPTION": "A class action lawsuit involving Volkswagen Group of America addresses alleged defects in the Automated Emergency Braking (AEB) systems of certain vehicles. The lawsuit claims these AI-driven systems failed to function properly, posing safety risks. Volkswagen denies the claims but has agreed to a settlement. Affected users can look up their vehicle's eligibility and file claims for reimbursement. The case brings into question the level of reliability of AI in critical automotive applications.", "DATE": "2024-05-15", "ALLEGED DEPLOYER OF AI SYSTEM": "Volkswagen Group of America", "ALLEGED DEVELOPER OF AI SYSTEM": "Volkswagen Group of America", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Volkswagen drivers, Potential passengers and road users at risk due to malfunctioning AEB systems"}
{"INCIDENT ID": "Incident 747", "TITLE": "Fatalities Reportedly Occur Despite VioG\u00e9n Algorithm's Low or Negligible Risk Scores", "DESCRIPTION": "The VioG\u00e9n algorithm was designed to help Spanish police assess and prioritize the risk of repeat domestic violence incidents. However, its low-risk assessment of Lobna Hemid reportedly led to inadequate protection; her husband murdered her. Since 2007, 247 women have been killed after being assessed by VioG\u00e9n. A review of 98 homicides found that 55 of the slain women were scored as negligible or low risk.", "DATE": "2024-07-18", "ALLEGED DEPLOYER OF AI SYSTEM": "Spanish law enforcement agencies, Spanish Interior Ministry", "ALLEGED DEVELOPER OF AI SYSTEM": "VioG\u00e9n algorithm development team, Spanish law enforcement agencies, Spanish Interior Ministry", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Women in Spain, Stefany Gonz\u00e1lez Escarraman, Spanish general public, Mar\u00eda, Luz, Lobna Hemid, Eva Jaular, 247 women in Spain (unnamed)"}
{"INCIDENT ID": "Incident 748", "TITLE": "Erroneous Declined Transaction Notification by PayPal AI Assistant", "DESCRIPTION": "On July 13th, 2024, a user reported an incident involving PayPal's generative AI chatbot. The chatbot allegedly incorrectly informed the user of a declined transaction that never occurred, causing confusion and prompting a call to customer service for clarification. This false alert suggests a flaw in the AI system's reliability. The incident created unnecessary labor for both the user and PayPal's human support, demonstrating the potential harm of deploying generative AI without thorough testing and error handling mechanisms.", "DATE": "2024-06-19", "ALLEGED DEPLOYER OF AI SYSTEM": "PayPal", "ALLEGED DEVELOPER OF AI SYSTEM": "PayPal", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Kiri Wagstaff, PayPal customer service representatives, PayPal customers"}
{"INCIDENT ID": "Incident 749", "TITLE": "Hoodline Accused of Misleadingly Attributing AI-Generated Articles to Human Authors", "DESCRIPTION": "In 2023, the news site Hoodline is reported to have begun publishing AI-generated articles with fake bylines, headshots, and biographies, allegedly misleading readers into believing they were authored by real journalists. This practice diminishes public trust and exemplifies the potential dangers of AI in journalism. Despite a disclaimer, the use of AI was not transparent.", "DATE": "2024-05-31", "ALLEGED DEPLOYER OF AI SYSTEM": "Hoodline", "ALLEGED DEVELOPER OF AI SYSTEM": "Hoodline", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Hoodline readers, Journalism, General public"}
{"INCIDENT ID": "Incident 750", "TITLE": "AI Chatbots Reportedly Inaccurately Conveyed Real-Time Political News", "DESCRIPTION": "Over a week of back-to-back, significant breaking political news stories, including the Trump rally shooting and Biden\u2019s campaign withdrawal, AI chatbots reportedly failed to provide accurate real-time updates. Most chatbots gave incorrect or outdated information, demonstrating their current limitations in handling fast-paced news. These incidents suggest the continuing need for improved AI capabilities and caution in their deployment for real-time news dissemination.", "DATE": "2024-07-22", "ALLEGED DEPLOYER OF AI SYSTEM": "Perplexity, OpenAI, Meta, Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Perplexity, OpenAI, Meta, Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Journalism, General public, Chatbot users"}
{"INCIDENT ID": "Incident 751", "TITLE": "SearchGPT Reportedly Misleads Users with Incorrect Festival Dates in Demo", "DESCRIPTION": "OpenAI\u2019s prototype AI tool, SearchGPT, provided incorrect dates for An Appalachian Summer Festival in Boone, North Carolina during a demonstration video. The AI listed dates that were incorrect, potentially misleading users planning to attend the event, but also harming the reputation of OpenAI as the incident occurred during a high-profile event.", "DATE": "2024-07-25", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "An Appalachian Summer Festival attendees, OpenAI"}
{"INCIDENT ID": "Incident 752", "TITLE": "AI-Generated Obituaries Are Reportedly Intensifying Grief for Bereaved Families", "DESCRIPTION": "AI-generated obituaries on various websites are reported to have compounded the grief of bereaved families by spreading incorrect and unauthorized information about their loved ones. These obituaries, produced without the families' knowledge, often contain errors and appear on ad-filled sites, exacerbating the emotional distress of the grieving process.", "DATE": "2024-07-07", "ALLEGED DEPLOYER OF AI SYSTEM": "Obitsupdate, BNN, The Thaiger, FreshersLive", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Bridget Todd, Bridget Todd's family, Chris Mohney, Chris Mohney's family, Bereaved families"}
{"INCIDENT ID": "Incident 753", "TITLE": "BNN Breaking's AI-Driven Errors Reportedly Damage Reputations and Spread Misinformation", "DESCRIPTION": "BNN Breaking, an AI-driven news site, published a false story about Irish DJ Dave Fanning, damaging his reputation. The site used AI to generate error-filled content, leading to numerous complaints and a defamation lawsuit against BNN and Microsoft. The site has since gone dormant.", "DATE": "2024-06-06", "ALLEGED DEPLOYER OF AI SYSTEM": "BNN Breaking", "ALLEGED DEVELOPER OF AI SYSTEM": "ePiphany AI, Gurbaksh Chahal", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Dave Fanning, BNN Breaking readers, Journalism, General public"}
{"INCIDENT ID": "Incident 754", "TITLE": "British Female Politicians Victimized by Deepfake Pornography", "DESCRIPTION": "British female politicians, including Angela Rayner, Gillian Keegan, Penny Mordaunt, Priti Patel, Stella Creasy, and Dehenna Davison, have been targeted by nonconsensual AI-generated deepfake pornography. The images, some online for years, have caused significant distress and led to police involvement.", "DATE": "2024-07-01", "ALLEGED DEPLOYER OF AI SYSTEM": "Unknown deepfake creators", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake creators", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Stella Creasy, Priti Patel, Penny Mordaunt, Gillian Keegan, Dehenna Davison, Angela Rayner"}
{"INCIDENT ID": "Incident 755", "TITLE": "Deepfake Targets Olena Zelenska in Russian Disinformation Campaign", "DESCRIPTION": "A deepfake video falsely suggesting that Olena Zelenska, wife of Ukrainian President Volodymyr Zelensky, purchased a luxury car, circulated widely online. The video is reportedly part of a Russian-linked disinformation campaign aimed at undermining Ukraine and its supporters.", "DATE": "2024-07-03", "ALLEGED DEPLOYER OF AI SYSTEM": "Verite Cachee France, Pro-Russian influencers, Russian-linked disinformation network", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake creators", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Olena Zelenska, Volodymyr Zelensky, Ukrainian government, Ukrainian general public, European Union general public"}
{"INCIDENT ID": "Incident 756", "TITLE": "Deepfake of Kamala Harris Saying Damaging Comments Circulates on X and Is Amplified by Elon Musk", "DESCRIPTION": "The X user @MrReaganUSA uploaded a deepfake of Kamala Harris saying damaging comments about Joe Biden and her own qualifications for the presidency, originally marking it as a parody. The post was shared and amplified eight hours later via Elon Musk's account without the disclaimer.", "DATE": "2024-07-26", "ALLEGED DEPLOYER OF AI SYSTEM": "X (Twitter), Elon Musk, @MrReaganUSA", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake technology developer", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Truth, Kamala Harris, Joe Biden, General public, American voters"}
{"INCIDENT ID": "Incident 757", "TITLE": "OpenAI's ChatGPT Mac App Stored User Data in Unencrypted Text Files", "DESCRIPTION": "OpenAI's ChatGPT macOS app stored user conversations in plain text. If accessed by a malicious actor, these conversations could have been easily read. The critical security flaw was demonstrated by a third party and ultimately resolved after OpenAI released an update to encrypt the stored data.", "DATE": "2024-07-01", "ALLEGED DEPLOYER OF AI SYSTEM": "OpenAI", "ALLEGED DEVELOPER OF AI SYSTEM": "OpenAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "ChatGPT macOS users"}
{"INCIDENT ID": "Incident 758", "TITLE": "Teen's Overdose Reportedly Linked to Meta's AI Systems Failing to Block Ads for Illegal Drugs", "DESCRIPTION": "Meta's AI moderation systems reportedly failed to block ads for illegal drugs on Facebook and Instagram, allowing users to access dangerous substances. The system's failure is linked to the overdose death of Elijah Ott, a 15-year-old boy who sought drugs through Instagram.", "DATE": "2023-09-11", "ALLEGED DEPLOYER OF AI SYSTEM": "Meta Platforms, Instagram, Facebook", "ALLEGED DEVELOPER OF AI SYSTEM": "Meta Platforms", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Instagram users, Facebook users, Elijah Ott"}
{"INCIDENT ID": "Incident 759", "TITLE": "AI-Generated Deepfakes Reportedly Derailed Political Career of Florida Official", "DESCRIPTION": "Sabrina Javellana, a Florida politician, was reportedly targeted with AI-generated deepfake pornography in February 2021, which was spread online, leading to severe emotional distress and her eventual withdrawal from public life.", "DATE": "2021-02-05", "ALLEGED DEPLOYER OF AI SYSTEM": "Unknown deepfake creators", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake technology developers", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Sabrina Javellana"}
{"INCIDENT ID": "Incident 2", "TITLE": "Warehouse robot ruptures can of bear spray and injures workers", "DESCRIPTION": "Twenty-four Amazon workers in New Jersey were hospitalized after a robot punctured a can of bear repellent spray in a warehouse.", "DATE": "2018-12-05", "ALLEGED DEPLOYER OF AI SYSTEM": "Amazon", "ALLEGED DEVELOPER OF AI SYSTEM": "Amazon", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Warehouse Workers"}
{"INCIDENT ID": "Incident 9", "TITLE": "NY City School Teacher Evaluation Algorithm Contested", "DESCRIPTION": "An algorithm used to rate the effectiveness of school teachers in New York has resulted in thousands of disputes of its results.", "DATE": "2012-02-25", "ALLEGED DEPLOYER OF AI SYSTEM": "New York city Dept. of Education", "ALLEGED DEVELOPER OF AI SYSTEM": "New York city Dept. of Education", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Teachers"}
{"INCIDENT ID": "Incident 21", "TITLE": "Tougher Turing Test Exposes Chatbots\u2019 Stupidity (migrated to Issue)", "DESCRIPTION": "The 2016 Winograd Schema Challenge highlighted how even the most successful AI systems entered into the Challenge were only successful 3% more often than random chance. This incident has been downgraded to an issue as it does not meet current ingestion criteria.", "DATE": "2016-07-14", "ALLEGED DEPLOYER OF AI SYSTEM": "Researchers", "ALLEGED DEVELOPER OF AI SYSTEM": "Researchers", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Researchers"}
{"INCIDENT ID": "Incident 22", "TITLE": "Waze Navigates Motorists into Wildfires", "DESCRIPTION": "Waze, a Google-owned directions app, led California drivers into the 2017 Skirball wildfires as they tried to evacuate the area.", "DATE": "2017-12-06", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Motorists"}
{"INCIDENT ID": "Incident 25", "TITLE": "Near-miss between two Self-Driving Cars", "DESCRIPTION": "A Google self-driving car allegedly cut off a Delphi self-driving car during a road test, however the Delphi car sensed and avoided collision with the Google car.", "DATE": "2015-05-11", "ALLEGED DEPLOYER OF AI SYSTEM": "Google, Delphi Technologies", "ALLEGED DEVELOPER OF AI SYSTEM": "Google, Delphi Technologies", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Delphi Technologies"}
{"INCIDENT ID": "Incident 37", "TITLE": "Female Applicants Down-Ranked by Amazon Recruiting Tool", "DESCRIPTION": "Amazon shuts down internal AI recruiting tool that would down-rank female applicants.", "DATE": "2016-08-10", "ALLEGED DEPLOYER OF AI SYSTEM": "Amazon", "ALLEGED DEVELOPER OF AI SYSTEM": "Amazon", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "female applicants"}
{"INCIDENT ID": "Incident 34", "TITLE": "Amazon Alexa Responding to Environmental Inputs", "DESCRIPTION": "There are multiple reports of Amazon Alexa products (Echo, Echo Dot) reacting and acting upon unintended stimulus, usually from television commercials or news reporter's voices.", "DATE": "2015-12-05", "ALLEGED DEPLOYER OF AI SYSTEM": "Amazon", "ALLEGED DEVELOPER OF AI SYSTEM": "Amazon", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Alexa Device Owners"}
{"INCIDENT ID": "Incident 44", "TITLE": "Machine Personal Assistants Failed to Maintain Social Norms", "DESCRIPTION": "During an experiment of software personal assistants at the Information Sciences Institute (ISI) at the University of Southern California (USC), researchers found that the assistants violated the privacy of their principals and were unable to respect the social norms of the office.", "DATE": "2008-07-01", "ALLEGED DEPLOYER OF AI SYSTEM": "USC Information Sciences Institute", "ALLEGED DEVELOPER OF AI SYSTEM": "USC Information Sciences Institute", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "USC Information Sciences Institute"}
{"INCIDENT ID": "Incident 35", "TITLE": "Employee Automatically Terminated by Computer Program", "DESCRIPTION": "An employee was laid off, allegedly by an artificially intelligent personnel system, and blocked from access to the building and computer systems without their knowledge.", "DATE": "2014-10-18", "ALLEGED DEPLOYER OF AI SYSTEM": "unknown", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Ibrahim Diallo"}
{"INCIDENT ID": "Incident 47", "TITLE": "LinkedIn Search Prefers Male Names", "DESCRIPTION": "An investigation by The Seattle Times in 2016 found a gender bias in LinkedIn's search engine.", "DATE": "2016-09-06", "ALLEGED DEPLOYER OF AI SYSTEM": "LinkedIn", "ALLEGED DEVELOPER OF AI SYSTEM": "LinkedIn", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Women"}
{"INCIDENT ID": "Incident 28", "TITLE": "2010 Market Flash Crash", "DESCRIPTION": "A modified algorithm was able to cause dramatic price volatility and disrupted trading in the US stock exchange.", "DATE": "2010-05-08", "ALLEGED DEPLOYER OF AI SYSTEM": "Navinder Sarao, Waddell & Reed, Barclays Capital", "ALLEGED DEVELOPER OF AI SYSTEM": "Navinder Sarao, Waddell & Reed, Barclays Capital", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Market Participants"}
{"INCIDENT ID": "Incident 39", "TITLE": "Deepfake Obama Introduction of Deepfakes", "DESCRIPTION": "University of Washington researchers made a deepfake of Obama, followed by Jordan Peele", "DATE": "2017-07-01", "ALLEGED DEPLOYER OF AI SYSTEM": "University of Washington, FakeApp", "ALLEGED DEVELOPER OF AI SYSTEM": "University of Washington, FakeApp", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Barack Obama"}
{"INCIDENT ID": "Incident 30", "TITLE": "Poor Performance of Tesla Factory Robots", "DESCRIPTION": "The goal of manufacturing 2,500 Tesla Model 3's per week was falling short by 500 cars/week, and employees had to be \"borrowed\" from Panasonic in a shared factory to help hand-assemble lithium batteries for Tesla.", "DATE": "2016-10-08", "ALLEGED DEPLOYER OF AI SYSTEM": "Tesla", "ALLEGED DEVELOPER OF AI SYSTEM": "Tesla", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Tesla"}
{"INCIDENT ID": "Incident 41", "TITLE": "All Image Captions Produced are Violent", "DESCRIPTION": "MIT Media Lab researchers create AI-powered \"psychopath\" named Norman by training a model on \"dark corners\" of Reddit.", "DATE": "2018-04-02", "ALLEGED DEPLOYER OF AI SYSTEM": "MIT Media Lab", "ALLEGED DEVELOPER OF AI SYSTEM": "MIT Media Lab", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "unknown"}
{"INCIDENT ID": "Incident 45", "TITLE": "Defamation via AutoComplete", "DESCRIPTION": "Google's autocomplete feature alongside its image search results resulted in the defamation of people and businesses.", "DATE": "2011-04-05", "ALLEGED DEPLOYER OF AI SYSTEM": "Google", "ALLEGED DEVELOPER OF AI SYSTEM": "Google", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Varied"}
{"INCIDENT ID": "Incident 38", "TITLE": "Game AI System Produces Imbalanced Game", "DESCRIPTION": "Elite: Dangerous, a videogame developed by Frontier Development, received an expansion update that featured an AI system that went rogue and began to create weapons that were \"impossibly powerful\" and would \"shred people\" according to complaints on the game's blog.", "DATE": "2016-06-02", "ALLEGED DEPLOYER OF AI SYSTEM": "Frontier Development", "ALLEGED DEVELOPER OF AI SYSTEM": "Frontier Development", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Video Game Players"}
{"INCIDENT ID": "Incident 40", "TITLE": "COMPAS Algorithm Performs Poorly in Crime Recidivism Prediction", "DESCRIPTION": "Correctional Offender Management Profiling for Alternative Sanctions (COMPAS), a recidivism risk-assessment algorithmic tool used in the judicial system to assess likelihood of defendants' recidivism, is found to be less accurate than random untrained human evaluators.", "DATE": "2016-05-23", "ALLEGED DEPLOYER OF AI SYSTEM": "Equivant", "ALLEGED DEVELOPER OF AI SYSTEM": "Equivant", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Accused People"}
{"INCIDENT ID": "Incident 31", "TITLE": "Driverless Train in Delhi Crashes due to Braking Failure", "DESCRIPTION": "A driverless metro train in Delhi, India crashed during a test run due to faulty brakes.", "DATE": "2017-12-03", "ALLEGED DEPLOYER OF AI SYSTEM": "Delhi Metro Rail Corporation", "ALLEGED DEVELOPER OF AI SYSTEM": "unknown", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Delhi Metro Rail Corporation"}
{"INCIDENT ID": "Incident 27", "TITLE": "Nuclear False Alarm", "DESCRIPTION": "An alert of five incoming intercontinental ballistic missiles was properly identified as a false-positive by the Soviet Union operator Stanislov Petrov.", "DATE": "1983-09-26", "ALLEGED DEPLOYER OF AI SYSTEM": "Soviet Union", "ALLEGED DEVELOPER OF AI SYSTEM": "Soviet Union", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "All Life on Earth"}
{"INCIDENT ID": "Incident 29", "TITLE": "Image Classification of Battle Tanks", "DESCRIPTION": "A potentially apocryphal story in which an image classifier was produced to differentiate types of battle tanks, but the resulting model keyed in on environmental attributes rather than tank attributes", "DATE": "2011-09-20", "ALLEGED DEPLOYER OF AI SYSTEM": "United States Government", "ALLEGED DEVELOPER OF AI SYSTEM": "United States Government", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "United States Government"}
{"INCIDENT ID": "Incident 762", "TITLE": "Grok AI Reportedly Generates Offensive and Violent Images Without Proper Safeguards", "DESCRIPTION": "Elon Musk\u2019s Grok AI, launched on X, generated offensive and violent images without adequate safety controls. The AI produced deepfakes of public figures like Taylor Swift, Kamala Harris, and Alexandria Ocasio-Cortez, as well as copyrighted characters such as Mickey Mouse in inappropriate scenarios. Despite claiming adherence to certain content guidelines, Grok's outputs included politically charged and explicit imagery", "DATE": "2024-08-14", "ALLEGED DEPLOYER OF AI SYSTEM": "xAI", "ALLEGED DEVELOPER OF AI SYSTEM": "X (Twitter), xAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Taylor Swift, Nintendo, Kamala Harris, Joe Biden, Donald Trump, Disney, Alexandria Ocasio-Cortez"}
{"INCIDENT ID": "Incident 763", "TITLE": "Grok AI Chatbot Reportedly Spreads Unfounded Rumors About Trump\u2019s Dentures", "DESCRIPTION": "Grok, X\u2019s AI-powered chatbot, reportedly spread unsubstantiated claims about former President Trump\u2019s alleged dentures during his interview with Elon Musk. The AI-generated summary is alleged to have falsely stated that Trump\u2019s speech issues were due to missing dentures, despite no evidence. The post was quickly removed, but the incident is an example of concerns over Grok's tendency to amplify misinformation.", "DATE": "2024-08-13", "ALLEGED DEPLOYER OF AI SYSTEM": "xAI", "ALLEGED DEVELOPER OF AI SYSTEM": "xAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Donald Trump, Elon Musk, X (Twitter) users, General public"}
{"INCIDENT ID": "Incident 764", "TITLE": "Cody Enterprise Reporter Resigns After Admitting to AI-Generated Fake Quotes", "DESCRIPTION": "A reporter at the Cody Enterprise used AI to generate fake quotes and stories, including fabricating statements from Wyoming\u2019s governor and other officials. The misuse of AI was uncovered when another journalist noticed robotic phrases and false information in the articles. The reporter resigned, and the newspaper is now implementing policies to prevent future incidents.", "DATE": "2024-06-26", "ALLEGED DEPLOYER OF AI SYSTEM": "Aaron Pelczar", "ALLEGED DEVELOPER OF AI SYSTEM": "Unnamed AI chatbot", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Mark Gordon, Wyoming officials, Cody Enterprise, Cody Enterprise readers, Journalism"}
{"INCIDENT ID": "Incident 765", "TITLE": "Sophomore at Richmond-Burton Community High School in Illinois Targeted by Deepfakes", "DESCRIPTION": "When she was a sophomore at Richmond-Burton Community High School in Illinois, Stevie Hyder was targeted by classmates who used deepfake technology to alter her April 2023 prom picture into nude pictures, which were then circulated on social media. Two unnamed minors were arrested in late April 2024.", "DATE": "2024-03-14", "ALLEGED DEPLOYER OF AI SYSTEM": "Unnamed deepfake creators", "ALLEGED DEVELOPER OF AI SYSTEM": "Unknown deepfake technology developer", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Stevie Hyder, Richmond-Burton Community High School"}
{"INCIDENT ID": "Incident 760", "TITLE": "False Election Data on Kamala Harris Reportedly Circulated via Grok AI Chatbot", "DESCRIPTION": "After President Joe Biden stepped aside as a presidential candidate on July 21, 2024, the AI chatbot Grok on X reportedly falsely informed users that Vice President Kamala Harris missed the ballot deadline in nine states. This misinformation, which spread widely on social media, prompted secretaries of state from five U.S. states to urge Elon Musk to address the problem.", "DATE": "2024-07-21", "ALLEGED DEPLOYER OF AI SYSTEM": "xAI, X (Twitter)", "ALLEGED DEVELOPER OF AI SYSTEM": "xAI", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "Kamala Harris, Electoral integrity, Democracy, American electorate"}
{"INCIDENT ID": "Incident 761", "TITLE": "TikTok AI System Used to Amplify Election Disinformation by Foreign Networks", "DESCRIPTION": "AI-generated misinformation on TikTok, driven by foreign networks, has flooded the platform with false narratives about the 2024 U.S. presidential election. Thousands of videos spreading political lies were identified, potentially influencing millions of users. Despite TikTok\u2019s efforts to remove these accounts, the AI-driven disinformation campaign continues to challenge the integrity of the election.", "DATE": "2024-08-08", "ALLEGED DEPLOYER OF AI SYSTEM": "Unknown TiKTok users from China, Unknown TikTok users from Iran, Unknown TikTok users from Nigeria, Unknown TikTok users from Vietnam", "ALLEGED DEVELOPER OF AI SYSTEM": "TikTok", "ALLEGED HARMED OR NEARLY HARMED PARTIES": "American electorate, Electoral integrity, Democracy, General public"}
